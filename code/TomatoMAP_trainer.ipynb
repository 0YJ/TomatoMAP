{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727b72fb-b718-4ed3-8340-5376050147ed",
   "metadata": {},
   "source": [
    "# TomatoMAP-Cls Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad99b1c-b47d-4386-bc62-433dda73b066",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T06:59:05.120408Z",
     "start_time": "2025-07-07T06:58:55.424375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment checker:\n",
      "  PyTorch version: 2.7.1+cu126\n",
      "  CUDA version: True\n",
      "  GPU device: Tesla V100-PCIE-16GB\n",
      "  GPU ram: 15.8 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchvision.models import (\n",
    "    MobileNet_V3_Large_Weights,\n",
    "    MobileNet_V3_Small_Weights,\n",
    "    MobileNet_V2_Weights,\n",
    "    ResNet18_Weights,\n",
    ")\n",
    "\n",
    "# env checker\n",
    "print(\"Environment checker:\")\n",
    "print(f\"  PyTorch version: {torch.__version__}\")\n",
    "print(f\"  CUDA version: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU ram: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35beeeb4-ca9c-47b4-9893-7d2bf01a1894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T07:00:42.814782Z",
     "start_time": "2025-07-07T07:00:42.797777Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"model saved at: {path}\")\n",
    "\n",
    "def load_model(model, path, device='cpu'):\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"model loaded from: {path}\")\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, path)\n",
    "\n",
    "def load_checkpoint(path, model, optimizer, device):\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"from epoch {start_epoch} re-training\")\n",
    "    return start_epoch\n",
    "\n",
    "def get_font(size=30, bold=False):\n",
    "    font_paths = [\n",
    "        \"C:/Windows/Fonts/arialbd.ttf\" if bold else \"C:/Windows/Fonts/arial.ttf\",\n",
    "        \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\" if bold else \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\",\n",
    "        \"/System/Library/Fonts/Supplemental/Arial-Bold.ttf\" if bold else \"/System/Library/Fonts/Supplemental/Arial.ttf\",\n",
    "    ]\n",
    "    for path in font_paths:\n",
    "        try:\n",
    "            return ImageFont.truetype(path, size=size)\n",
    "        except:\n",
    "            continue\n",
    "    return ImageFont.load_default()\n",
    "\n",
    "def denormalize(img_tensor, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "    mean = torch.tensor(mean).view(3, 1, 1).to(img_tensor.device)\n",
    "    std = torch.tensor(std).view(3, 1, 1).to(img_tensor.device)\n",
    "    return torch.clamp(img_tensor * std + mean, 0, 1)\n",
    "\n",
    "def get_model(name, num_classes, pretrained=True):\n",
    "    print(f\"build model: {name}, class number: {num_classes}\")\n",
    "    \n",
    "    if name == 'mobilenet_v3_large':\n",
    "        weights = MobileNet_V3_Large_Weights.DEFAULT if pretrained else None\n",
    "        model = models.mobilenet_v3_large(weights=weights)\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "    elif name == 'mobilenet_v3_small':\n",
    "        weights = MobileNet_V3_Small_Weights.DEFAULT if pretrained else None\n",
    "        model = models.mobilenet_v3_small(weights=weights)\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "    elif name == 'mobilenet_v2':\n",
    "        weights = MobileNet_V2_Weights.DEFAULT if pretrained else None\n",
    "        model = models.mobilenet_v2(weights=weights)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif name == 'resnet18':\n",
    "        weights = ResNet18_Weights.DEFAULT if pretrained else None\n",
    "        model = models.resnet18(weights=weights)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {name} not supported.\")\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"parameter info: Total: {total_params:,}, Trainable: {trainable_params:,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "class BBCHDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_dir, split='train', transform=None):\n",
    "        self.data_dir = os.path.join(data_dir, split)\n",
    "        self.transform = transform\n",
    "        \n",
    "        if not os.path.exists(self.data_dir):\n",
    "            raise FileNotFoundError(f\"Directory not found: {self.data_dir}\")\n",
    "        \n",
    "        # get all classes\n",
    "        self.classes = sorted([d for d in os.listdir(self.data_dir)\n",
    "                              if os.path.isdir(os.path.join(self.data_dir, d))])\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        self.samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.samples.append((img_path, class_idx))\n",
    "        \n",
    "        print(f\"loading {split} dataset: {len(self.samples)} images, {len(self.classes)} classes\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"failed to load image: {img_path}, error: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# data enhance\n",
    "def get_transforms(target_size=(640, 640)):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(target_size),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(target_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "def get_dataloaders(data_dir, batch_size=32, target_size=(640, 640), num_workers=8, include_test=False):\n",
    "    print(f\"building dataloader: {data_dir}\")\n",
    "    \n",
    "    train_transform, val_transform = get_transforms(target_size)\n",
    "    \n",
    "    train_dataset = BBCHDataset(data_dir, 'train', train_transform)\n",
    "    val_dataset = BBCHDataset(data_dir, 'val', val_transform)\n",
    "\n",
    "    # for windows users\n",
    "    import platform\n",
    "    if platform.system() == 'Windows':\n",
    "        num_workers = 0\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    test_loader = None\n",
    "    if include_test:\n",
    "        test_dir = os.path.join(data_dir, 'test')\n",
    "        if os.path.exists(test_dir):\n",
    "            test_dataset = BBCHDataset(data_dir, 'test', val_transform)\n",
    "            test_loader = DataLoader(\n",
    "                test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
    "            )\n",
    "        else:\n",
    "            print(\"test set not found, using val as test\")\n",
    "            test_loader = val_loader\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a707cf3-f677-4963-bff3-043bdc24f791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T07:03:52.327730Z",
     "start_time": "2025-07-07T07:03:52.313731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:\n",
      "  data_dir: TomatoMAP/TomatoMAP-Cls\n",
      "  model_name: mobilenet_v3_large\n",
      "  num_classes: 50\n",
      "  batch_size: 32\n",
      "  num_epochs: 30\n",
      "  learning_rate: 0.0001\n",
      "  target_size: (640, 640)\n",
      "  patience: 3\n",
      "  save_interval: 20\n"
     ]
    }
   ],
   "source": [
    "CLASSIFICATION_CONFIG = {\n",
    "    'data_dir': 'TomatoMAP/TomatoMAP-Cls',\n",
    "    'model_name': 'mobilenet_v3_large',  # 'mobilenet_v3_small', 'mobilenet_v2', 'resnet18'\n",
    "    'num_classes': 50,\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 30,\n",
    "    'learning_rate': 1e-4,\n",
    "    'target_size': (640, 640),\n",
    "    'patience': 3,\n",
    "    'save_interval': 20\n",
    "}\n",
    "\n",
    "print(\"config:\")\n",
    "for key, value in CLASSIFICATION_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b168c68-baaf-426d-b81d-7794e3c0a099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TomatoMAP-Cls Trainer\n",
      "============================================================\n",
      "data founded at: TomatoMAP/TomatoMAP-Cls\n",
      "TomatoMAP-Cls is well structured.\n",
      "\n",
      " training config:\n",
      "   data_dir: TomatoMAP/TomatoMAP-Cls\n",
      "   model_name: mobilenet_v3_large\n",
      "   num_classes: 50\n",
      "   batch_size: 32\n",
      "   num_epochs: 30\n",
      "   learning_rate: 0.0001\n",
      "   target_size: (640, 640)\n",
      "   patience: 3\n",
      "   save_interval: 20\n",
      "\n",
      " training start.\n",
      "Using device: cuda\n",
      "building dataloader: TomatoMAP/TomatoMAP-Cls\n",
      "loading train dataset: 45099 images, 50 classes\n",
      "loading val dataset: 12870 images, 50 classes\n",
      "loading test dataset: 6495 images, 50 classes\n",
      "build model: mobilenet_v3_large, class number: 50\n",
      "parameter info: Total: 4,266,082, Trainable: 4,266,082\n",
      "Training start with 30 epoch(s),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]: 100%|████████████████| 1410/1410 [06:55<00:00,  3.39it/s, Loss=1.8002, Acc=32.31%]\n",
      "Epoch 1/30 [Val]: 100%|████████████████████| 403/403 [01:00<00:00,  6.67it/s, Loss=1.8581, Acc=40.05%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/30:\n",
      "  Train - Loss: 2.1123, Acc: 32.31%\n",
      "  Val - Loss: 1.6768, Acc: 40.05%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 40.05%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [Train]: 100%|████████████████| 1410/1410 [06:48<00:00,  3.45it/s, Loss=1.9883, Acc=42.30%]\n",
      "Epoch 2/30 [Val]: 100%|████████████████████| 403/403 [01:07<00:00,  5.99it/s, Loss=0.9373, Acc=45.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 2/30:\n",
      "  Train - Loss: 1.6399, Acc: 42.30%\n",
      "  Val - Loss: 1.4930, Acc: 45.84%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 45.84%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [Train]: 100%|████████████████| 1410/1410 [06:52<00:00,  3.42it/s, Loss=1.7607, Acc=47.10%]\n",
      "Epoch 3/30 [Val]: 100%|████████████████████| 403/403 [01:00<00:00,  6.64it/s, Loss=0.9665, Acc=47.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 3/30:\n",
      "  Train - Loss: 1.4578, Acc: 47.10%\n",
      "  Val - Loss: 1.4351, Acc: 47.71%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 47.71%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [Train]: 100%|████████████████| 1410/1410 [06:46<00:00,  3.47it/s, Loss=1.2591, Acc=51.96%]\n",
      "Epoch 4/30 [Val]: 100%|████████████████████| 403/403 [01:06<00:00,  6.06it/s, Loss=1.2630, Acc=53.02%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 4/30:\n",
      "  Train - Loss: 1.3072, Acc: 51.96%\n",
      "  Val - Loss: 1.2602, Acc: 53.02%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 53.02%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Train]: 100%|████████████████| 1410/1410 [06:54<00:00,  3.40it/s, Loss=1.0347, Acc=56.47%]\n",
      "Epoch 5/30 [Val]: 100%|████████████████████| 403/403 [01:00<00:00,  6.63it/s, Loss=1.0445, Acc=54.39%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 5/30:\n",
      "  Train - Loss: 1.1802, Acc: 56.47%\n",
      "  Val - Loss: 1.2064, Acc: 54.39%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 54.39%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Train]: 100%|████████████████| 1410/1410 [06:57<00:00,  3.38it/s, Loss=0.8705, Acc=60.32%]\n",
      "Epoch 6/30 [Val]: 100%|████████████████████| 403/403 [01:02<00:00,  6.47it/s, Loss=0.5300, Acc=58.96%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 6/30:\n",
      "  Train - Loss: 1.0670, Acc: 60.32%\n",
      "  Val - Loss: 1.0961, Acc: 58.96%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 58.96%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [Train]: 100%|████████████████| 1410/1410 [06:46<00:00,  3.47it/s, Loss=0.9907, Acc=64.10%]\n",
      "Epoch 7/30 [Val]: 100%|████████████████████| 403/403 [01:04<00:00,  6.29it/s, Loss=0.5100, Acc=60.51%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 7/30:\n",
      "  Train - Loss: 0.9635, Acc: 64.10%\n",
      "  Val - Loss: 1.0496, Acc: 60.51%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 60.51%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [Train]: 100%|████████████████| 1410/1410 [06:42<00:00,  3.50it/s, Loss=1.0332, Acc=67.50%]\n",
      "Epoch 8/30 [Val]: 100%|████████████████████| 403/403 [01:00<00:00,  6.68it/s, Loss=0.4854, Acc=62.77%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 8/30:\n",
      "  Train - Loss: 0.8680, Acc: 67.50%\n",
      "  Val - Loss: 0.9902, Acc: 62.77%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 62.77%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [Train]: 100%|████████████████| 1410/1410 [06:48<00:00,  3.45it/s, Loss=0.8735, Acc=70.62%]\n",
      "Epoch 9/30 [Val]: 100%|████████████████████| 403/403 [01:01<00:00,  6.58it/s, Loss=0.3427, Acc=64.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 9/30:\n",
      "  Train - Loss: 0.7869, Acc: 70.62%\n",
      "  Val - Loss: 0.9535, Acc: 64.92%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 64.92%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [Train]: 100%|███████████████| 1410/1410 [06:53<00:00,  3.41it/s, Loss=0.5824, Acc=73.65%]\n",
      "Epoch 10/30 [Val]: 100%|███████████████████| 403/403 [01:01<00:00,  6.55it/s, Loss=0.1160, Acc=66.73%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 10/30:\n",
      "  Train - Loss: 0.7029, Acc: 73.65%\n",
      "  Val - Loss: 0.8825, Acc: 66.73%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 66.73%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [Train]: 100%|███████████████| 1410/1410 [07:00<00:00,  3.36it/s, Loss=0.6338, Acc=76.41%]\n",
      "Epoch 11/30 [Val]: 100%|███████████████████| 403/403 [01:00<00:00,  6.68it/s, Loss=0.9800, Acc=70.13%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 11/30:\n",
      "  Train - Loss: 0.6342, Acc: 76.41%\n",
      "  Val - Loss: 0.8193, Acc: 70.13%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 70.13%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [Train]: 100%|███████████████| 1410/1410 [06:59<00:00,  3.36it/s, Loss=0.6373, Acc=78.85%]\n",
      "Epoch 12/30 [Val]: 100%|███████████████████| 403/403 [00:59<00:00,  6.74it/s, Loss=0.5220, Acc=69.18%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 12/30:\n",
      "  Train - Loss: 0.5705, Acc: 78.85%\n",
      "  Val - Loss: 0.8643, Acc: 69.18%\n",
      "  lr: 1.00e-04\n",
      "  val acc not raised (1/3)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [Train]: 100%|███████████████| 1410/1410 [06:56<00:00,  3.38it/s, Loss=0.4635, Acc=80.82%]\n",
      "Epoch 13/30 [Val]: 100%|███████████████████| 403/403 [00:59<00:00,  6.76it/s, Loss=0.4900, Acc=70.23%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 13/30:\n",
      "  Train - Loss: 0.5188, Acc: 80.82%\n",
      "  Val - Loss: 0.8389, Acc: 70.23%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 70.23%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 [Train]: 100%|███████████████| 1410/1410 [06:58<00:00,  3.37it/s, Loss=0.8183, Acc=82.79%]\n",
      "Epoch 14/30 [Val]: 100%|███████████████████| 403/403 [01:01<00:00,  6.53it/s, Loss=0.1427, Acc=72.19%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 14/30:\n",
      "  Train - Loss: 0.4690, Acc: 82.79%\n",
      "  Val - Loss: 0.7842, Acc: 72.19%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 72.19%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 [Train]: 100%|███████████████| 1410/1410 [06:41<00:00,  3.51it/s, Loss=0.6168, Acc=84.51%]\n",
      "Epoch 15/30 [Val]: 100%|███████████████████| 403/403 [01:00<00:00,  6.67it/s, Loss=0.0423, Acc=73.65%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 15/30:\n",
      "  Train - Loss: 0.4207, Acc: 84.51%\n",
      "  Val - Loss: 0.7464, Acc: 73.65%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 73.65%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 [Train]: 100%|███████████████| 1410/1410 [07:09<00:00,  3.29it/s, Loss=0.3393, Acc=86.13%]\n",
      "Epoch 16/30 [Val]: 100%|███████████████████| 403/403 [01:01<00:00,  6.59it/s, Loss=0.0441, Acc=74.16%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 16/30:\n",
      "  Train - Loss: 0.3839, Acc: 86.13%\n",
      "  Val - Loss: 0.7422, Acc: 74.16%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 74.16%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 [Train]: 100%|███████████████| 1410/1410 [06:46<00:00,  3.47it/s, Loss=0.8132, Acc=87.79%]\n",
      "Epoch 17/30 [Val]: 100%|███████████████████| 403/403 [01:01<00:00,  6.60it/s, Loss=0.0240, Acc=73.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 17/30:\n",
      "  Train - Loss: 0.3403, Acc: 87.79%\n",
      "  Val - Loss: 0.8209, Acc: 73.03%\n",
      "  lr: 1.00e-04\n",
      "  val acc not raised (1/3)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 [Train]: 100%|███████████████| 1410/1410 [06:44<00:00,  3.49it/s, Loss=1.2770, Acc=88.62%]\n",
      "Epoch 18/30 [Val]: 100%|███████████████████| 403/403 [01:00<00:00,  6.67it/s, Loss=0.0083, Acc=75.19%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 18/30:\n",
      "  Train - Loss: 0.3198, Acc: 88.62%\n",
      "  Val - Loss: 0.7634, Acc: 75.19%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 75.19%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 [Train]: 100%|███████████████| 1410/1410 [06:47<00:00,  3.46it/s, Loss=0.3210, Acc=89.24%]\n",
      "Epoch 19/30 [Val]: 100%|███████████████████| 403/403 [01:00<00:00,  6.68it/s, Loss=0.2833, Acc=75.68%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 19/30:\n",
      "  Train - Loss: 0.2938, Acc: 89.24%\n",
      "  Val - Loss: 0.7364, Acc: 75.68%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 75.68%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 [Train]: 100%|███████████████| 1410/1410 [06:43<00:00,  3.50it/s, Loss=0.4446, Acc=90.42%]\n",
      "Epoch 20/30 [Val]: 100%|███████████████████| 403/403 [01:01<00:00,  6.57it/s, Loss=0.0088, Acc=74.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 20/30:\n",
      "  Train - Loss: 0.2635, Acc: 90.42%\n",
      "  Val - Loss: 0.7816, Acc: 74.93%\n",
      "  lr: 1.00e-04\n",
      "  val acc not raised (1/3)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 [Train]: 100%|███████████████| 1410/1410 [06:48<00:00,  3.45it/s, Loss=0.2350, Acc=91.08%]\n",
      "Epoch 21/30 [Val]: 100%|███████████████████| 403/403 [01:03<00:00,  6.33it/s, Loss=0.7884, Acc=76.23%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 21/30:\n",
      "  Train - Loss: 0.2497, Acc: 91.08%\n",
      "  Val - Loss: 0.7626, Acc: 76.23%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 76.23%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 [Train]: 100%|███████████████| 1410/1410 [06:45<00:00,  3.48it/s, Loss=0.4563, Acc=92.02%]\n",
      "Epoch 22/30 [Val]: 100%|███████████████████| 403/403 [01:00<00:00,  6.64it/s, Loss=0.0347, Acc=75.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 22/30:\n",
      "  Train - Loss: 0.2265, Acc: 92.02%\n",
      "  Val - Loss: 0.8087, Acc: 75.87%\n",
      "  lr: 1.00e-04\n",
      "  val acc not raised (1/3)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 [Train]: 100%|███████████████| 1410/1410 [07:10<00:00,  3.27it/s, Loss=0.3957, Acc=92.44%]\n",
      "Epoch 23/30 [Val]: 100%|███████████████████| 403/403 [01:06<00:00,  6.06it/s, Loss=0.2525, Acc=76.99%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 23/30:\n",
      "  Train - Loss: 0.2128, Acc: 92.44%\n",
      "  Val - Loss: 0.7541, Acc: 76.99%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 76.99%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 [Train]: 100%|███████████████| 1410/1410 [06:52<00:00,  3.42it/s, Loss=0.1079, Acc=92.88%]\n",
      "Epoch 24/30 [Val]: 100%|███████████████████| 403/403 [01:05<00:00,  6.11it/s, Loss=0.0584, Acc=77.33%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 24/30:\n",
      "  Train - Loss: 0.2004, Acc: 92.88%\n",
      "  Val - Loss: 0.7255, Acc: 77.33%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 77.33%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 [Train]: 100%|███████████████| 1410/1410 [06:45<00:00,  3.48it/s, Loss=0.3559, Acc=93.45%]\n",
      "Epoch 25/30 [Val]: 100%|███████████████████| 403/403 [01:04<00:00,  6.23it/s, Loss=0.0602, Acc=77.47%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 25/30:\n",
      "  Train - Loss: 0.1869, Acc: 93.45%\n",
      "  Val - Loss: 0.7610, Acc: 77.47%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 77.47%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 [Train]: 100%|███████████████| 1410/1410 [06:46<00:00,  3.47it/s, Loss=0.2543, Acc=93.95%]\n",
      "Epoch 26/30 [Val]: 100%|███████████████████| 403/403 [01:01<00:00,  6.58it/s, Loss=0.0157, Acc=78.09%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 26/30:\n",
      "  Train - Loss: 0.1716, Acc: 93.95%\n",
      "  Val - Loss: 0.7465, Acc: 78.09%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 78.09%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 [Train]: 100%|███████████████| 1410/1410 [06:47<00:00,  3.46it/s, Loss=0.0405, Acc=94.37%]\n",
      "Epoch 27/30 [Val]: 100%|███████████████████| 403/403 [00:59<00:00,  6.73it/s, Loss=0.2581, Acc=77.28%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 27/30:\n",
      "  Train - Loss: 0.1627, Acc: 94.37%\n",
      "  Val - Loss: 0.7966, Acc: 77.28%\n",
      "  lr: 1.00e-04\n",
      "  val acc not raised (1/3)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 [Train]: 100%|███████████████| 1410/1410 [06:44<00:00,  3.48it/s, Loss=0.4891, Acc=94.52%]\n",
      "Epoch 28/30 [Val]: 100%|███████████████████| 403/403 [01:00<00:00,  6.62it/s, Loss=0.0969, Acc=79.19%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 28/30:\n",
      "  Train - Loss: 0.1564, Acc: 94.52%\n",
      "  Val - Loss: 0.7067, Acc: 79.19%\n",
      "  lr: 1.00e-04\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/best_mobilenet_v3_large.pth\n",
      "  best val acc: 79.19%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 [Train]: 100%|███████████████| 1410/1410 [06:52<00:00,  3.41it/s, Loss=0.4975, Acc=94.85%]\n",
      "Epoch 29/30 [Val]: 100%|███████████████████| 403/403 [01:04<00:00,  6.28it/s, Loss=0.2542, Acc=77.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 29/30:\n",
      "  Train - Loss: 0.1497, Acc: 94.85%\n",
      "  Val - Loss: 0.8152, Acc: 77.54%\n",
      "  lr: 1.00e-04\n",
      "  val acc not raised (1/3)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 [Train]: 100%|███████████████| 1410/1410 [06:47<00:00,  3.46it/s, Loss=0.3944, Acc=95.06%]\n",
      "Epoch 30/30 [Val]: 100%|███████████████████| 403/403 [01:00<00:00,  6.68it/s, Loss=0.1726, Acc=79.02%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 30/30:\n",
      "  Train - Loss: 0.1404, Acc: 95.06%\n",
      "  Val - Loss: 0.7246, Acc: 79.02%\n",
      "  lr: 1.00e-05\n",
      "  val acc not raised (2/3)\n",
      "------------------------------------------------------------\n",
      "model saved at: cls/runs/mobilenet_v3_large_cls/final_mobilenet_v3_large.pth\n",
      "\n",
      " TomatoMAP-Cls is trained!\n",
      "  best val acc: 79.19%\n",
      "  model saved at: cls/runs/mobilenet_v3_large_cls\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training log saved at: cls/runs/mobilenet_v3_large_cls/training_history.csv\n",
      "\n",
      "============================================================\n",
      "\n",
      " training finished!\n",
      "   best val acc is: 79.19%\n",
      "   model saved at: cls/runs/mobilenet_v3_large_cls\n",
      "\n",
      " evaluating on test subset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|███████████████████████████████████████| 203/203 [00:31<00:00,  6.42it/s, Acc=79.01%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test subset acc: 79.01%\n",
      "\n",
      " building confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 310x310 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " Evaluation results:\n",
      "   best val acc: 79.19%\n",
      "   test acc: 79.01%\n",
      "   class number: 50\n",
      "   test data size: 6495\n",
      "   results saved at: cls/runs/mobilenet_v3_large_cls\n",
      "   GGWP!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def train_model(config):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    output_dir = Path(f\"cls/runs/{config['model_name']}_cls\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    train_loader, val_loader, test_loader = get_dataloaders(\n",
    "        config['data_dir'], \n",
    "        batch_size=config['batch_size'],\n",
    "        target_size=config['target_size'],\n",
    "        num_workers=8,\n",
    "        include_test=True\n",
    "    )\n",
    "    \n",
    "    model = get_model(config['model_name'], config['num_classes'], pretrained=True)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=0.01)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(f\"Training start with {config['num_epochs']} epoch(s),\")\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Train]\")\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_pbar):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            current_acc = 100 * train_correct / train_total\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{current_acc:.2f}%'\n",
    "            })\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Val]\")\n",
    "            \n",
    "            for images, labels in val_pbar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                current_acc = 100 * val_correct / val_total\n",
    "                val_pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Acc': f'{current_acc:.2f}%'\n",
    "                })\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        print(f\"\\n Epoch {epoch+1}/{config['num_epochs']}:\")\n",
    "        print(f\"  Train - Loss: {avg_train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Val - Loss: {avg_val_loss:.4f}, Acc: {val_acc:.2f}%\")\n",
    "        print(f\"  lr: {current_lr:.2e}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_path = output_dir / f\"best_{config['model_name']}.pth\"\n",
    "            save_model(model, best_model_path)\n",
    "            patience_counter = 0\n",
    "            print(f\"  best val acc: {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  val acc not raised ({patience_counter}/{config['patience']})\")\n",
    "        \n",
    "        if (epoch + 1) % config['save_interval'] == 0:\n",
    "            checkpoint_path = output_dir / f\"checkpoint_epoch_{epoch+1}.pth\"\n",
    "            save_checkpoint(model, optimizer, epoch, checkpoint_path)\n",
    "        \n",
    "        if patience_counter >= config['patience']:\n",
    "            print(f\"\\n Trigger early stop. Val acc has {config['patience']} epochs no improve\")\n",
    "            break\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    final_model_path = output_dir / f\"final_{config['model_name']}.pth\"\n",
    "    save_model(model, final_model_path)\n",
    "    \n",
    "    print(f\"\\n TomatoMAP-Cls is trained!\")\n",
    "    print(f\"  best val acc: {best_val_acc:.2f}%\")\n",
    "    print(f\"  model saved at: {output_dir}\")\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_losses, label='train loss', color='blue')\n",
    "    plt.plot(val_losses, label='val loss', color='red')\n",
    "    plt.title('training loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(train_accuracies, label='train acc', color='blue')\n",
    "    plt.plot(val_accuracies, label='val acc', color='red')\n",
    "    plt.title('training acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    lrs = []\n",
    "    for i in range(len(train_losses)):\n",
    "        if i < 30:\n",
    "            lrs.append(config['learning_rate'])\n",
    "        elif i < 60:\n",
    "            lrs.append(config['learning_rate'] * 0.1)\n",
    "        else:\n",
    "            lrs.append(config['learning_rate'] * 0.01)\n",
    "    plt.plot(lrs, label='lr', color='green')\n",
    "    plt.title('lr changes')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'training_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    history_df = pd.DataFrame({\n",
    "        'epoch': range(1, len(train_losses) + 1),\n",
    "        'train_loss': train_losses,\n",
    "        'val_loss': val_losses,\n",
    "        'train_acc': train_accuracies,\n",
    "        'val_acc': val_accuracies\n",
    "    })\n",
    "    history_df.to_csv(output_dir / 'training_history.csv', index=False)\n",
    "    print(f\" training log saved at: {output_dir / 'training_history.csv'}\")\n",
    "    \n",
    "    return model, best_val_acc, output_dir, test_loader\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TomatoMAP-Cls Trainer\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not os.path.exists(CLASSIFICATION_CONFIG['data_dir']):\n",
    "    print(f\"dataset not exist\")\n",
    "    print(f\"   path: {CLASSIFICATION_CONFIG['data_dir']}\")\n",
    "    print(f\"   please check data structure\")\n",
    "else:\n",
    "    print(f\"data founded at: {CLASSIFICATION_CONFIG['data_dir']}\")\n",
    "    \n",
    "    train_dir = os.path.join(CLASSIFICATION_CONFIG['data_dir'], 'train')\n",
    "    val_dir = os.path.join(CLASSIFICATION_CONFIG['data_dir'], 'val')\n",
    "    test_dir = os.path.join(CLASSIFICATION_CONFIG['data_dir'], 'test')\n",
    "    \n",
    "    if not os.path.exists(train_dir):\n",
    "        print(f\"training subset not exist: {train_dir}\")\n",
    "    elif not os.path.exists(val_dir):\n",
    "        print(f\"val subset not exist: {val_dir}\")\n",
    "    elif not os.path.exists(test_dir):\n",
    "        print(f\"test subset not exist: {test_dir}\")\n",
    "        print(f\"   using val subset for test\")\n",
    "    else:\n",
    "        print(f\"TomatoMAP-Cls is well structured.\")\n",
    "        \n",
    "        print(\"\\n training config:\")\n",
    "        for key, value in CLASSIFICATION_CONFIG.items():\n",
    "            print(f\"   {key}: {value}\")\n",
    "        \n",
    "        print(\"\\n training start.\")\n",
    "        \n",
    "        try:\n",
    "            model, best_acc, output_dir, test_loader = train_model(CLASSIFICATION_CONFIG)\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"\\n training finished!\")\n",
    "            print(f\"   best val acc is: {best_acc:.2f}%\")\n",
    "            print(f\"   model saved at: {output_dir}\")\n",
    "            \n",
    "            print(\"\\n evaluating on test subset...\")\n",
    "            model.eval()\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "            test_predictions = []\n",
    "            test_labels = []\n",
    "            \n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                test_pbar = tqdm(test_loader, desc=\"evaluating\")\n",
    "                for images, labels in test_pbar:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    \n",
    "                    test_total += labels.size(0)\n",
    "                    test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    test_predictions.extend(predicted.cpu().numpy())\n",
    "                    test_labels.extend(labels.cpu().numpy())\n",
    "                    \n",
    "                    current_acc = 100 * test_correct / test_total\n",
    "                    test_pbar.set_postfix({'Acc': f'{current_acc:.2f}%'})\n",
    "            \n",
    "            test_accuracy = 100 * test_correct / test_total\n",
    "            print(f\" test subset acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "            print(\"\\n building confusion matrix\")\n",
    "            \n",
    "            train_dataset = test_loader.dataset\n",
    "            class_names = train_dataset.classes\n",
    "            \n",
    "            cm = confusion_matrix(test_labels, test_predictions)\n",
    "            \n",
    "            cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "            cm_df.to_csv(output_dir / 'confusion_matrix.csv')\n",
    "\n",
    "            normalized_cm = cm_df.div(cm_df.sum(axis=1), axis=0).fillna(0)\n",
    "            \n",
    "            matrix = normalized_cm.T.to_numpy()\n",
    "            \n",
    "            from matplotlib import rcParams\n",
    "            # rcParams['font.family'] = 'Calibri' # Ubuntu doesn't own this when training on ubuntu VM\n",
    "            rcParams['font.size'] = 8\n",
    "            \n",
    "            masked_matrix = np.ma.masked_where(matrix == 0, matrix)\n",
    "            \n",
    "            from matplotlib.colors import Normalize\n",
    "            cmap = plt.cm.jet\n",
    "            cmap.set_bad(color='white')\n",
    "            norm = Normalize(vmin=0.1, vmax=1)\n",
    "            \n",
    "            fig_width_in = 3.1\n",
    "            fig_height_in = fig_width_in\n",
    "            fig, ax = plt.subplots(figsize=(fig_width_in, fig_height_in))\n",
    "            \n",
    "            im = ax.imshow(masked_matrix, cmap=cmap, norm=norm)\n",
    "\n",
    "            # For further process for publishing purpose, labels are removed :)\n",
    "            ax.set_xlabel(\"\")\n",
    "            ax.set_ylabel(\"\")\n",
    "            \n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_dir / 'normalized_confusion_matrix.png', format='png', dpi=300)\n",
    "            plt.show()\n",
    "            \n",
    "            # plt.figure(figsize=(12, 10))\n",
    "            # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "            # disp.plot(cmap='Blues', values_format='d')\n",
    "            # plt.title(f'Detailed Confusion Matrix (test acc: {test_accuracy:.2f}%)', fontsize=8)\n",
    "            # plt.xticks(rotation=45, ha='right')\n",
    "            # plt.yticks(rotation=0)\n",
    "            # plt.tight_layout()\n",
    "            # plt.savefig(output_dir / 'detailed_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "            # plt.show()\n",
    "            \n",
    "            test_results = {\n",
    "                'test_accuracy': test_accuracy,\n",
    "                'total_samples': test_total,\n",
    "                'correct_predictions': test_correct,\n",
    "                'num_classes': len(class_names),\n",
    "                'class_names': class_names\n",
    "            }\n",
    "            \n",
    "            import json\n",
    "            with open(output_dir / 'test_results.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(test_results, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\" Evaluation results:\")\n",
    "            print(f\"   best val acc: {best_acc:.2f}%\")\n",
    "            print(f\"   test acc: {test_accuracy:.2f}%\")\n",
    "            print(f\"   class number: {len(class_names)}\")\n",
    "            print(f\"   test data size: {test_total}\")\n",
    "            print(f\"   results saved at: {output_dir}\")\n",
    "            print(f\"   GGWP!\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n training interruptted\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n error during training:\")\n",
    "            print(f\"   error info: {str(e)}\")\n",
    "            print(\"\\nDetails:\")\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270bc778-324d-46cf-aec4-37f9b4cd6cde",
   "metadata": {},
   "source": [
    "# TomatoMAP-Det Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517ad488-17f7-44d5-aa3d-0b23e131d49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.63 🚀 Python-3.10.0 torch-2.7.1+cu126 CUDA:0 (Tesla V100-PCIE-16GB, 16144MiB)\n",
      "Setup complete ✅ (24 CPUs, 113.0 GB RAM, 137.6/145.2 GB disk)\n",
      "/home/ubuntu/project/EoC/code/det/ultralytics/__init__.py\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics import RTDETR\n",
    "\n",
    "# using proper libiary?\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "print(ultralytics.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3872b57-2251-4d4d-a179-ff0c7d312236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TomatoMAP-Det Trainer\n",
      "\n",
      "============================================================\n",
      "downloading pretrained model: \n",
      "model info: \n",
      "New https://pypi.org/project/ultralytics/8.3.162 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.63 🚀 Python-3.10.0 torch-2.7.1+cu126 CUDA:0 (Tesla V100-PCIE-16GB, 16144MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11l.pt, data=det/TomatoMAP-Det.yaml, epochs=500, time=None, patience=10, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=[0], workers=8, project=det/output, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.00089, lrf=0.009, momentum=0.6, weight_decay=0.00016, warmup_epochs=7.22893, warmup_momentum=0.6, warmup_bias_lr=0.0, box=5.45995, cls=0.4119, dfl=1.0, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.0181, hsv_s=0.27375, hsv_v=0.06764, degrees=0.0, translate=0.14088, scale=0.06371, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.02976, bgr=0.0, mosaic=0.8, mixup=0.0, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=det/best_hyperparameters.yaml, tracker=botsort.yaml, save_dir=det/output/train10\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1416421  ultralytics.nn.modules.head.Detect           [7, [256, 512, 512]]          \n",
      "YOLO11l summary: 631 layers, 25,315,877 parameters, 25,315,861 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir det/output/train10', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/project/EoC/code/det/ultralytics/utils/torch_utils.py:258: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:233.)\n",
      "  fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.shape))\n",
      "/home/ubuntu/project/EoC/code/det/ultralytics/utils/torch_utils.py:263: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:233.)\n",
      "  fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/project/EoC/code/det/ultralytics/nn/modules/block.py:1248: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:233.)\n",
      "  attn = (q.transpose(-2, -1) @ k) * (self.head_dim ** -0.5)\n",
      "/home/ubuntu/project/EoC/code/det/ultralytics/nn/modules/block.py:1252: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:233.)\n",
      "  x = (v @ attn.transpose(-2, -1))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Det/labels/test.cache... 64463 image\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Det/labels/test.cache... 64463 images,\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to det/output/train10/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00089' and 'momentum=0.6' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.00016), 173 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdet/output/train10\u001b[0m\n",
      "Starting training for 500 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/project/EoC/code/det/ultralytics/nn/modules/block.py:917: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:233.)\n",
      "  attn = (q.transpose(-2, -1) @ k) * self.scale\n",
      "/home/ubuntu/project/EoC/code/det/ultralytics/nn/modules/block.py:919: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:233.)\n",
      "  x = (v @ attn.transpose(-2, -1)).view(B, C, H, W) + self.pe(v.reshape(B, C, H, W))\n",
      "/home/ubuntu/project/EoC/code/det/ultralytics/utils/loss.py:201: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:233.)\n",
      "  pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
      "/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/torch/autograd/graph.py:824: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:233.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      1/500      3.49G     0.7763      1.099     0.9851         46        640:  55%|█████▍    | 8845/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11l.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel info: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdet/TomatoMAP-Det.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdet/output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdet/best_hyperparameters.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# fine-tuned hyperparameters, ready to use, details please contact us per email\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#profile=True,\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/engine/model.py:808\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 808\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/engine/trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/engine/trainer.py:381\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[1;32m    380\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/nn/tasks.py:110\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/nn/tasks.py:291\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[0;32m--> 291\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(preds, batch)\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/nn/tasks.py:111\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/nn/tasks.py:129\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/nn/tasks.py:150\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 150\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    151\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/nn/modules/block.py:239\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 239\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/nn/modules/block.py:239\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 239\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/nn/modules/block.py:264\u001b[0m, in \u001b[0;36mC3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through the CSP bottleneck with 2 convolutions.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv3(torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(x)), \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/nn/modules/block.py:348\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x))\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/project/EoC/code/det/ultralytics/nn/modules/conv.py:51\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.use_deterministic_algorithms(False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TomatoMAP-Det Trainer\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "print(\"downloading pretrained model: \")\n",
    "\n",
    "model = YOLO(\"yolo11l.pt\")\n",
    "\n",
    "print(\"model info: \")\n",
    "\n",
    "train_result = model.train(\n",
    "    data=\"det/TomatoMAP-Det.yaml\",\n",
    "    epochs=500,\n",
    "    imgsz=640,\n",
    "    device=[0],\n",
    "    batch=4,\n",
    "    patience=10,\n",
    "    project=\"det/output\",\n",
    "    cfg=\"det/best_hyperparameters.yaml\", # fine-tuned hyperparameters, ready to use, details please contact us per email\n",
    "    #profile=True,\n",
    "    plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c9228d-dc78-42af-8b78-7a41685f25b5",
   "metadata": {},
   "source": [
    "# TomatoMAP-Seg Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9f46fe-5dea-4098-9ac0-20249a648788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detectron2 version: 0.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Detectron2\n",
    "import detectron2\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor, HookBase\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import MetadataCatalog, build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.events import get_event_storage\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "print(f\"  Detectron2 version: {detectron2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce474b7-4d66-4a5a-957b-475a14a237b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_segmentation(points):\n",
    "    #format points [[x,y],[x,y]] to [x1,y1,x2,y2,...]\n",
    "    return [coord for pair in points for coord in pair]\n",
    "\n",
    "def load_categories_from_yaml(yaml_path):\n",
    "    with open(yaml_path, 'r', encoding='utf-8') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    categories = []\n",
    "    cat_map = {}\n",
    "    cat_id = 1\n",
    "    for item in data['label']:\n",
    "        name = item['name']\n",
    "        if name == '__background__':\n",
    "            continue\n",
    "        categories.append({\n",
    "            \"id\": cat_id,\n",
    "            \"name\": name,\n",
    "            \"supercategory\": \"none\"\n",
    "        })\n",
    "        cat_map[name] = cat_id\n",
    "        cat_id += 1\n",
    "    return categories, cat_map\n",
    "\n",
    "def convert_isat_folder_to_coco(task_dir, label_dir, yaml_path, output_dir, train_ratio=0.7, val_ratio=0.2):\n",
    "    print(\"ISAT2COCO...\")\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    categories, category_map = load_categories_from_yaml(yaml_path)\n",
    "    print(f\"loaded {len(categories)} classes\")\n",
    "\n",
    "    if not os.path.exists(task_dir):\n",
    "        print(f\"image folder not exist: {task_dir}\")\n",
    "        return False\n",
    "    \n",
    "    if not os.path.exists(label_dir):\n",
    "        print(f\"label folder not exist: {label_dir}\")\n",
    "        return False\n",
    "\n",
    "    images = [f for f in os.listdir(task_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "    json_map = {os.path.splitext(f)[0]: f for f in os.listdir(label_dir) if f.endswith(\".json\")}\n",
    "\n",
    "    print(f\"found {len(images)} images\")\n",
    "    print(f\"found {len(json_map)} labels\")\n",
    "\n",
    "    # matching image and labels\n",
    "    dataset = []\n",
    "    unmatched_images = []\n",
    "    \n",
    "    for img_name in tqdm(images, desc=\"matching image and labels\"):\n",
    "        base = os.path.splitext(img_name)[0]\n",
    "        if base in json_map:\n",
    "            dataset.append({\n",
    "                \"img_file\": img_name,\n",
    "                \"json_file\": json_map[base]\n",
    "            })\n",
    "        else:\n",
    "            unmatched_images.append(img_name)\n",
    "\n",
    "    print(f\"successfully matches {len(dataset)} pairs\")\n",
    "    if unmatched_images:\n",
    "        print(f\" {len(unmatched_images)} unmatches images\")\n",
    "\n",
    "    if len(dataset) == 0:\n",
    "        print(\"no matched pairs\")\n",
    "        return False\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "    total = len(dataset)\n",
    "    train_end = int(total * train_ratio)\n",
    "    val_end = int(total * (train_ratio + val_ratio))\n",
    "\n",
    "    splits = {\n",
    "        \"train\": dataset[:train_end],\n",
    "        \"val\": dataset[train_end:val_end],\n",
    "        \"test\": dataset[val_end:]\n",
    "    }\n",
    "\n",
    "    print(f\"\\n spilting dataset:\")\n",
    "    for split_name, split_data in splits.items():\n",
    "        print(f\"  {split_name}: {len(split_data)} iamges ({len(split_data)/total*100:.1f}%)\")\n",
    "\n",
    "    conversion_stats = {}\n",
    "    \n",
    "    for split_name, split_data in splits.items():\n",
    "        if len(split_data) == 0:\n",
    "            print(f\" {split_name} dataset empty, skipping\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n transforming {split_name} dataset.\")\n",
    "        \n",
    "        coco = {\n",
    "            \"images\": [],\n",
    "            \"annotations\": [],\n",
    "            \"categories\": categories\n",
    "        }\n",
    "        ann_id = 1\n",
    "        img_id = 1\n",
    "        \n",
    "        processed_annotations = 0\n",
    "        skipped_annotations = 0\n",
    "\n",
    "        for item in tqdm(split_data, desc=f\"processing {split_name}\"):\n",
    "            img_path = os.path.join(task_dir, item[\"img_file\"])\n",
    "            json_path = os.path.join(label_dir, item[\"json_file\"])\n",
    "\n",
    "            if not os.path.exists(json_path):\n",
    "                print(f\" label files not exist: {json_path}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    isat = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"failed to load label file {json_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            info = isat['info']\n",
    "            coco[\"images\"].append({\n",
    "                \"file_name\": item[\"img_file\"],\n",
    "                \"id\": img_id,\n",
    "                \"width\": info[\"width\"],\n",
    "                \"height\": info[\"height\"]\n",
    "            })\n",
    "\n",
    "            for obj in isat.get('objects', []):\n",
    "                cat = obj['category']\n",
    "                if cat not in category_map:\n",
    "                    skipped_annotations += 1\n",
    "                    continue\n",
    "\n",
    "                seg_flat = flatten_segmentation(obj[\"segmentation\"])\n",
    "                if len(seg_flat) < 6:\n",
    "                    skipped_annotations += 1\n",
    "                    continue\n",
    "\n",
    "                coco[\"annotations\"].append({\n",
    "                    \"id\": ann_id,\n",
    "                    \"image_id\": img_id,\n",
    "                    \"category_id\": category_map[cat],\n",
    "                    \"segmentation\": [seg_flat],\n",
    "                    \"bbox\": obj[\"bbox\"],\n",
    "                    \"area\": obj[\"area\"],\n",
    "                    \"iscrowd\": obj.get(\"iscrowd\", 0),\n",
    "                    \"group_id\": obj.get(\"group\", None)\n",
    "                })\n",
    "                ann_id += 1\n",
    "                processed_annotations += 1\n",
    "                \n",
    "            img_id += 1\n",
    "\n",
    "        output_file = os.path.join(output_dir, f\"{split_name}.json\")\n",
    "        with open(output_file, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(coco, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        conversion_stats[split_name] = {\n",
    "            'images': len(split_data),\n",
    "            'annotations': processed_annotations,\n",
    "            'skipped': skipped_annotations\n",
    "        }\n",
    "\n",
    "        print(f\"  generated {split_name}.json\")\n",
    "        print(f\"     images: {len(split_data)}\")\n",
    "        print(f\"     labels: {processed_annotations}\")\n",
    "        print(f\"     skipped: {skipped_annotations}\")\n",
    "\n",
    "    print(f\"\\n ISAT2COCO finished\")\n",
    "    print(f\" output at: {output_dir}\")\n",
    "    print(f\" transform info:\")\n",
    "    \n",
    "    total_images = sum(stats['images'] for stats in conversion_stats.values())\n",
    "    total_annotations = sum(stats['annotations'] for stats in conversion_stats.values())\n",
    "    total_skipped = sum(stats['skipped'] for stats in conversion_stats.values())\n",
    "    \n",
    "    print(f\"  total images: {total_images}\")\n",
    "    print(f\"  total labels: {total_annotations}\")\n",
    "    print(f\"  skipped labels: {total_skipped}\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15c7807-6686-49b8-8c2b-c9fc5a960936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations:\n",
      "ISAT converter config:\n",
      "  task_dir: TomatoMAP/TomatoMAP-Seg/images\n",
      "  label_dir: TomatoMAP/TomatoMAP-Seg/labels\n",
      "  yaml_path: TomatoMAP/TomatoMAP-Seg/labels/isat.yaml\n",
      "  output_dir: TomatoMAP/TomatoMAP-Seg/cocoOut\n",
      "  train_ratio: 0.7\n",
      "  val_ratio: 0.2\n",
      "  auto_convert: True\n",
      "\n",
      " dataset config:\n",
      "  dataset_root: TomatoMAP/TomatoMAP-Seg/\n",
      "  img_dir: TomatoMAP/TomatoMAP-Seg/images\n",
      "  coco_ann_dir: TomatoMAP/TomatoMAP-Seg/cocoOut\n",
      "  isat_yaml_path: TomatoMAP/TomatoMAP-Seg/labels/isat.yaml\n",
      "  output_dir: TomatoMAP/TomatoMAP-Seg/output\n",
      "  num_classes: 10\n",
      "\n",
      " training config:\n",
      "  model_name: mask_rcnn_R_50_FPN_1x\n",
      "  batch_size: 4\n",
      "  base_lr: 0.00024\n",
      "  max_epochs: 100\n",
      "  patience: 15\n",
      "  num_workers: 8\n",
      "  score_thresh_test: 0.3\n",
      "  input_min_size_train: (640, 672, 704, 736, 768, 800)\n",
      "  input_max_size_train: 1333\n",
      "  checkpoint_period: 10\n",
      "  eval_period: 10\n"
     ]
    }
   ],
   "source": [
    "ISAT_CONFIG = {\n",
    "    'task_dir': \"TomatoMAP/TomatoMAP-Seg/images\",\n",
    "    'label_dir': \"TomatoMAP/TomatoMAP-Seg/labels\",\n",
    "    'yaml_path': \"TomatoMAP/TomatoMAP-Seg/labels/isat.yaml\",\n",
    "    'output_dir': \"TomatoMAP/TomatoMAP-Seg/cocoOut\",\n",
    "    'train_ratio': 0.7,\n",
    "    'val_ratio': 0.2,    # rest 0.1 is test\n",
    "    'auto_convert': True\n",
    "}\n",
    "\n",
    "DATASET_CONFIG = {\n",
    "    'dataset_root': \"TomatoMAP/TomatoMAP-Seg/\",\n",
    "    'img_dir': \"TomatoMAP/TomatoMAP-Seg/images\",\n",
    "    'coco_ann_dir': \"TomatoMAP/TomatoMAP-Seg/cocoOut\",\n",
    "    'isat_yaml_path': \"TomatoMAP/TomatoMAP-Seg/labels/isat.yaml\",\n",
    "    'output_dir': \"TomatoMAP/TomatoMAP-Seg/output\",\n",
    "    'num_classes': 10,    # without background\n",
    "}\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    'model_name': \"mask_rcnn_R_50_FPN_1x\",\n",
    "    'batch_size': 4,\n",
    "    'base_lr': 0.00024,\n",
    "    'max_epochs': 100,\n",
    "    'patience': 15,\n",
    "    'num_workers': 8,  # Windows user please set to 0\n",
    "    'score_thresh_test': 0.3,\n",
    "    'input_min_size_train': (640, 672, 704, 736, 768, 800), \n",
    "    'input_max_size_train': 1333,\n",
    "    'checkpoint_period': 10,\n",
    "    'eval_period': 10,\n",
    "}\n",
    "\n",
    "print(\"Configurations:\")\n",
    "print(\"ISAT converter config:\")\n",
    "for key, value in ISAT_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"\\n dataset config:\")\n",
    "for key, value in DATASET_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"\\n training config:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb7b82da-fe47-4535-b599-7fe5551181a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ISAT coverting to COCO format\n",
      "============================================================\n",
      "ISAT checked, start converting...\n",
      "ISAT2COCO...\n",
      "loaded 10 classes\n",
      "found 3612 images\n",
      "found 727 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "matching image and labels: 100%|██████████████████████████████| 3612/3612 [00:00<00:00, 804173.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully matches 727 pairs\n",
      " 2885 unmatches images\n",
      "\n",
      " spilting dataset:\n",
      "  train: 508 iamges (69.9%)\n",
      "  val: 146 iamges (20.1%)\n",
      "  test: 73 iamges (10.0%)\n",
      "\n",
      " transforming train dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing train: 100%|████████████████████████████████████████████| 508/508 [00:01<00:00, 309.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  generated train.json\n",
      "     images: 508\n",
      "     labels: 4592\n",
      "     skipped: 0\n",
      "\n",
      " transforming val dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing val: 100%|██████████████████████████████████████████████| 146/146 [00:00<00:00, 330.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  generated val.json\n",
      "     images: 146\n",
      "     labels: 1276\n",
      "     skipped: 0\n",
      "\n",
      " transforming test dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing test: 100%|███████████████████████████████████████████████| 73/73 [00:00<00:00, 738.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  generated test.json\n",
      "     images: 73\n",
      "     labels: 645\n",
      "     skipped: 0\n",
      "\n",
      " ISAT2COCO finished\n",
      " output at: TomatoMAP/TomatoMAP-Seg/cocoOut\n",
      " transform info:\n",
      "  total images: 727\n",
      "  total labels: 6513\n",
      "  skipped labels: 0\n",
      "\n",
      " Configuration of dataset is updated:\n",
      "   image path: TomatoMAP/TomatoMAP-Seg/images\n",
      "   label path: TomatoMAP/TomatoMAP-Seg/cocoOut\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ISAT coverting to COCO format\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "need_conversion = ISAT_CONFIG['auto_convert']\n",
    "\n",
    "coco_files_exist = all(\n",
    "    os.path.exists(os.path.join(ISAT_CONFIG['output_dir'], f\"{split}.json\"))\n",
    "    for split in ['train', 'val', 'test']\n",
    ")\n",
    "\n",
    "if coco_files_exist and not need_conversion:\n",
    "    print(\"coco format exist, skipping!\")\n",
    "    print(\"   if wanna reconvert, set ISAT_CONFIG['auto_convert'] = True\")\n",
    "else:\n",
    "    required_isat_paths = [\n",
    "        ISAT_CONFIG['task_dir'],\n",
    "        ISAT_CONFIG['label_dir'], \n",
    "        ISAT_CONFIG['yaml_path']\n",
    "    ]\n",
    "    \n",
    "    missing_paths = [path for path in required_isat_paths if not os.path.exists(path)]\n",
    "    \n",
    "    if missing_paths:\n",
    "        print(\"following ISAT path not exist:\")\n",
    "        for path in missing_paths:\n",
    "            print(f\"   {path}\")\n",
    "        print(\"\\nplease check ISAT_CONFIG path setting\")\n",
    "        conversion_success = False\n",
    "    else:\n",
    "        print(\"ISAT checked, start converting...\")\n",
    "        \n",
    "        conversion_success = convert_isat_folder_to_coco(\n",
    "            task_dir=ISAT_CONFIG['task_dir'],\n",
    "            label_dir=ISAT_CONFIG['label_dir'],\n",
    "            yaml_path=ISAT_CONFIG['yaml_path'],\n",
    "            output_dir=ISAT_CONFIG['output_dir'],\n",
    "            train_ratio=ISAT_CONFIG['train_ratio'],\n",
    "            val_ratio=ISAT_CONFIG['val_ratio']\n",
    "        )\n",
    "\n",
    "if 'conversion_success' not in locals():\n",
    "    conversion_success = True\n",
    "\n",
    "if conversion_success:\n",
    "    DATASET_CONFIG['coco_ann_dir'] = ISAT_CONFIG['output_dir']\n",
    "    DATASET_CONFIG['img_dir'] = ISAT_CONFIG['task_dir'] \n",
    "    DATASET_CONFIG['isat_yaml_path'] = ISAT_CONFIG['yaml_path']\n",
    "    print(f\"\\n Configuration of dataset is updated:\")\n",
    "    print(f\"   image path: {DATASET_CONFIG['img_dir']}\")\n",
    "    print(f\"   label path: {DATASET_CONFIG['coco_ann_dir']}\")\n",
    "else:\n",
    "    print(\"\\n Transfer failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e72146-ee66-4937-a2c8-6949de40cc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TomatoMAP-Seg info:\n",
      "========================================\n",
      "train: 508 images, 4592 labels\n",
      "val: 146 images, 1276 labels\n",
      "test: 73 images, 645 labels\n",
      "\n",
      " analyze dataset object areas...\n",
      "============================================================\n",
      "\n",
      "TRAIN dataset analysis:\n",
      "----------------------------------------\n",
      "average size: 3648 x 5472\n",
      "total object amount: 4592\n",
      "\n",
      " original object image size distribution:\n",
      "  small object (<32²): 97 (2.1%)\n",
      "  mid object (32²-96²): 517 (11.3%)\n",
      "  big object (>96²): 3978 (86.6%)\n",
      "  min area: 2 pixel²\n",
      "  max area: 5373098 pixel²\n",
      "  mean area: 352411 pixel²\n",
      "\n",
      "scaled to 640-1333 :\n",
      "  small object (<32²): 1005 (21.9%)\n",
      "  mid object (32²-96²): 2095 (45.6%)\n",
      "  big object (>96²): 1492 (32.5%)\n",
      "\n",
      "VAL dataset analysis:\n",
      "----------------------------------------\n",
      "average size: 3648 x 5472\n",
      "total object amount: 1276\n",
      "\n",
      " original object image size distribution:\n",
      "  small object (<32²): 18 (1.4%)\n",
      "  mid object (32²-96²): 155 (12.1%)\n",
      "  big object (>96²): 1103 (86.4%)\n",
      "  min area: 6 pixel²\n",
      "  max area: 5199393 pixel²\n",
      "  mean area: 342357 pixel²\n",
      "\n",
      "scaled to 640-1333 :\n",
      "  small object (<32²): 266 (20.8%)\n",
      "  mid object (32²-96²): 636 (49.8%)\n",
      "  big object (>96²): 374 (29.3%)\n",
      "\n",
      "TEST dataset analysis:\n",
      "----------------------------------------\n",
      "average size: 3648 x 5472\n",
      "total object amount: 645\n",
      "\n",
      " original object image size distribution:\n",
      "  small object (<32²): 15 (2.3%)\n",
      "  mid object (32²-96²): 56 (8.7%)\n",
      "  big object (>96²): 574 (89.0%)\n",
      "  min area: 6 pixel²\n",
      "  max area: 4568398 pixel²\n",
      "  mean area: 348066 pixel²\n",
      "\n",
      "scaled to 640-1333 :\n",
      "  small object (<32²): 133 (20.6%)\n",
      "  mid object (32²-96²): 322 (49.9%)\n",
      "  big object (>96²): 190 (29.5%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_dataset_areas():\n",
    "    print(f\"\\n analyze dataset object areas...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        ann_file = os.path.join(DATASET_CONFIG['coco_ann_dir'], f\"{split}.json\")\n",
    "        if not os.path.exists(ann_file):\n",
    "            print(f\"label file {ann_file} not exist\")\n",
    "            continue\n",
    "            \n",
    "        with open(ann_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        image_info = {img['id']: img for img in data['images']}\n",
    "        \n",
    "        areas_original = []\n",
    "        areas_scaled = []\n",
    "        \n",
    "        min_size = min(TRAINING_CONFIG['input_min_size_train'])\n",
    "        max_size = TRAINING_CONFIG['input_max_size_train']\n",
    "        \n",
    "        for ann in data['annotations']:\n",
    "            if 'area' in ann:\n",
    "                area = ann['area']\n",
    "            else:\n",
    "                bbox = ann.get('bbox', [0, 0, 0, 0])\n",
    "                area = bbox[2] * bbox[3]\n",
    "            areas_original.append(area)\n",
    "            \n",
    "            img_id = ann['image_id']\n",
    "            if img_id in image_info:\n",
    "                img = image_info[img_id]\n",
    "                orig_w, orig_h = img['width'], img['height']\n",
    "                \n",
    "                size = max(orig_w, orig_h)\n",
    "                if size > max_size:\n",
    "                    scale = max_size / size\n",
    "                else:\n",
    "                    scale = min_size / min(orig_w, orig_h)\n",
    "                    if scale * size > max_size:\n",
    "                        scale = max_size / size\n",
    "                \n",
    "                scaled_area = area * (scale ** 2)\n",
    "                areas_scaled.append(scaled_area)\n",
    "        \n",
    "        areas_original = np.array(areas_original)\n",
    "        areas_scaled = np.array(areas_scaled) if areas_scaled else areas_original\n",
    "        \n",
    "        print(f\"\\n{split.upper()} dataset analysis:\")\n",
    "        print(f\"-\" * 40)\n",
    "        \n",
    "        if len(data['images']) > 0:\n",
    "            avg_width = np.mean([img['width'] for img in data['images']])\n",
    "            avg_height = np.mean([img['height'] for img in data['images']])\n",
    "            print(f\"average size: {avg_width:.0f} x {avg_height:.0f}\")\n",
    "        \n",
    "        print(f\"total object amount: {len(areas_original)}\")\n",
    "        \n",
    "        print(f\"\\n original object image size distribution:\")\n",
    "        small_orig = np.sum(areas_original < 32**2)\n",
    "        medium_orig = np.sum((areas_original >= 32**2) & (areas_original < 96**2))\n",
    "        large_orig = np.sum(areas_original >= 96**2)\n",
    "        \n",
    "        print(f\"  small object (<32²): {small_orig} ({small_orig/len(areas_original)*100:.1f}%)\")\n",
    "        print(f\"  mid object (32²-96²): {medium_orig} ({medium_orig/len(areas_original)*100:.1f}%)\")\n",
    "        print(f\"  big object (>96²): {large_orig} ({large_orig/len(areas_original)*100:.1f}%)\")\n",
    "        print(f\"  min area: {np.min(areas_original):.0f} pixel²\")\n",
    "        print(f\"  max area: {np.max(areas_original):.0f} pixel²\")\n",
    "        print(f\"  mean area: {np.mean(areas_original):.0f} pixel²\")\n",
    "        \n",
    "        print(f\"\\nscaled to {min_size}-{max_size} :\")\n",
    "        small_scaled = np.sum(areas_scaled < 32**2)\n",
    "        medium_scaled = np.sum((areas_scaled >= 32**2) & (areas_scaled < 96**2))\n",
    "        large_scaled = np.sum(areas_scaled >= 96**2)\n",
    "        \n",
    "        print(f\"  small object (<32²): {small_scaled} ({small_scaled/len(areas_scaled)*100:.1f}%)\")\n",
    "        print(f\"  mid object (32²-96²): {medium_scaled} ({medium_scaled/len(areas_scaled)*100:.1f}%)\")\n",
    "        print(f\"  big object (>96²): {large_scaled} ({large_scaled/len(areas_scaled)*100:.1f}%)\")\n",
    "        \n",
    "        if small_scaled == 0:\n",
    "            print(f\"\\n after scale, no small object - APs set to -1\")\n",
    "        if medium_scaled == 0:\n",
    "            print(f\" after scale, no mid object - APm set to -1\")\n",
    "        if large_scaled == 0:\n",
    "            print(f\" after scale, no big object - APl set to -1\")\n",
    "\n",
    "def get_dataset_info():\n",
    "    print(f\"\\n TomatoMAP-Seg info:\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        ann_file = os.path.join(DATASET_CONFIG['coco_ann_dir'], f\"{split}.json\")\n",
    "        if os.path.exists(ann_file):\n",
    "            with open(ann_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            print(f\"{split}: {len(data['images'])} images, {len(data['annotations'])} labels\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "if conversion_success:\n",
    "    get_dataset_info()\n",
    "    analyze_dataset_areas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ca5eb8-9ece-4fdc-8240-54e8df7b7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestModelHook(HookBase):\n",
    "    # hook to save the best model based on validation segmentation mAP\n",
    "    \n",
    "    def __init__(self, cfg, eval_period, patience=10):\n",
    "        self.cfg = cfg.clone()\n",
    "        self.eval_period = eval_period\n",
    "        self.patience = patience\n",
    "        self.best_score = 0\n",
    "        self.best_metric_name = None\n",
    "        self.best_epoch = -1\n",
    "        self.epochs_without_improvement = 0\n",
    "        self.should_stop = False\n",
    "        self.history = []\n",
    "        \n",
    "    def get_valid_score(self, segm_results):\n",
    "        priority_metrics = [\"AP\", \"AP50\", \"AP75\", \"APm\", \"APl\"]\n",
    "        \n",
    "        for metric in priority_metrics:\n",
    "            value = segm_results.get(metric, -1)\n",
    "            if value != -1:\n",
    "                return metric, value\n",
    "        \n",
    "        return None, None\n",
    "    \n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        is_final_iter = next_iter == self.trainer.max_iter\n",
    "        \n",
    "        if (next_iter % self.eval_period == 0 and not is_final_iter):\n",
    "            current_epoch = (next_iter // self.eval_period)\n",
    "            \n",
    "            results = self._do_eval()\n",
    "            if results is None:\n",
    "                print(f\"Epoch {current_epoch}: evaluate failed\")\n",
    "                return\n",
    "            \n",
    "            segm_results = results.get(\"segm\", {})\n",
    "            bbox_results = results.get(\"bbox\", {})\n",
    "            \n",
    "            metric_name, current_score = self.get_valid_score(segm_results)\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Epoch {current_epoch} evaluate result:\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            print(\"\\n bbox metrics:\")\n",
    "            for key in [\"AP\", \"AP50\", \"AP75\", \"APs\", \"APm\", \"APl\"]:\n",
    "                value = bbox_results.get(key, -1)\n",
    "                if value != -1:\n",
    "                    print(f\"  {key}: {value:.4f} ✓\")\n",
    "                else:\n",
    "                    print(f\"  {key}: N/A\")\n",
    "            \n",
    "            print(\"\\n seg metrics:\")\n",
    "            for key in [\"AP\", \"AP50\", \"AP75\", \"APs\", \"APm\", \"APl\"]:\n",
    "                value = segm_results.get(key, -1)\n",
    "                if value != -1:\n",
    "                    print(f\"  {key}: {value:.4f} ✓\")\n",
    "                else:\n",
    "                    print(f\"  {key}: N/A (no object for this class)\")\n",
    "            \n",
    "            if metric_name is None:\n",
    "                print(\"\\n waring! no useful metrics\")\n",
    "                print(\"please check TomatoMAP-Seg structure\")\n",
    "\n",
    "                metric_name, current_score = self.get_valid_score(bbox_results)\n",
    "                if metric_name is not None:\n",
    "                    print(f\"using bbox metric: {metric_name} = {current_score:.4f}\")\n",
    "                else:\n",
    "                    return\n",
    "            \n",
    "            print(f\"\\n main metrics: {metric_name} = {current_score:.4f}\")\n",
    "            \n",
    "            self.history.append({\n",
    "                'epoch': current_epoch,\n",
    "                'metric': metric_name,\n",
    "                'score': current_score,\n",
    "                'all_metrics': {**segm_results, **{'bbox_' + k: v for k, v in bbox_results.items()}}\n",
    "            })\n",
    "            \n",
    "            if current_score > self.best_score:\n",
    "                improvement = current_score - self.best_score\n",
    "                self.best_score = current_score\n",
    "                self.best_metric_name = metric_name\n",
    "                self.best_epoch = current_epoch\n",
    "                self.epochs_without_improvement = 0\n",
    "                \n",
    "                self.trainer.checkpointer.save(\"model_best\")\n",
    "                print(f\"\\n best model saved\")\n",
    "                print(f\"   score: {current_score:.4f} (↑{improvement:.4f})\")\n",
    "                \n",
    "                best_results_file = os.path.join(self.cfg.OUTPUT_DIR, \"best_results.json\")\n",
    "                with open(best_results_file, 'w') as f:\n",
    "                    json.dump({\n",
    "                        'epoch': current_epoch,\n",
    "                        'metric': metric_name,\n",
    "                        'score': current_score,\n",
    "                        'segm_results': segm_results,\n",
    "                        'bbox_results': bbox_results\n",
    "                    }, f, indent=2)\n",
    "            else:\n",
    "                self.epochs_without_improvement += 1\n",
    "                gap = self.best_score - current_score\n",
    "                print(f\"\\ncurrent: {current_score:.4f} | best: {self.best_score:.4f} (gap: {gap:.4f})\")\n",
    "                print(f\"continuted {self.epochs_without_improvement}/{self.patience} epoch no improve\")\n",
    "            \n",
    "            if self.epochs_without_improvement >= self.patience:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"early stop triggered\")\n",
    "                print(f\"   best {self.best_metric_name}: {self.best_score:.4f} (epoch {self.best_epoch})\")\n",
    "                print(f\"   total epochs: {current_epoch}\")\n",
    "                print(f\"{'='*60}\")\n",
    "                self.should_stop = True\n",
    "\n",
    "                self.trainer.storage._iter = self.trainer.max_iter\n",
    "    \n",
    "    def _do_eval(self):\n",
    "\n",
    "        try:\n",
    "            evaluator = COCOEvaluator(\"tomato_val\", self.cfg, False, \n",
    "                                    output_dir=os.path.join(self.cfg.OUTPUT_DIR, \"inference\"))\n",
    "            val_loader = build_detection_test_loader(self.cfg, \"tomato_val\")\n",
    "            results = inference_on_dataset(self.trainer.model, val_loader, evaluator)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"evaluate failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    def __init__(self, cfg, patience=None):\n",
    "        self.patience = patience if patience is not None else TRAINING_CONFIG['patience']\n",
    "        super().__init__(cfg)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(\n",
    "            dataset_name=dataset_name,\n",
    "            distributed=False,\n",
    "            output_dir=output_folder,\n",
    "            use_fast_impl=True,\n",
    "            tasks=(\"bbox\", \"segm\"),\n",
    "        )\n",
    "    \n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        \n",
    "        try:\n",
    "            train_loader = build_detection_train_loader(self.cfg)\n",
    "            iters_per_epoch = len(train_loader) // self.cfg.SOLVER.IMS_PER_BATCH\n",
    "            print(f\"iters per epoch: {iters_per_epoch}\")\n",
    "        except:\n",
    "            iters_per_epoch = 106\n",
    "            print(f\"iters per epoch: {iters_per_epoch}\")\n",
    "        \n",
    "        eval_period = iters_per_epoch * TRAINING_CONFIG['eval_period']\n",
    "        \n",
    "        best_model_hook = BestModelHook(self.cfg, eval_period, self.patience)\n",
    "        hooks.append(best_model_hook)\n",
    "        \n",
    "        self.best_model_hook = best_model_hook\n",
    "        \n",
    "        return hooks\n",
    "    \n",
    "    def run_step(self):\n",
    "        super().run_step()\n",
    "        \n",
    "        if hasattr(self, 'best_model_hook') and self.best_model_hook.should_stop:\n",
    "            print(\"early stop triggered, training stop\")\n",
    "            self.storage._iter = self.max_iter\n",
    "    \n",
    "    def train(self):\n",
    "        super().train()\n",
    "        \n",
    "        if hasattr(self, 'best_model_hook'):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"training info:\")\n",
    "            print(f\"{'='*60}\")\n",
    "            if self.best_model_hook.best_score > 0:\n",
    "                print(f\"best {self.best_model_hook.best_metric_name}: {self.best_model_hook.best_score:.4f}\")\n",
    "                print(f\"best epoch: {self.best_model_hook.best_epoch}\")\n",
    "                print(f\"best model saved as: model_best.pth\")\n",
    "            else:\n",
    "                print(\"no metrics found for training\")\n",
    "            \n",
    "            history_file = os.path.join(self.cfg.OUTPUT_DIR, \"training_history.json\")\n",
    "            with open(history_file, 'w') as f:\n",
    "                json.dump(self.best_model_hook.history, f, indent=2)\n",
    "            print(f\"training log saved at: {history_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f48af04-6a2d-4ee7-8647-53efb20c376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TomatoMAP-Seg Registeration\n",
      "============================================================\n",
      "register dataset\n",
      "loading label classes: 10 classes\n",
      "  0: nascent\n",
      "  1: mini\n",
      "  2: unripe green tomato\n",
      "  3: semi ripe\n",
      "  4: fully ripe\n",
      "  5: 2mm\n",
      "  6: 4mm\n",
      "  7: 6mm\n",
      "  8: 8mm\n",
      "  9: 12mm\n",
      "  registered tomato_train\n",
      "  registered tomato_val\n",
      "  registered tomato_test\n",
      "TomatoMAP-Seg is registered\n",
      "building configed\n",
      "Configuration:\n",
      "  model: mask_rcnn_R_50_FPN_1x\n",
      "  class num: 10\n",
      "  batch size: 4\n",
      "  lr: 0.00024\n",
      "  max epoch: 100\n",
      "  patience: 15\n",
      "  imput size: 640-1333\n",
      "  output path: TomatoMAP/TomatoMAP-Seg/output\n",
      "  device: cuda\n"
     ]
    }
   ],
   "source": [
    "def register_all_datasets():\n",
    "    print(\"register dataset\")\n",
    "    \n",
    "    try:\n",
    "        with open(DATASET_CONFIG['isat_yaml_path'], 'r', encoding='utf-8') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        labels = [item['name'] for item in data['label'] if item['name'] != '__background__']\n",
    "        print(f\"loading label classes: {len(labels)} classes\")\n",
    "        for i, label in enumerate(labels):\n",
    "            print(f\"  {i}: {label}\")\n",
    "    except Exception as e:\n",
    "        print(f\"class label loading failed: {e}\")\n",
    "        return None\n",
    "    \n",
    "    datasets = ['train', 'val', 'test']\n",
    "    \n",
    "    for dataset_name in datasets:\n",
    "        dataset_key = f\"tomato_{dataset_name}\"\n",
    "        \n",
    "        try:\n",
    "            from detectron2.data.datasets.coco import _PREDEFINED_SPLITS_COCO\n",
    "            if dataset_key in _PREDEFINED_SPLITS_COCO:\n",
    "                del _PREDEFINED_SPLITS_COCO[dataset_key]\n",
    "        except ImportError:\n",
    "            try:\n",
    "                from detectron2.data.datasets.builtin import _PREDEFINED_SPLITS_COCO\n",
    "                if dataset_key in _PREDEFINED_SPLITS_COCO:\n",
    "                    del _PREDEFINED_SPLITS_COCO[dataset_key]\n",
    "            except ImportError:\n",
    "                try:\n",
    "                    from detectron2.data.datasets.register_coco import _PREDEFINED_SPLITS_COCO\n",
    "                    if dataset_key in _PREDEFINED_SPLITS_COCO:\n",
    "                        del _PREDEFINED_SPLITS_COCO[dataset_key]\n",
    "                except ImportError:\n",
    "                    print(f\"  can't clean {dataset_key} version cap)\")\n",
    "        \n",
    "        try:\n",
    "            if MetadataCatalog.has(dataset_key):\n",
    "                MetadataCatalog.remove(dataset_key)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for dataset_name in datasets:\n",
    "        coco_json = os.path.join(DATASET_CONFIG['coco_ann_dir'], f\"{dataset_name}.json\")\n",
    "        dataset_key = f\"tomato_{dataset_name}\"\n",
    "        \n",
    "        if os.path.exists(coco_json):\n",
    "            abs_coco_json = os.path.abspath(coco_json)\n",
    "            abs_img_dir = os.path.abspath(DATASET_CONFIG['img_dir'])\n",
    "            \n",
    "            try:\n",
    "                register_coco_instances(\n",
    "                    dataset_key, \n",
    "                    {}, \n",
    "                    abs_coco_json, \n",
    "                    abs_img_dir\n",
    "                )\n",
    "                MetadataCatalog.get(dataset_key).thing_classes = labels\n",
    "                print(f\"  registered {dataset_key}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  register failed: {e}\")\n",
    "                try:\n",
    "                    MetadataCatalog.get(dataset_key).thing_classes = labels\n",
    "                    print(f\"  re-setting {dataset_key} meta data\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"  meta setting failed: {e2}\")\n",
    "        else:\n",
    "            print(f\"  can't find {coco_json}\")\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def build_cfg():\n",
    "    cfg = get_cfg()\n",
    "    \n",
    "    model_config_file = f\"COCO-InstanceSegmentation/{TRAINING_CONFIG['model_name']}.yaml\"\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(model_config_file))\n",
    "    \n",
    "    cfg.DATASETS.TRAIN = (\"tomato_train\",)\n",
    "    cfg.DATASETS.TEST = (\"tomato_val\",)\n",
    "    \n",
    "    cfg.DATALOADER.NUM_WORKERS = TRAINING_CONFIG['num_workers']\n",
    "    \n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = DATASET_CONFIG['num_classes']\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_config_file)\n",
    "    \n",
    "    cfg.SOLVER.IMS_PER_BATCH = TRAINING_CONFIG['batch_size']\n",
    "    cfg.SOLVER.BASE_LR = TRAINING_CONFIG['base_lr']\n",
    "    \n",
    "    estimated_iters_per_epoch = 106\n",
    "    cfg.SOLVER.MAX_ITER = estimated_iters_per_epoch * TRAINING_CONFIG['max_epochs']\n",
    "    \n",
    "    cfg.SOLVER.STEPS = (int(cfg.SOLVER.MAX_ITER * 0.7), int(cfg.SOLVER.MAX_ITER * 0.9))\n",
    "    cfg.SOLVER.GAMMA = 0.1\n",
    "    \n",
    "    cfg.INPUT.MIN_SIZE_TRAIN = TRAINING_CONFIG['input_min_size_train']\n",
    "    cfg.INPUT.MAX_SIZE_TRAIN = TRAINING_CONFIG['input_max_size_train']\n",
    "    \n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = TRAINING_CONFIG['score_thresh_test']\n",
    "    \n",
    "    cfg.OUTPUT_DIR = DATASET_CONFIG['output_dir']\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    cfg.MODEL.DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    cfg.SOLVER.CHECKPOINT_PERIOD = estimated_iters_per_epoch * TRAINING_CONFIG['checkpoint_period']\n",
    "    \n",
    "    return cfg\n",
    "\n",
    "if conversion_success:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TomatoMAP-Seg Registeration\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    class_labels = register_all_datasets()\n",
    "    \n",
    "    if class_labels is not None:\n",
    "        print(\"TomatoMAP-Seg is registered\")\n",
    "        \n",
    "        cfg = build_cfg()\n",
    "        print(\"building configed\")\n",
    "        \n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"  model: {TRAINING_CONFIG['model_name']}\")\n",
    "        print(f\"  class num: {DATASET_CONFIG['num_classes']}\")\n",
    "        print(f\"  batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "        print(f\"  lr: {TRAINING_CONFIG['base_lr']}\")\n",
    "        print(f\"  max epoch: {TRAINING_CONFIG['max_epochs']}\")\n",
    "        print(f\"  patience: {TRAINING_CONFIG['patience']}\")\n",
    "        print(f\"  imput size: {TRAINING_CONFIG['input_min_size_train'][0]}-{TRAINING_CONFIG['input_max_size_train']}\")\n",
    "        print(f\"  output path: {cfg.OUTPUT_DIR}\")\n",
    "        print(f\"  device: {cfg.MODEL.DEVICE}\")\n",
    "    else:\n",
    "        print(\"data registeration failed\")\n",
    "        conversion_success = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c32a6e5-3c8b-4dcc-8330-90af90c680ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ready to start training\n",
      "============================================================\n",
      "Training TomatoMAP-Seg\n",
      "\u001b[32m[07/08 11:09:35 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[07/08 11:09:36 d2.data.datasets.coco]: \u001b[0mLoaded 508 images in COCO format from /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Seg/cocoOut/train.json\n",
      "\u001b[32m[07/08 11:09:36 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 506 images left.\n",
      "\u001b[32m[07/08 11:09:36 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |   category    | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:-------------:|:-------------|\n",
      "|  nascent   | 407          |    mini    | 195          | unripe gree.. | 629          |\n",
      "| semi ripe  | 269          | fully ripe | 1559         |      2mm      | 166          |\n",
      "|    4mm     | 447          |    6mm     | 468          |      8mm      | 239          |\n",
      "|    12mm    | 213          |            |              |               |              |\n",
      "|   total    | 4592         |            |              |               |              |\u001b[0m\n",
      "\u001b[32m[07/08 11:09:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/08 11:09:36 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/08 11:09:36 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/08 11:09:36 d2.data.common]: \u001b[0mSerializing 506 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/08 11:09:36 d2.data.common]: \u001b[0mSerialized dataset takes 19.13 MiB\n",
      "\u001b[32m[07/08 11:09:36 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=4\n",
      "\u001b[32m[07/08 11:09:37 d2.data.datasets.coco]: \u001b[0mLoaded 508 images in COCO format from /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Seg/cocoOut/train.json\n",
      "\u001b[32m[07/08 11:09:37 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 506 images left.\n",
      "\u001b[32m[07/08 11:09:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/08 11:09:37 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/08 11:09:37 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/08 11:09:37 d2.data.common]: \u001b[0mSerializing 506 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/08 11:09:37 d2.data.common]: \u001b[0mSerialized dataset takes 19.13 MiB\n",
      "\u001b[32m[07/08 11:09:37 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=4\n",
      "iters per epoch: 106\n",
      "\u001b[32m[07/08 11:09:37 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (10, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (10,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " training configuration:\n",
      "  model: mask_rcnn_R_50_FPN_1x\n",
      "  max epoch: 100\n",
      "  patience: 15 epochs\n",
      "  eval period: per 10 epochs\n",
      "  save check point: per 10 epochs\n",
      "  multi scale training: 640-1333\n",
      "\n",
      "============================================================\n",
      "training start\n",
      "============================================================\n",
      "\u001b[32m[07/08 11:09:37 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4314.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/08 11:09:48 d2.utils.events]: \u001b[0m eta: 1:16:49  iter: 19  total_loss: 3.945  loss_cls: 2.441  loss_box_reg: 0.527  loss_mask: 0.6923  loss_rpn_cls: 0.1606  loss_rpn_loc: 0.07952    time: 0.4440  last_time: 0.4043  data_time: 0.0820  last_data_time: 0.0090   lr: 4.7954e-06  max_mem: 4476M\n",
      "\u001b[32m[07/08 11:09:56 d2.utils.events]: \u001b[0m eta: 1:16:23  iter: 39  total_loss: 3.817  loss_cls: 2.292  loss_box_reg: 0.5398  loss_mask: 0.6907  loss_rpn_cls: 0.1619  loss_rpn_loc: 0.08303    time: 0.4410  last_time: 0.4477  data_time: 0.0201  last_data_time: 0.0100   lr: 9.5906e-06  max_mem: 4477M\n",
      "\u001b[32m[07/08 11:10:05 d2.utils.events]: \u001b[0m eta: 1:16:41  iter: 59  total_loss: 3.448  loss_cls: 1.961  loss_box_reg: 0.554  loss_mask: 0.6882  loss_rpn_cls: 0.1698  loss_rpn_loc: 0.08415    time: 0.4387  last_time: 0.4431  data_time: 0.0119  last_data_time: 0.0098   lr: 1.4386e-05  max_mem: 4477M\n",
      "\u001b[32m[07/08 11:10:14 d2.utils.events]: \u001b[0m eta: 1:16:13  iter: 79  total_loss: 3.15  loss_cls: 1.56  loss_box_reg: 0.6151  loss_mask: 0.6821  loss_rpn_cls: 0.1385  loss_rpn_loc: 0.09451    time: 0.4371  last_time: 0.4159  data_time: 0.0127  last_data_time: 0.0089   lr: 1.9181e-05  max_mem: 4477M\n",
      "\u001b[32m[07/08 11:10:23 d2.utils.events]: \u001b[0m eta: 1:16:24  iter: 99  total_loss: 2.633  loss_cls: 1.118  loss_box_reg: 0.6085  loss_mask: 0.6754  loss_rpn_cls: 0.1115  loss_rpn_loc: 0.08436    time: 0.4371  last_time: 0.4459  data_time: 0.0112  last_data_time: 0.0080   lr: 2.3976e-05  max_mem: 4477M\n",
      "\u001b[32m[07/08 11:10:32 d2.utils.events]: \u001b[0m eta: 1:16:23  iter: 119  total_loss: 2.43  loss_cls: 0.9118  loss_box_reg: 0.6456  loss_mask: 0.6662  loss_rpn_cls: 0.09856  loss_rpn_loc: 0.09845    time: 0.4407  last_time: 0.4561  data_time: 0.0140  last_data_time: 0.0171   lr: 2.8771e-05  max_mem: 4552M\n",
      "\u001b[32m[07/08 11:10:41 d2.utils.events]: \u001b[0m eta: 1:16:19  iter: 139  total_loss: 2.343  loss_cls: 0.8387  loss_box_reg: 0.6695  loss_mask: 0.6561  loss_rpn_cls: 0.0842  loss_rpn_loc: 0.08678    time: 0.4415  last_time: 0.4446  data_time: 0.0125  last_data_time: 0.0122   lr: 3.3567e-05  max_mem: 4552M\n",
      "\u001b[32m[07/08 11:10:50 d2.utils.events]: \u001b[0m eta: 1:16:34  iter: 159  total_loss: 2.272  loss_cls: 0.8221  loss_box_reg: 0.6521  loss_mask: 0.6478  loss_rpn_cls: 0.07118  loss_rpn_loc: 0.07877    time: 0.4425  last_time: 0.4676  data_time: 0.0113  last_data_time: 0.0088   lr: 3.8362e-05  max_mem: 4552M\n",
      "\u001b[32m[07/08 11:10:59 d2.utils.events]: \u001b[0m eta: 1:16:40  iter: 179  total_loss: 2.325  loss_cls: 0.8389  loss_box_reg: 0.6989  loss_mask: 0.6368  loss_rpn_cls: 0.05885  loss_rpn_loc: 0.09124    time: 0.4434  last_time: 0.4309  data_time: 0.0133  last_data_time: 0.0107   lr: 4.3157e-05  max_mem: 4640M\n",
      "\u001b[32m[07/08 11:11:07 d2.utils.events]: \u001b[0m eta: 1:16:31  iter: 199  total_loss: 2.135  loss_cls: 0.7568  loss_box_reg: 0.6422  loss_mask: 0.6249  loss_rpn_cls: 0.032  loss_rpn_loc: 0.07029    time: 0.4429  last_time: 0.4135  data_time: 0.0125  last_data_time: 0.0118   lr: 4.7952e-05  max_mem: 4640M\n",
      "\u001b[32m[07/08 11:11:16 d2.utils.events]: \u001b[0m eta: 1:16:31  iter: 219  total_loss: 2.197  loss_cls: 0.7791  loss_box_reg: 0.6701  loss_mask: 0.6136  loss_rpn_cls: 0.03523  loss_rpn_loc: 0.0673    time: 0.4438  last_time: 0.4296  data_time: 0.0131  last_data_time: 0.0099   lr: 5.2747e-05  max_mem: 4640M\n",
      "\u001b[32m[07/08 11:11:25 d2.utils.events]: \u001b[0m eta: 1:16:31  iter: 239  total_loss: 2.062  loss_cls: 0.7168  loss_box_reg: 0.647  loss_mask: 0.593  loss_rpn_cls: 0.0323  loss_rpn_loc: 0.06171    time: 0.4439  last_time: 0.4677  data_time: 0.0122  last_data_time: 0.0161   lr: 5.7543e-05  max_mem: 4640M\n",
      "\u001b[32m[07/08 11:11:34 d2.utils.events]: \u001b[0m eta: 1:16:23  iter: 259  total_loss: 2.114  loss_cls: 0.7401  loss_box_reg: 0.6819  loss_mask: 0.5703  loss_rpn_cls: 0.03387  loss_rpn_loc: 0.06223    time: 0.4437  last_time: 0.4366  data_time: 0.0128  last_data_time: 0.0111   lr: 6.2338e-05  max_mem: 4640M\n",
      "\u001b[32m[07/08 11:11:43 d2.utils.events]: \u001b[0m eta: 1:16:16  iter: 279  total_loss: 2.081  loss_cls: 0.7022  loss_box_reg: 0.6561  loss_mask: 0.5477  loss_rpn_cls: 0.03883  loss_rpn_loc: 0.07004    time: 0.4439  last_time: 0.4369  data_time: 0.0120  last_data_time: 0.0096   lr: 6.7133e-05  max_mem: 4640M\n",
      "\u001b[32m[07/08 11:11:52 d2.utils.events]: \u001b[0m eta: 1:16:07  iter: 299  total_loss: 2.061  loss_cls: 0.7337  loss_box_reg: 0.6677  loss_mask: 0.5178  loss_rpn_cls: 0.03318  loss_rpn_loc: 0.06414    time: 0.4438  last_time: 0.4127  data_time: 0.0107  last_data_time: 0.0077   lr: 7.1928e-05  max_mem: 4640M\n",
      "\u001b[32m[07/08 11:12:01 d2.utils.events]: \u001b[0m eta: 1:15:57  iter: 319  total_loss: 1.93  loss_cls: 0.7153  loss_box_reg: 0.6791  loss_mask: 0.4756  loss_rpn_cls: 0.03331  loss_rpn_loc: 0.06072    time: 0.4435  last_time: 0.4986  data_time: 0.0118  last_data_time: 0.0136   lr: 7.6723e-05  max_mem: 4640M\n",
      "\u001b[32m[07/08 11:12:10 d2.utils.events]: \u001b[0m eta: 1:15:49  iter: 339  total_loss: 1.978  loss_cls: 0.7206  loss_box_reg: 0.7289  loss_mask: 0.3995  loss_rpn_cls: 0.0329  loss_rpn_loc: 0.06406    time: 0.4448  last_time: 0.4871  data_time: 0.0162  last_data_time: 0.0087   lr: 8.1519e-05  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:12:19 d2.utils.events]: \u001b[0m eta: 1:15:48  iter: 359  total_loss: 1.945  loss_cls: 0.7263  loss_box_reg: 0.6908  loss_mask: 0.3297  loss_rpn_cls: 0.04056  loss_rpn_loc: 0.06958    time: 0.4453  last_time: 0.4185  data_time: 0.0123  last_data_time: 0.0165   lr: 8.6314e-05  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:12:28 d2.utils.events]: \u001b[0m eta: 1:15:43  iter: 379  total_loss: 1.882  loss_cls: 0.7144  loss_box_reg: 0.6883  loss_mask: 0.357  loss_rpn_cls: 0.03144  loss_rpn_loc: 0.05592    time: 0.4456  last_time: 0.4612  data_time: 0.0124  last_data_time: 0.0108   lr: 9.1109e-05  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:12:37 d2.utils.events]: \u001b[0m eta: 1:15:34  iter: 399  total_loss: 1.774  loss_cls: 0.7192  loss_box_reg: 0.681  loss_mask: 0.2647  loss_rpn_cls: 0.03199  loss_rpn_loc: 0.06366    time: 0.4456  last_time: 0.4374  data_time: 0.0123  last_data_time: 0.0088   lr: 9.5904e-05  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:12:46 d2.utils.events]: \u001b[0m eta: 1:15:37  iter: 419  total_loss: 1.842  loss_cls: 0.7285  loss_box_reg: 0.6941  loss_mask: 0.278  loss_rpn_cls: 0.04656  loss_rpn_loc: 0.06536    time: 0.4462  last_time: 0.4545  data_time: 0.0130  last_data_time: 0.0106   lr: 0.0001007  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:12:56 d2.utils.events]: \u001b[0m eta: 1:15:29  iter: 439  total_loss: 1.644  loss_cls: 0.6703  loss_box_reg: 0.6254  loss_mask: 0.2639  loss_rpn_cls: 0.02561  loss_rpn_loc: 0.06388    time: 0.4469  last_time: 0.5639  data_time: 0.0287  last_data_time: 0.1217   lr: 0.00010549  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:13:05 d2.utils.events]: \u001b[0m eta: 1:15:25  iter: 459  total_loss: 1.663  loss_cls: 0.6582  loss_box_reg: 0.6681  loss_mask: 0.2549  loss_rpn_cls: 0.03305  loss_rpn_loc: 0.05622    time: 0.4482  last_time: 0.5681  data_time: 0.0317  last_data_time: 0.1327   lr: 0.00011029  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:13:14 d2.utils.events]: \u001b[0m eta: 1:15:21  iter: 479  total_loss: 1.753  loss_cls: 0.6981  loss_box_reg: 0.7004  loss_mask: 0.2563  loss_rpn_cls: 0.04591  loss_rpn_loc: 0.06167    time: 0.4489  last_time: 0.4350  data_time: 0.0281  last_data_time: 0.0125   lr: 0.00011509  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:13:23 d2.utils.events]: \u001b[0m eta: 1:15:09  iter: 499  total_loss: 1.75  loss_cls: 0.7156  loss_box_reg: 0.6902  loss_mask: 0.2269  loss_rpn_cls: 0.03588  loss_rpn_loc: 0.06401    time: 0.4489  last_time: 0.4389  data_time: 0.0206  last_data_time: 0.0060   lr: 0.00011988  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:13:33 d2.utils.events]: \u001b[0m eta: 1:15:03  iter: 519  total_loss: 1.616  loss_cls: 0.6532  loss_box_reg: 0.6618  loss_mask: 0.2042  loss_rpn_cls: 0.02871  loss_rpn_loc: 0.05206    time: 0.4495  last_time: 0.6542  data_time: 0.0338  last_data_time: 0.2171   lr: 0.00012468  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:13:42 d2.utils.events]: \u001b[0m eta: 1:14:51  iter: 539  total_loss: 1.632  loss_cls: 0.6602  loss_box_reg: 0.6961  loss_mask: 0.2082  loss_rpn_cls: 0.0339  loss_rpn_loc: 0.06493    time: 0.4498  last_time: 0.4673  data_time: 0.0248  last_data_time: 0.0086   lr: 0.00012947  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:13:52 d2.utils.events]: \u001b[0m eta: 1:14:53  iter: 559  total_loss: 1.773  loss_cls: 0.7071  loss_box_reg: 0.7197  loss_mask: 0.2351  loss_rpn_cls: 0.03093  loss_rpn_loc: 0.05719    time: 0.4510  last_time: 0.5024  data_time: 0.0394  last_data_time: 0.0886   lr: 0.00013427  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:14:01 d2.utils.events]: \u001b[0m eta: 1:14:47  iter: 579  total_loss: 1.579  loss_cls: 0.6493  loss_box_reg: 0.6741  loss_mask: 0.1807  loss_rpn_cls: 0.03132  loss_rpn_loc: 0.06021    time: 0.4517  last_time: 0.5565  data_time: 0.0389  last_data_time: 0.1566   lr: 0.00013906  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:14:10 d2.utils.events]: \u001b[0m eta: 1:14:38  iter: 599  total_loss: 1.565  loss_cls: 0.6169  loss_box_reg: 0.6451  loss_mask: 0.2153  loss_rpn_cls: 0.02653  loss_rpn_loc: 0.05169    time: 0.4517  last_time: 0.4297  data_time: 0.0230  last_data_time: 0.0119   lr: 0.00014386  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:14:19 d2.utils.events]: \u001b[0m eta: 1:14:29  iter: 619  total_loss: 1.734  loss_cls: 0.6583  loss_box_reg: 0.7141  loss_mask: 0.2024  loss_rpn_cls: 0.0329  loss_rpn_loc: 0.0671    time: 0.4518  last_time: 0.4552  data_time: 0.0108  last_data_time: 0.0200   lr: 0.00014865  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:14:28 d2.utils.events]: \u001b[0m eta: 1:14:20  iter: 639  total_loss: 1.598  loss_cls: 0.6497  loss_box_reg: 0.6619  loss_mask: 0.2004  loss_rpn_cls: 0.03149  loss_rpn_loc: 0.06172    time: 0.4521  last_time: 0.4785  data_time: 0.0244  last_data_time: 0.0238   lr: 0.00015345  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:14:37 d2.utils.events]: \u001b[0m eta: 1:14:12  iter: 659  total_loss: 1.574  loss_cls: 0.6335  loss_box_reg: 0.688  loss_mask: 0.1737  loss_rpn_cls: 0.03  loss_rpn_loc: 0.05652    time: 0.4519  last_time: 0.4501  data_time: 0.0123  last_data_time: 0.0084   lr: 0.00015824  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:14:46 d2.utils.events]: \u001b[0m eta: 1:14:15  iter: 679  total_loss: 1.651  loss_cls: 0.6409  loss_box_reg: 0.7174  loss_mask: 0.2049  loss_rpn_cls: 0.03222  loss_rpn_loc: 0.06455    time: 0.4520  last_time: 0.4828  data_time: 0.0115  last_data_time: 0.0097   lr: 0.00016304  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:14:56 d2.utils.events]: \u001b[0m eta: 1:14:08  iter: 699  total_loss: 1.603  loss_cls: 0.5835  loss_box_reg: 0.6832  loss_mask: 0.1844  loss_rpn_cls: 0.02856  loss_rpn_loc: 0.06736    time: 0.4522  last_time: 0.4852  data_time: 0.0167  last_data_time: 0.0213   lr: 0.00016783  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:15:05 d2.utils.events]: \u001b[0m eta: 1:13:57  iter: 719  total_loss: 1.605  loss_cls: 0.6084  loss_box_reg: 0.6898  loss_mask: 0.1792  loss_rpn_cls: 0.0335  loss_rpn_loc: 0.07016    time: 0.4522  last_time: 0.5344  data_time: 0.0170  last_data_time: 0.1238   lr: 0.00017263  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:15:14 d2.utils.events]: \u001b[0m eta: 1:13:52  iter: 739  total_loss: 1.513  loss_cls: 0.5929  loss_box_reg: 0.6719  loss_mask: 0.18  loss_rpn_cls: 0.03185  loss_rpn_loc: 0.06099    time: 0.4527  last_time: 0.4605  data_time: 0.0280  last_data_time: 0.0130   lr: 0.00017742  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:15:24 d2.utils.events]: \u001b[0m eta: 1:13:46  iter: 759  total_loss: 1.626  loss_cls: 0.6488  loss_box_reg: 0.7213  loss_mask: 0.1906  loss_rpn_cls: 0.02519  loss_rpn_loc: 0.05242    time: 0.4532  last_time: 0.4458  data_time: 0.0310  last_data_time: 0.0089   lr: 0.00018222  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:15:33 d2.utils.events]: \u001b[0m eta: 1:13:40  iter: 779  total_loss: 1.519  loss_cls: 0.5966  loss_box_reg: 0.6629  loss_mask: 0.1653  loss_rpn_cls: 0.03039  loss_rpn_loc: 0.05348    time: 0.4538  last_time: 0.4592  data_time: 0.0230  last_data_time: 0.0096   lr: 0.00018701  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:15:42 d2.utils.events]: \u001b[0m eta: 1:13:33  iter: 799  total_loss: 1.557  loss_cls: 0.5926  loss_box_reg: 0.6824  loss_mask: 0.1792  loss_rpn_cls: 0.03003  loss_rpn_loc: 0.04164    time: 0.4539  last_time: 0.4796  data_time: 0.0123  last_data_time: 0.0160   lr: 0.00019181  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:15:51 d2.utils.events]: \u001b[0m eta: 1:13:27  iter: 819  total_loss: 1.653  loss_cls: 0.6246  loss_box_reg: 0.7446  loss_mask: 0.1919  loss_rpn_cls: 0.03129  loss_rpn_loc: 0.06239    time: 0.4540  last_time: 0.4507  data_time: 0.0142  last_data_time: 0.0201   lr: 0.0001966  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:16:01 d2.utils.events]: \u001b[0m eta: 1:13:26  iter: 839  total_loss: 1.582  loss_cls: 0.6364  loss_box_reg: 0.6779  loss_mask: 0.1441  loss_rpn_cls: 0.02709  loss_rpn_loc: 0.05005    time: 0.4541  last_time: 0.4283  data_time: 0.0134  last_data_time: 0.0163   lr: 0.0002014  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:16:10 d2.utils.events]: \u001b[0m eta: 1:13:18  iter: 859  total_loss: 1.534  loss_cls: 0.6007  loss_box_reg: 0.6906  loss_mask: 0.151  loss_rpn_cls: 0.02897  loss_rpn_loc: 0.06412    time: 0.4541  last_time: 0.4592  data_time: 0.0119  last_data_time: 0.0161   lr: 0.00020619  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:16:19 d2.utils.events]: \u001b[0m eta: 1:13:09  iter: 879  total_loss: 1.621  loss_cls: 0.6425  loss_box_reg: 0.7053  loss_mask: 0.1576  loss_rpn_cls: 0.025  loss_rpn_loc: 0.05983    time: 0.4545  last_time: 0.4296  data_time: 0.0258  last_data_time: 0.0049   lr: 0.00021099  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:16:28 d2.utils.events]: \u001b[0m eta: 1:13:01  iter: 899  total_loss: 1.549  loss_cls: 0.5801  loss_box_reg: 0.6915  loss_mask: 0.1538  loss_rpn_cls: 0.03323  loss_rpn_loc: 0.07288    time: 0.4547  last_time: 0.4690  data_time: 0.0178  last_data_time: 0.0171   lr: 0.00021578  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:16:38 d2.utils.events]: \u001b[0m eta: 1:12:52  iter: 919  total_loss: 1.58  loss_cls: 0.5909  loss_box_reg: 0.6867  loss_mask: 0.1658  loss_rpn_cls: 0.02578  loss_rpn_loc: 0.05884    time: 0.4549  last_time: 0.4480  data_time: 0.0245  last_data_time: 0.0098   lr: 0.00022058  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:16:47 d2.utils.events]: \u001b[0m eta: 1:12:46  iter: 939  total_loss: 1.487  loss_cls: 0.6159  loss_box_reg: 0.6856  loss_mask: 0.1457  loss_rpn_cls: 0.0247  loss_rpn_loc: 0.04685    time: 0.4552  last_time: 0.5018  data_time: 0.0197  last_data_time: 0.0174   lr: 0.00022537  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:16:56 d2.utils.events]: \u001b[0m eta: 1:12:37  iter: 959  total_loss: 1.493  loss_cls: 0.5793  loss_box_reg: 0.6513  loss_mask: 0.1614  loss_rpn_cls: 0.02416  loss_rpn_loc: 0.04971    time: 0.4554  last_time: 0.4194  data_time: 0.0272  last_data_time: 0.0091   lr: 0.00023017  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:17:05 d2.utils.events]: \u001b[0m eta: 1:12:26  iter: 979  total_loss: 1.466  loss_cls: 0.5526  loss_box_reg: 0.6574  loss_mask: 0.1419  loss_rpn_cls: 0.02527  loss_rpn_loc: 0.05214    time: 0.4551  last_time: 0.4526  data_time: 0.0123  last_data_time: 0.0112   lr: 0.00023497  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:17:14 d2.utils.events]: \u001b[0m eta: 1:12:18  iter: 999  total_loss: 1.554  loss_cls: 0.5958  loss_box_reg: 0.7003  loss_mask: 0.1431  loss_rpn_cls: 0.0271  loss_rpn_loc: 0.06261    time: 0.4551  last_time: 0.4123  data_time: 0.0135  last_data_time: 0.0103   lr: 0.00023976  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:17:23 d2.utils.events]: \u001b[0m eta: 1:12:11  iter: 1019  total_loss: 1.585  loss_cls: 0.5886  loss_box_reg: 0.6974  loss_mask: 0.1512  loss_rpn_cls: 0.02551  loss_rpn_loc: 0.06118    time: 0.4550  last_time: 0.4362  data_time: 0.0124  last_data_time: 0.0086   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:17:33 d2.utils.events]: \u001b[0m eta: 1:12:05  iter: 1039  total_loss: 1.518  loss_cls: 0.5693  loss_box_reg: 0.6588  loss_mask: 0.1467  loss_rpn_cls: 0.02573  loss_rpn_loc: 0.0639    time: 0.4550  last_time: 0.4315  data_time: 0.0218  last_data_time: 0.0041   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:17:42 d2.utils.events]: \u001b[0m eta: 1:12:03  iter: 1059  total_loss: 1.516  loss_cls: 0.5788  loss_box_reg: 0.679  loss_mask: 0.1618  loss_rpn_cls: 0.03013  loss_rpn_loc: 0.06548    time: 0.4550  last_time: 0.4610  data_time: 0.0134  last_data_time: 0.0081   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:17:42 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 11:17:42 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/08 11:17:42 d2.data.datasets.coco]: \u001b[0mLoaded 146 images in COCO format from /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Seg/cocoOut/val.json\n",
      "\u001b[32m[07/08 11:17:42 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |   category    | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:-------------:|:-------------|\n",
      "|  nascent   | 107          |    mini    | 44           | unripe gree.. | 179          |\n",
      "| semi ripe  | 74           | fully ripe | 406          |      2mm      | 58           |\n",
      "|    4mm     | 147          |    6mm     | 159          |      8mm      | 49           |\n",
      "|    12mm    | 53           |            |              |               |              |\n",
      "|   total    | 1276         |            |              |               |              |\u001b[0m\n",
      "\u001b[32m[07/08 11:17:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/08 11:17:42 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/08 11:17:42 d2.data.common]: \u001b[0mSerializing 146 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/08 11:17:42 d2.data.common]: \u001b[0mSerialized dataset takes 5.22 MiB\n",
      "\u001b[32m[07/08 11:17:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 146 batches\n",
      "\u001b[32m[07/08 11:17:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/146. Dataloading: 0.0345 s/iter. Inference: 0.0656 s/iter. Eval: 0.2523 s/iter. Total: 0.3524 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/08 11:17:53 d2.evaluation.evaluator]: \u001b[0mInference done 25/146. Dataloading: 0.0114 s/iter. Inference: 0.0678 s/iter. Eval: 0.2768 s/iter. Total: 0.3562 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/08 11:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 40/146. Dataloading: 0.0074 s/iter. Inference: 0.0674 s/iter. Eval: 0.2783 s/iter. Total: 0.3535 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/08 11:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 50/146. Dataloading: 0.0062 s/iter. Inference: 0.0688 s/iter. Eval: 0.3116 s/iter. Total: 0.3869 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/08 11:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 62/146. Dataloading: 0.0054 s/iter. Inference: 0.0694 s/iter. Eval: 0.3213 s/iter. Total: 0.3964 s/iter. ETA=0:00:33\n",
      "\u001b[32m[07/08 11:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 75/146. Dataloading: 0.0048 s/iter. Inference: 0.0697 s/iter. Eval: 0.3293 s/iter. Total: 0.4040 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/08 11:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 91/146. Dataloading: 0.0042 s/iter. Inference: 0.0692 s/iter. Eval: 0.3201 s/iter. Total: 0.3937 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/08 11:18:25 d2.evaluation.evaluator]: \u001b[0mInference done 107/146. Dataloading: 0.0038 s/iter. Inference: 0.0685 s/iter. Eval: 0.3167 s/iter. Total: 0.3892 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/08 11:18:31 d2.evaluation.evaluator]: \u001b[0mInference done 120/146. Dataloading: 0.0035 s/iter. Inference: 0.0681 s/iter. Eval: 0.3205 s/iter. Total: 0.3923 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/08 11:18:36 d2.evaluation.evaluator]: \u001b[0mInference done 136/146. Dataloading: 0.0033 s/iter. Inference: 0.0671 s/iter. Eval: 0.3121 s/iter. Total: 0.3827 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/08 11:18:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:53.942869 (0.382574 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 11:18:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.066753 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 11:18:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/08 11:18:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to TomatoMAP/TomatoMAP-Seg/output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/08 11:18:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "evaluate failed: 'info'\n",
      "Epoch 1: evaluate failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45811/3081507412.py\", line 123, in _do_eval\n",
      "    results = inference_on_dataset(self.trainer.model, val_loader, evaluator)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py\", line 215, in inference_on_dataset\n",
      "    results = evaluator.evaluate()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 206, in evaluate\n",
      "    self._eval_predictions(predictions, img_ids=img_ids)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 266, in _eval_predictions\n",
      "    _evaluate_predictions_on_coco(\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 590, in _evaluate_predictions_on_coco\n",
      "    coco_dt = coco_gt.loadRes(coco_results)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/pycocotools/coco.py\", line 314, in loadRes\n",
      "    res.dataset['info'] = copy.deepcopy(self.dataset['info'])\n",
      "KeyError: 'info'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/08 11:18:49 d2.utils.events]: \u001b[0m eta: 1:12:01  iter: 1079  total_loss: 1.511  loss_cls: 0.5798  loss_box_reg: 0.6504  loss_mask: 0.1434  loss_rpn_cls: 0.02967  loss_rpn_loc: 0.05186    time: 0.4555  last_time: 0.4951  data_time: 0.0278  last_data_time: 0.0158   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:18:58 d2.utils.events]: \u001b[0m eta: 1:11:57  iter: 1099  total_loss: 1.371  loss_cls: 0.5181  loss_box_reg: 0.6436  loss_mask: 0.1188  loss_rpn_cls: 0.02565  loss_rpn_loc: 0.04872    time: 0.4557  last_time: 0.4402  data_time: 0.0235  last_data_time: 0.0094   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:19:07 d2.utils.events]: \u001b[0m eta: 1:11:46  iter: 1119  total_loss: 1.516  loss_cls: 0.5748  loss_box_reg: 0.6764  loss_mask: 0.1379  loss_rpn_cls: 0.02544  loss_rpn_loc: 0.0528    time: 0.4556  last_time: 0.4313  data_time: 0.0174  last_data_time: 0.0082   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:19:17 d2.utils.events]: \u001b[0m eta: 1:11:39  iter: 1139  total_loss: 1.553  loss_cls: 0.569  loss_box_reg: 0.7046  loss_mask: 0.1428  loss_rpn_cls: 0.02649  loss_rpn_loc: 0.06293    time: 0.4560  last_time: 0.4811  data_time: 0.0246  last_data_time: 0.0076   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:19:26 d2.utils.events]: \u001b[0m eta: 1:11:30  iter: 1159  total_loss: 1.459  loss_cls: 0.5082  loss_box_reg: 0.6502  loss_mask: 0.1621  loss_rpn_cls: 0.02847  loss_rpn_loc: 0.06229    time: 0.4558  last_time: 0.5014  data_time: 0.0104  last_data_time: 0.0120   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:19:35 d2.utils.events]: \u001b[0m eta: 1:11:21  iter: 1179  total_loss: 1.399  loss_cls: 0.5458  loss_box_reg: 0.6434  loss_mask: 0.1359  loss_rpn_cls: 0.02134  loss_rpn_loc: 0.05965    time: 0.4558  last_time: 0.4188  data_time: 0.0127  last_data_time: 0.0099   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:19:44 d2.utils.events]: \u001b[0m eta: 1:11:15  iter: 1199  total_loss: 1.4  loss_cls: 0.5355  loss_box_reg: 0.6129  loss_mask: 0.1381  loss_rpn_cls: 0.02142  loss_rpn_loc: 0.04896    time: 0.4558  last_time: 0.4576  data_time: 0.0117  last_data_time: 0.0205   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:19:53 d2.utils.events]: \u001b[0m eta: 1:11:03  iter: 1219  total_loss: 1.459  loss_cls: 0.5628  loss_box_reg: 0.6728  loss_mask: 0.1233  loss_rpn_cls: 0.02902  loss_rpn_loc: 0.05716    time: 0.4557  last_time: 0.4265  data_time: 0.0105  last_data_time: 0.0080   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:20:02 d2.utils.events]: \u001b[0m eta: 1:10:54  iter: 1239  total_loss: 1.396  loss_cls: 0.5442  loss_box_reg: 0.648  loss_mask: 0.145  loss_rpn_cls: 0.02728  loss_rpn_loc: 0.0511    time: 0.4556  last_time: 0.4387  data_time: 0.0111  last_data_time: 0.0095   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:20:11 d2.utils.events]: \u001b[0m eta: 1:10:48  iter: 1259  total_loss: 1.413  loss_cls: 0.5271  loss_box_reg: 0.653  loss_mask: 0.1401  loss_rpn_cls: 0.0244  loss_rpn_loc: 0.04826    time: 0.4558  last_time: 0.4771  data_time: 0.0109  last_data_time: 0.0125   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:20:21 d2.utils.events]: \u001b[0m eta: 1:10:39  iter: 1279  total_loss: 1.437  loss_cls: 0.5626  loss_box_reg: 0.6735  loss_mask: 0.1461  loss_rpn_cls: 0.01999  loss_rpn_loc: 0.05617    time: 0.4558  last_time: 0.4654  data_time: 0.0175  last_data_time: 0.0145   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:20:30 d2.utils.events]: \u001b[0m eta: 1:10:31  iter: 1299  total_loss: 1.454  loss_cls: 0.5776  loss_box_reg: 0.6658  loss_mask: 0.1377  loss_rpn_cls: 0.02666  loss_rpn_loc: 0.05846    time: 0.4559  last_time: 0.4608  data_time: 0.0233  last_data_time: 0.0134   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:20:40 d2.utils.events]: \u001b[0m eta: 1:10:23  iter: 1319  total_loss: 1.329  loss_cls: 0.4955  loss_box_reg: 0.6152  loss_mask: 0.1322  loss_rpn_cls: 0.02484  loss_rpn_loc: 0.0503    time: 0.4564  last_time: 0.4595  data_time: 0.0405  last_data_time: 0.0071   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:20:49 d2.utils.events]: \u001b[0m eta: 1:10:17  iter: 1339  total_loss: 1.355  loss_cls: 0.5087  loss_box_reg: 0.6128  loss_mask: 0.1527  loss_rpn_cls: 0.02793  loss_rpn_loc: 0.05923    time: 0.4566  last_time: 0.5691  data_time: 0.0340  last_data_time: 0.1485   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:20:59 d2.utils.events]: \u001b[0m eta: 1:10:07  iter: 1359  total_loss: 1.27  loss_cls: 0.4895  loss_box_reg: 0.5845  loss_mask: 0.1335  loss_rpn_cls: 0.02145  loss_rpn_loc: 0.05542    time: 0.4570  last_time: 0.5726  data_time: 0.0432  last_data_time: 0.1473   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:21:08 d2.utils.events]: \u001b[0m eta: 1:10:00  iter: 1379  total_loss: 1.495  loss_cls: 0.578  loss_box_reg: 0.6833  loss_mask: 0.1154  loss_rpn_cls: 0.02822  loss_rpn_loc: 0.07223    time: 0.4572  last_time: 0.5170  data_time: 0.0248  last_data_time: 0.1228   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:21:18 d2.utils.events]: \u001b[0m eta: 1:09:55  iter: 1399  total_loss: 1.394  loss_cls: 0.5498  loss_box_reg: 0.6435  loss_mask: 0.1196  loss_rpn_cls: 0.0238  loss_rpn_loc: 0.05156    time: 0.4573  last_time: 0.4571  data_time: 0.0174  last_data_time: 0.0019   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:21:27 d2.utils.events]: \u001b[0m eta: 1:09:46  iter: 1419  total_loss: 1.378  loss_cls: 0.5254  loss_box_reg: 0.6391  loss_mask: 0.1334  loss_rpn_cls: 0.03098  loss_rpn_loc: 0.05052    time: 0.4578  last_time: 0.5865  data_time: 0.0348  last_data_time: 0.1215   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:21:37 d2.utils.events]: \u001b[0m eta: 1:09:41  iter: 1439  total_loss: 1.424  loss_cls: 0.5361  loss_box_reg: 0.6694  loss_mask: 0.1343  loss_rpn_cls: 0.0261  loss_rpn_loc: 0.05449    time: 0.4578  last_time: 0.4791  data_time: 0.0095  last_data_time: 0.0076   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:21:46 d2.utils.events]: \u001b[0m eta: 1:09:32  iter: 1459  total_loss: 1.48  loss_cls: 0.5469  loss_box_reg: 0.6923  loss_mask: 0.1234  loss_rpn_cls: 0.02263  loss_rpn_loc: 0.05321    time: 0.4579  last_time: 0.4606  data_time: 0.0207  last_data_time: 0.0038   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:21:55 d2.utils.events]: \u001b[0m eta: 1:09:25  iter: 1479  total_loss: 1.353  loss_cls: 0.521  loss_box_reg: 0.6041  loss_mask: 0.1291  loss_rpn_cls: 0.02531  loss_rpn_loc: 0.05048    time: 0.4578  last_time: 0.4663  data_time: 0.0122  last_data_time: 0.0084   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:22:04 d2.utils.events]: \u001b[0m eta: 1:09:22  iter: 1499  total_loss: 1.358  loss_cls: 0.521  loss_box_reg: 0.6186  loss_mask: 0.131  loss_rpn_cls: 0.02171  loss_rpn_loc: 0.04973    time: 0.4580  last_time: 0.3993  data_time: 0.0283  last_data_time: 0.0107   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:22:14 d2.utils.events]: \u001b[0m eta: 1:09:14  iter: 1519  total_loss: 1.399  loss_cls: 0.5131  loss_box_reg: 0.6275  loss_mask: 0.1327  loss_rpn_cls: 0.02725  loss_rpn_loc: 0.06612    time: 0.4581  last_time: 0.4615  data_time: 0.0190  last_data_time: 0.0155   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:22:23 d2.utils.events]: \u001b[0m eta: 1:09:05  iter: 1539  total_loss: 1.292  loss_cls: 0.4876  loss_box_reg: 0.6208  loss_mask: 0.1309  loss_rpn_cls: 0.02331  loss_rpn_loc: 0.04914    time: 0.4580  last_time: 0.4345  data_time: 0.0132  last_data_time: 0.0079   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:22:32 d2.utils.events]: \u001b[0m eta: 1:08:54  iter: 1559  total_loss: 1.385  loss_cls: 0.5321  loss_box_reg: 0.6076  loss_mask: 0.1297  loss_rpn_cls: 0.02052  loss_rpn_loc: 0.05059    time: 0.4580  last_time: 0.4664  data_time: 0.0148  last_data_time: 0.0099   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:22:41 d2.utils.events]: \u001b[0m eta: 1:08:46  iter: 1579  total_loss: 1.414  loss_cls: 0.5155  loss_box_reg: 0.6551  loss_mask: 0.1272  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.06632    time: 0.4580  last_time: 0.4467  data_time: 0.0121  last_data_time: 0.0118   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:22:50 d2.utils.events]: \u001b[0m eta: 1:08:38  iter: 1599  total_loss: 1.309  loss_cls: 0.5231  loss_box_reg: 0.6196  loss_mask: 0.1261  loss_rpn_cls: 0.02102  loss_rpn_loc: 0.04877    time: 0.4581  last_time: 0.4638  data_time: 0.0112  last_data_time: 0.0075   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:22:59 d2.utils.events]: \u001b[0m eta: 1:08:30  iter: 1619  total_loss: 1.297  loss_cls: 0.481  loss_box_reg: 0.5923  loss_mask: 0.1331  loss_rpn_cls: 0.02198  loss_rpn_loc: 0.04816    time: 0.4580  last_time: 0.4147  data_time: 0.0118  last_data_time: 0.0096   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:23:09 d2.utils.events]: \u001b[0m eta: 1:08:24  iter: 1639  total_loss: 1.378  loss_cls: 0.5328  loss_box_reg: 0.6568  loss_mask: 0.1278  loss_rpn_cls: 0.0241  loss_rpn_loc: 0.07019    time: 0.4580  last_time: 0.4392  data_time: 0.0118  last_data_time: 0.0082   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:23:18 d2.utils.events]: \u001b[0m eta: 1:08:18  iter: 1659  total_loss: 1.304  loss_cls: 0.5165  loss_box_reg: 0.6166  loss_mask: 0.1348  loss_rpn_cls: 0.01902  loss_rpn_loc: 0.05708    time: 0.4580  last_time: 0.4441  data_time: 0.0129  last_data_time: 0.0176   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:23:27 d2.utils.events]: \u001b[0m eta: 1:08:09  iter: 1679  total_loss: 1.283  loss_cls: 0.5078  loss_box_reg: 0.5889  loss_mask: 0.1193  loss_rpn_cls: 0.02204  loss_rpn_loc: 0.04822    time: 0.4581  last_time: 0.4381  data_time: 0.0212  last_data_time: 0.0087   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:23:37 d2.utils.events]: \u001b[0m eta: 1:08:02  iter: 1699  total_loss: 1.306  loss_cls: 0.5056  loss_box_reg: 0.6201  loss_mask: 0.1215  loss_rpn_cls: 0.01955  loss_rpn_loc: 0.04983    time: 0.4583  last_time: 0.4095  data_time: 0.0330  last_data_time: 0.0054   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:23:46 d2.utils.events]: \u001b[0m eta: 1:07:55  iter: 1719  total_loss: 1.417  loss_cls: 0.5168  loss_box_reg: 0.67  loss_mask: 0.1164  loss_rpn_cls: 0.01976  loss_rpn_loc: 0.05359    time: 0.4586  last_time: 0.4462  data_time: 0.0225  last_data_time: 0.0072   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:23:56 d2.utils.events]: \u001b[0m eta: 1:07:47  iter: 1739  total_loss: 1.352  loss_cls: 0.5104  loss_box_reg: 0.6065  loss_mask: 0.1361  loss_rpn_cls: 0.02293  loss_rpn_loc: 0.0603    time: 0.4587  last_time: 0.4632  data_time: 0.0111  last_data_time: 0.0160   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:24:05 d2.utils.events]: \u001b[0m eta: 1:07:38  iter: 1759  total_loss: 1.32  loss_cls: 0.4922  loss_box_reg: 0.6146  loss_mask: 0.1279  loss_rpn_cls: 0.01988  loss_rpn_loc: 0.05516    time: 0.4587  last_time: 0.4669  data_time: 0.0169  last_data_time: 0.0081   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:24:14 d2.utils.events]: \u001b[0m eta: 1:07:28  iter: 1779  total_loss: 1.252  loss_cls: 0.4817  loss_box_reg: 0.5851  loss_mask: 0.1282  loss_rpn_cls: 0.02129  loss_rpn_loc: 0.0491    time: 0.4589  last_time: 0.4471  data_time: 0.0291  last_data_time: 0.0150   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:24:24 d2.utils.events]: \u001b[0m eta: 1:07:20  iter: 1799  total_loss: 1.324  loss_cls: 0.4963  loss_box_reg: 0.6426  loss_mask: 0.1313  loss_rpn_cls: 0.02355  loss_rpn_loc: 0.05412    time: 0.4590  last_time: 0.4873  data_time: 0.0193  last_data_time: 0.0116   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:24:33 d2.utils.events]: \u001b[0m eta: 1:07:11  iter: 1819  total_loss: 1.213  loss_cls: 0.4916  loss_box_reg: 0.568  loss_mask: 0.1026  loss_rpn_cls: 0.01888  loss_rpn_loc: 0.046    time: 0.4590  last_time: 0.4401  data_time: 0.0161  last_data_time: 0.0108   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:24:42 d2.utils.events]: \u001b[0m eta: 1:07:00  iter: 1839  total_loss: 1.391  loss_cls: 0.5266  loss_box_reg: 0.6359  loss_mask: 0.1281  loss_rpn_cls: 0.02181  loss_rpn_loc: 0.05756    time: 0.4590  last_time: 0.4212  data_time: 0.0146  last_data_time: 0.0159   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:24:51 d2.utils.events]: \u001b[0m eta: 1:06:50  iter: 1859  total_loss: 1.271  loss_cls: 0.5102  loss_box_reg: 0.5988  loss_mask: 0.1072  loss_rpn_cls: 0.01944  loss_rpn_loc: 0.04405    time: 0.4589  last_time: 0.4272  data_time: 0.0177  last_data_time: 0.0124   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:25:00 d2.utils.events]: \u001b[0m eta: 1:06:41  iter: 1879  total_loss: 1.23  loss_cls: 0.4462  loss_box_reg: 0.6017  loss_mask: 0.1392  loss_rpn_cls: 0.02062  loss_rpn_loc: 0.04661    time: 0.4589  last_time: 0.4768  data_time: 0.0109  last_data_time: 0.0087   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:25:10 d2.utils.events]: \u001b[0m eta: 1:06:32  iter: 1899  total_loss: 1.413  loss_cls: 0.518  loss_box_reg: 0.6487  loss_mask: 0.1178  loss_rpn_cls: 0.02039  loss_rpn_loc: 0.06191    time: 0.4591  last_time: 0.4536  data_time: 0.0110  last_data_time: 0.0093   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:25:19 d2.utils.events]: \u001b[0m eta: 1:06:24  iter: 1919  total_loss: 1.271  loss_cls: 0.4865  loss_box_reg: 0.5948  loss_mask: 0.1216  loss_rpn_cls: 0.01836  loss_rpn_loc: 0.04275    time: 0.4592  last_time: 0.4425  data_time: 0.0258  last_data_time: 0.0084   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:25:29 d2.utils.events]: \u001b[0m eta: 1:06:15  iter: 1939  total_loss: 1.334  loss_cls: 0.4765  loss_box_reg: 0.6273  loss_mask: 0.142  loss_rpn_cls: 0.02502  loss_rpn_loc: 0.05411    time: 0.4594  last_time: 0.4829  data_time: 0.0208  last_data_time: 0.0151   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:25:38 d2.utils.events]: \u001b[0m eta: 1:06:07  iter: 1959  total_loss: 1.277  loss_cls: 0.4663  loss_box_reg: 0.6032  loss_mask: 0.1335  loss_rpn_cls: 0.01846  loss_rpn_loc: 0.05064    time: 0.4595  last_time: 0.4691  data_time: 0.0224  last_data_time: 0.0188   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:25:47 d2.utils.events]: \u001b[0m eta: 1:06:01  iter: 1979  total_loss: 1.286  loss_cls: 0.4788  loss_box_reg: 0.6094  loss_mask: 0.1107  loss_rpn_cls: 0.01655  loss_rpn_loc: 0.05254    time: 0.4594  last_time: 0.4764  data_time: 0.0122  last_data_time: 0.0102   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:25:56 d2.utils.events]: \u001b[0m eta: 1:05:52  iter: 1999  total_loss: 1.368  loss_cls: 0.5278  loss_box_reg: 0.626  loss_mask: 0.1292  loss_rpn_cls: 0.02307  loss_rpn_loc: 0.06405    time: 0.4594  last_time: 0.4908  data_time: 0.0104  last_data_time: 0.0090   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:26:06 d2.utils.events]: \u001b[0m eta: 1:05:44  iter: 2019  total_loss: 1.28  loss_cls: 0.4711  loss_box_reg: 0.6118  loss_mask: 0.1143  loss_rpn_cls: 0.0248  loss_rpn_loc: 0.04506    time: 0.4596  last_time: 0.4871  data_time: 0.0236  last_data_time: 0.0087   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:26:15 d2.utils.events]: \u001b[0m eta: 1:05:37  iter: 2039  total_loss: 1.309  loss_cls: 0.4659  loss_box_reg: 0.6105  loss_mask: 0.1436  loss_rpn_cls: 0.0172  loss_rpn_loc: 0.06043    time: 0.4596  last_time: 0.4797  data_time: 0.0104  last_data_time: 0.0111   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:26:25 d2.utils.events]: \u001b[0m eta: 1:05:26  iter: 2059  total_loss: 1.342  loss_cls: 0.5097  loss_box_reg: 0.6328  loss_mask: 0.1232  loss_rpn_cls: 0.02119  loss_rpn_loc: 0.05347    time: 0.4597  last_time: 0.4721  data_time: 0.0228  last_data_time: 0.0175   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:26:34 d2.utils.events]: \u001b[0m eta: 1:05:18  iter: 2079  total_loss: 1.35  loss_cls: 0.5448  loss_box_reg: 0.6241  loss_mask: 0.1129  loss_rpn_cls: 0.01828  loss_rpn_loc: 0.05318    time: 0.4597  last_time: 0.4571  data_time: 0.0159  last_data_time: 0.0087   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:26:43 d2.utils.events]: \u001b[0m eta: 1:05:13  iter: 2099  total_loss: 1.275  loss_cls: 0.474  loss_box_reg: 0.6041  loss_mask: 0.1206  loss_rpn_cls: 0.02091  loss_rpn_loc: 0.04554    time: 0.4599  last_time: 0.4730  data_time: 0.0240  last_data_time: 0.0112   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:26:53 d2.utils.events]: \u001b[0m eta: 1:05:07  iter: 2119  total_loss: 1.331  loss_cls: 0.4909  loss_box_reg: 0.6233  loss_mask: 0.1224  loss_rpn_cls: 0.01437  loss_rpn_loc: 0.05711    time: 0.4599  last_time: 0.4076  data_time: 0.0205  last_data_time: 0.0128   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:26:53 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 11:26:53 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/08 11:26:54 d2.data.datasets.coco]: \u001b[0mLoaded 146 images in COCO format from /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Seg/cocoOut/val.json\n",
      "\u001b[32m[07/08 11:26:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/08 11:26:54 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/08 11:26:54 d2.data.common]: \u001b[0mSerializing 146 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/08 11:26:54 d2.data.common]: \u001b[0mSerialized dataset takes 5.22 MiB\n",
      "\u001b[32m[07/08 11:26:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 146 batches\n",
      "\u001b[32m[07/08 11:27:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/146. Dataloading: 0.0018 s/iter. Inference: 0.0735 s/iter. Eval: 0.4806 s/iter. Total: 0.5559 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/08 11:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 21/146. Dataloading: 0.0016 s/iter. Inference: 0.0720 s/iter. Eval: 0.4581 s/iter. Total: 0.5321 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/08 11:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 30/146. Dataloading: 0.0019 s/iter. Inference: 0.0718 s/iter. Eval: 0.4760 s/iter. Total: 0.5500 s/iter. ETA=0:01:03\n",
      "\u001b[32m[07/08 11:27:16 d2.evaluation.evaluator]: \u001b[0mInference done 40/146. Dataloading: 0.0020 s/iter. Inference: 0.0708 s/iter. Eval: 0.4747 s/iter. Total: 0.5477 s/iter. ETA=0:00:58\n",
      "\u001b[32m[07/08 11:27:21 d2.evaluation.evaluator]: \u001b[0mInference done 47/146. Dataloading: 0.0020 s/iter. Inference: 0.0721 s/iter. Eval: 0.5021 s/iter. Total: 0.5764 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/08 11:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 56/146. Dataloading: 0.0020 s/iter. Inference: 0.0719 s/iter. Eval: 0.5023 s/iter. Total: 0.5765 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/08 11:27:32 d2.evaluation.evaluator]: \u001b[0mInference done 64/146. Dataloading: 0.0023 s/iter. Inference: 0.0723 s/iter. Eval: 0.5102 s/iter. Total: 0.5852 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/08 11:27:37 d2.evaluation.evaluator]: \u001b[0mInference done 73/146. Dataloading: 0.0023 s/iter. Inference: 0.0725 s/iter. Eval: 0.5150 s/iter. Total: 0.5901 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/08 11:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 82/146. Dataloading: 0.0022 s/iter. Inference: 0.0726 s/iter. Eval: 0.5149 s/iter. Total: 0.5899 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/08 11:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 91/146. Dataloading: 0.0022 s/iter. Inference: 0.0730 s/iter. Eval: 0.5145 s/iter. Total: 0.5899 s/iter. ETA=0:00:32\n",
      "\u001b[32m[07/08 11:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 101/146. Dataloading: 0.0021 s/iter. Inference: 0.0728 s/iter. Eval: 0.5076 s/iter. Total: 0.5828 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/08 11:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 110/146. Dataloading: 0.0021 s/iter. Inference: 0.0733 s/iter. Eval: 0.5127 s/iter. Total: 0.5883 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/08 11:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 120/146. Dataloading: 0.0020 s/iter. Inference: 0.0728 s/iter. Eval: 0.5060 s/iter. Total: 0.5811 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/08 11:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 131/146. Dataloading: 0.0020 s/iter. Inference: 0.0725 s/iter. Eval: 0.4978 s/iter. Total: 0.5725 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/08 11:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 141/146. Dataloading: 0.0019 s/iter. Inference: 0.0721 s/iter. Eval: 0.4942 s/iter. Total: 0.5685 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/08 11:28:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:20.535709 (0.571175 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 11:28:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.072064 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 11:28:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/08 11:28:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to TomatoMAP/TomatoMAP-Seg/output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/08 11:28:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "evaluate failed: 'info'\n",
      "Epoch 2: evaluate failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45811/3081507412.py\", line 123, in _do_eval\n",
      "    results = inference_on_dataset(self.trainer.model, val_loader, evaluator)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py\", line 215, in inference_on_dataset\n",
      "    results = evaluator.evaluate()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 206, in evaluate\n",
      "    self._eval_predictions(predictions, img_ids=img_ids)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 266, in _eval_predictions\n",
      "    _evaluate_predictions_on_coco(\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 590, in _evaluate_predictions_on_coco\n",
      "    coco_dt = coco_gt.loadRes(coco_results)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/pycocotools/coco.py\", line 314, in loadRes\n",
      "    res.dataset['info'] = copy.deepcopy(self.dataset['info'])\n",
      "KeyError: 'info'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/08 11:28:27 d2.utils.events]: \u001b[0m eta: 1:04:55  iter: 2139  total_loss: 1.267  loss_cls: 0.4857  loss_box_reg: 0.5727  loss_mask: 0.1209  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.05304    time: 0.4599  last_time: 0.4747  data_time: 0.0167  last_data_time: 0.0128   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:28:36 d2.utils.events]: \u001b[0m eta: 1:04:47  iter: 2159  total_loss: 1.277  loss_cls: 0.4924  loss_box_reg: 0.6015  loss_mask: 0.1049  loss_rpn_cls: 0.02222  loss_rpn_loc: 0.04174    time: 0.4599  last_time: 0.4501  data_time: 0.0235  last_data_time: 0.0175   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:28:45 d2.utils.events]: \u001b[0m eta: 1:04:39  iter: 2179  total_loss: 1.365  loss_cls: 0.4906  loss_box_reg: 0.6578  loss_mask: 0.1222  loss_rpn_cls: 0.02158  loss_rpn_loc: 0.05989    time: 0.4599  last_time: 0.3961  data_time: 0.0164  last_data_time: 0.0075   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:28:55 d2.utils.events]: \u001b[0m eta: 1:04:31  iter: 2199  total_loss: 1.198  loss_cls: 0.4551  loss_box_reg: 0.5811  loss_mask: 0.1216  loss_rpn_cls: 0.01599  loss_rpn_loc: 0.05351    time: 0.4600  last_time: 0.4327  data_time: 0.0214  last_data_time: 0.0211   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:29:04 d2.utils.events]: \u001b[0m eta: 1:04:24  iter: 2219  total_loss: 1.286  loss_cls: 0.4981  loss_box_reg: 0.6089  loss_mask: 0.1335  loss_rpn_cls: 0.02141  loss_rpn_loc: 0.05294    time: 0.4600  last_time: 0.4837  data_time: 0.0169  last_data_time: 0.0083   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:29:13 d2.utils.events]: \u001b[0m eta: 1:04:16  iter: 2239  total_loss: 1.266  loss_cls: 0.4804  loss_box_reg: 0.5932  loss_mask: 0.1123  loss_rpn_cls: 0.01751  loss_rpn_loc: 0.0531    time: 0.4601  last_time: 0.5346  data_time: 0.0213  last_data_time: 0.1100   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:29:23 d2.utils.events]: \u001b[0m eta: 1:04:05  iter: 2259  total_loss: 1.261  loss_cls: 0.511  loss_box_reg: 0.5894  loss_mask: 0.1058  loss_rpn_cls: 0.02008  loss_rpn_loc: 0.04751    time: 0.4602  last_time: 0.4144  data_time: 0.0146  last_data_time: 0.0083   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:29:32 d2.utils.events]: \u001b[0m eta: 1:04:00  iter: 2279  total_loss: 1.258  loss_cls: 0.4867  loss_box_reg: 0.5963  loss_mask: 0.1161  loss_rpn_cls: 0.01764  loss_rpn_loc: 0.05232    time: 0.4602  last_time: 0.4881  data_time: 0.0225  last_data_time: 0.0173   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:29:41 d2.utils.events]: \u001b[0m eta: 1:03:50  iter: 2299  total_loss: 1.303  loss_cls: 0.5098  loss_box_reg: 0.6401  loss_mask: 0.1068  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.05337    time: 0.4602  last_time: 0.4504  data_time: 0.0164  last_data_time: 0.0091   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:29:50 d2.utils.events]: \u001b[0m eta: 1:03:41  iter: 2319  total_loss: 1.266  loss_cls: 0.4853  loss_box_reg: 0.5969  loss_mask: 0.1183  loss_rpn_cls: 0.01515  loss_rpn_loc: 0.04518    time: 0.4602  last_time: 0.4389  data_time: 0.0137  last_data_time: 0.0086   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:30:00 d2.utils.events]: \u001b[0m eta: 1:03:36  iter: 2339  total_loss: 1.33  loss_cls: 0.4815  loss_box_reg: 0.6179  loss_mask: 0.1216  loss_rpn_cls: 0.02218  loss_rpn_loc: 0.06117    time: 0.4603  last_time: 0.4628  data_time: 0.0185  last_data_time: 0.0156   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:30:09 d2.utils.events]: \u001b[0m eta: 1:03:26  iter: 2359  total_loss: 1.215  loss_cls: 0.4744  loss_box_reg: 0.5608  loss_mask: 0.1169  loss_rpn_cls: 0.01823  loss_rpn_loc: 0.04853    time: 0.4603  last_time: 0.4259  data_time: 0.0126  last_data_time: 0.0120   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:30:18 d2.utils.events]: \u001b[0m eta: 1:03:20  iter: 2379  total_loss: 1.372  loss_cls: 0.5026  loss_box_reg: 0.6391  loss_mask: 0.1176  loss_rpn_cls: 0.01962  loss_rpn_loc: 0.05596    time: 0.4604  last_time: 0.4286  data_time: 0.0183  last_data_time: 0.0110   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:30:28 d2.utils.events]: \u001b[0m eta: 1:03:12  iter: 2399  total_loss: 1.228  loss_cls: 0.4625  loss_box_reg: 0.5739  loss_mask: 0.1087  loss_rpn_cls: 0.01627  loss_rpn_loc: 0.05363    time: 0.4605  last_time: 0.4689  data_time: 0.0134  last_data_time: 0.0119   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:30:37 d2.utils.events]: \u001b[0m eta: 1:02:59  iter: 2419  total_loss: 1.164  loss_cls: 0.4469  loss_box_reg: 0.5388  loss_mask: 0.09877  loss_rpn_cls: 0.01771  loss_rpn_loc: 0.04256    time: 0.4605  last_time: 0.4409  data_time: 0.0129  last_data_time: 0.0090   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:30:46 d2.utils.events]: \u001b[0m eta: 1:02:52  iter: 2439  total_loss: 1.305  loss_cls: 0.4873  loss_box_reg: 0.6156  loss_mask: 0.1094  loss_rpn_cls: 0.01828  loss_rpn_loc: 0.0543    time: 0.4605  last_time: 0.4551  data_time: 0.0123  last_data_time: 0.0129   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:30:56 d2.utils.events]: \u001b[0m eta: 1:02:45  iter: 2459  total_loss: 1.301  loss_cls: 0.4651  loss_box_reg: 0.603  loss_mask: 0.1229  loss_rpn_cls: 0.01972  loss_rpn_loc: 0.05724    time: 0.4606  last_time: 0.4727  data_time: 0.0220  last_data_time: 0.0160   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:31:05 d2.utils.events]: \u001b[0m eta: 1:02:36  iter: 2479  total_loss: 1.159  loss_cls: 0.4427  loss_box_reg: 0.5439  loss_mask: 0.1257  loss_rpn_cls: 0.0178  loss_rpn_loc: 0.05694    time: 0.4606  last_time: 0.4451  data_time: 0.0128  last_data_time: 0.0091   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:31:14 d2.utils.events]: \u001b[0m eta: 1:02:27  iter: 2499  total_loss: 1.309  loss_cls: 0.4857  loss_box_reg: 0.587  loss_mask: 0.1106  loss_rpn_cls: 0.01802  loss_rpn_loc: 0.05714    time: 0.4605  last_time: 0.4361  data_time: 0.0105  last_data_time: 0.0075   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:31:23 d2.utils.events]: \u001b[0m eta: 1:02:18  iter: 2519  total_loss: 1.26  loss_cls: 0.4597  loss_box_reg: 0.606  loss_mask: 0.1186  loss_rpn_cls: 0.0238  loss_rpn_loc: 0.05666    time: 0.4605  last_time: 0.4380  data_time: 0.0115  last_data_time: 0.0108   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:31:33 d2.utils.events]: \u001b[0m eta: 1:02:10  iter: 2539  total_loss: 1.257  loss_cls: 0.4715  loss_box_reg: 0.6174  loss_mask: 0.1132  loss_rpn_cls: 0.01799  loss_rpn_loc: 0.04691    time: 0.4606  last_time: 0.4382  data_time: 0.0111  last_data_time: 0.0089   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:31:42 d2.utils.events]: \u001b[0m eta: 1:01:58  iter: 2559  total_loss: 1.165  loss_cls: 0.435  loss_box_reg: 0.5514  loss_mask: 0.1154  loss_rpn_cls: 0.0174  loss_rpn_loc: 0.04919    time: 0.4606  last_time: 0.4397  data_time: 0.0140  last_data_time: 0.0085   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:31:52 d2.utils.events]: \u001b[0m eta: 1:01:48  iter: 2579  total_loss: 1.206  loss_cls: 0.4592  loss_box_reg: 0.5756  loss_mask: 0.1059  loss_rpn_cls: 0.01368  loss_rpn_loc: 0.05433    time: 0.4607  last_time: 0.5827  data_time: 0.0344  last_data_time: 0.1502   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:32:01 d2.utils.events]: \u001b[0m eta: 1:01:41  iter: 2599  total_loss: 1.177  loss_cls: 0.4557  loss_box_reg: 0.5605  loss_mask: 0.1033  loss_rpn_cls: 0.01798  loss_rpn_loc: 0.04882    time: 0.4608  last_time: 0.5047  data_time: 0.0237  last_data_time: 0.0067   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:32:11 d2.utils.events]: \u001b[0m eta: 1:01:35  iter: 2619  total_loss: 1.274  loss_cls: 0.4689  loss_box_reg: 0.6233  loss_mask: 0.1288  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.04163    time: 0.4610  last_time: 0.4641  data_time: 0.0256  last_data_time: 0.0090   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:32:20 d2.utils.events]: \u001b[0m eta: 1:01:26  iter: 2639  total_loss: 1.203  loss_cls: 0.4572  loss_box_reg: 0.5424  loss_mask: 0.119  loss_rpn_cls: 0.01493  loss_rpn_loc: 0.05062    time: 0.4610  last_time: 0.4475  data_time: 0.0142  last_data_time: 0.0158   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:32:29 d2.utils.events]: \u001b[0m eta: 1:01:17  iter: 2659  total_loss: 1.306  loss_cls: 0.4974  loss_box_reg: 0.5974  loss_mask: 0.1028  loss_rpn_cls: 0.01855  loss_rpn_loc: 0.05417    time: 0.4610  last_time: 0.4457  data_time: 0.0228  last_data_time: 0.0077   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:32:38 d2.utils.events]: \u001b[0m eta: 1:01:07  iter: 2679  total_loss: 1.243  loss_cls: 0.4458  loss_box_reg: 0.578  loss_mask: 0.1129  loss_rpn_cls: 0.01874  loss_rpn_loc: 0.05241    time: 0.4610  last_time: 0.4451  data_time: 0.0127  last_data_time: 0.0071   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:32:47 d2.utils.events]: \u001b[0m eta: 1:00:55  iter: 2699  total_loss: 1.248  loss_cls: 0.456  loss_box_reg: 0.5729  loss_mask: 0.1138  loss_rpn_cls: 0.01981  loss_rpn_loc: 0.05831    time: 0.4609  last_time: 0.4667  data_time: 0.0109  last_data_time: 0.0168   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:32:56 d2.utils.events]: \u001b[0m eta: 1:00:45  iter: 2719  total_loss: 1.263  loss_cls: 0.44  loss_box_reg: 0.5634  loss_mask: 0.1151  loss_rpn_cls: 0.01731  loss_rpn_loc: 0.05911    time: 0.4608  last_time: 0.4832  data_time: 0.0100  last_data_time: 0.0083   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:33:06 d2.utils.events]: \u001b[0m eta: 1:00:35  iter: 2739  total_loss: 1.236  loss_cls: 0.4665  loss_box_reg: 0.577  loss_mask: 0.1182  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.04673    time: 0.4608  last_time: 0.4656  data_time: 0.0119  last_data_time: 0.0093   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:33:15 d2.utils.events]: \u001b[0m eta: 1:00:25  iter: 2759  total_loss: 1.258  loss_cls: 0.4473  loss_box_reg: 0.5839  loss_mask: 0.1048  loss_rpn_cls: 0.01756  loss_rpn_loc: 0.05286    time: 0.4609  last_time: 0.6009  data_time: 0.0228  last_data_time: 0.1386   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:33:24 d2.utils.events]: \u001b[0m eta: 1:00:16  iter: 2779  total_loss: 1.243  loss_cls: 0.4769  loss_box_reg: 0.599  loss_mask: 0.1068  loss_rpn_cls: 0.01882  loss_rpn_loc: 0.05336    time: 0.4609  last_time: 0.4853  data_time: 0.0198  last_data_time: 0.0090   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:33:34 d2.utils.events]: \u001b[0m eta: 1:00:06  iter: 2799  total_loss: 1.202  loss_cls: 0.468  loss_box_reg: 0.5713  loss_mask: 0.09855  loss_rpn_cls: 0.01821  loss_rpn_loc: 0.04198    time: 0.4610  last_time: 0.4565  data_time: 0.0177  last_data_time: 0.0167   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:33:43 d2.utils.events]: \u001b[0m eta: 0:59:56  iter: 2819  total_loss: 1.236  loss_cls: 0.464  loss_box_reg: 0.606  loss_mask: 0.08882  loss_rpn_cls: 0.01368  loss_rpn_loc: 0.05136    time: 0.4610  last_time: 0.4389  data_time: 0.0161  last_data_time: 0.0117   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:33:52 d2.utils.events]: \u001b[0m eta: 0:59:47  iter: 2839  total_loss: 1.107  loss_cls: 0.4044  loss_box_reg: 0.5289  loss_mask: 0.1111  loss_rpn_cls: 0.01781  loss_rpn_loc: 0.04105    time: 0.4610  last_time: 0.3782  data_time: 0.0299  last_data_time: 0.0072   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:34:01 d2.utils.events]: \u001b[0m eta: 0:59:38  iter: 2859  total_loss: 1.179  loss_cls: 0.4382  loss_box_reg: 0.5662  loss_mask: 0.1078  loss_rpn_cls: 0.01699  loss_rpn_loc: 0.04321    time: 0.4610  last_time: 0.4779  data_time: 0.0125  last_data_time: 0.0178   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:34:11 d2.utils.events]: \u001b[0m eta: 0:59:29  iter: 2879  total_loss: 1.305  loss_cls: 0.4732  loss_box_reg: 0.6157  loss_mask: 0.1255  loss_rpn_cls: 0.01866  loss_rpn_loc: 0.06884    time: 0.4610  last_time: 0.4752  data_time: 0.0185  last_data_time: 0.0144   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:34:21 d2.utils.events]: \u001b[0m eta: 0:59:19  iter: 2899  total_loss: 1.33  loss_cls: 0.4927  loss_box_reg: 0.6192  loss_mask: 0.1081  loss_rpn_cls: 0.02048  loss_rpn_loc: 0.05941    time: 0.4612  last_time: 0.4774  data_time: 0.0282  last_data_time: 0.0109   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:34:30 d2.utils.events]: \u001b[0m eta: 0:59:10  iter: 2919  total_loss: 1.167  loss_cls: 0.4361  loss_box_reg: 0.5619  loss_mask: 0.1057  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.04149    time: 0.4613  last_time: 0.6515  data_time: 0.0162  last_data_time: 0.0082   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:34:39 d2.utils.events]: \u001b[0m eta: 0:59:01  iter: 2939  total_loss: 1.262  loss_cls: 0.479  loss_box_reg: 0.5828  loss_mask: 0.1152  loss_rpn_cls: 0.01667  loss_rpn_loc: 0.04394    time: 0.4613  last_time: 0.4290  data_time: 0.0185  last_data_time: 0.0022   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:34:48 d2.utils.events]: \u001b[0m eta: 0:58:51  iter: 2959  total_loss: 1.174  loss_cls: 0.4455  loss_box_reg: 0.5412  loss_mask: 0.103  loss_rpn_cls: 0.01425  loss_rpn_loc: 0.0444    time: 0.4613  last_time: 0.4693  data_time: 0.0120  last_data_time: 0.0219   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:34:58 d2.utils.events]: \u001b[0m eta: 0:58:42  iter: 2979  total_loss: 1.204  loss_cls: 0.4685  loss_box_reg: 0.5807  loss_mask: 0.1154  loss_rpn_cls: 0.01731  loss_rpn_loc: 0.06123    time: 0.4614  last_time: 0.4351  data_time: 0.0288  last_data_time: 0.0022   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:35:07 d2.utils.events]: \u001b[0m eta: 0:58:33  iter: 2999  total_loss: 1.247  loss_cls: 0.4654  loss_box_reg: 0.6051  loss_mask: 0.1097  loss_rpn_cls: 0.01886  loss_rpn_loc: 0.05447    time: 0.4614  last_time: 0.4792  data_time: 0.0239  last_data_time: 0.0145   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:35:17 d2.utils.events]: \u001b[0m eta: 0:58:23  iter: 3019  total_loss: 1.226  loss_cls: 0.4601  loss_box_reg: 0.5703  loss_mask: 0.1052  loss_rpn_cls: 0.01753  loss_rpn_loc: 0.05375    time: 0.4615  last_time: 0.4384  data_time: 0.0194  last_data_time: 0.0101   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:35:26 d2.utils.events]: \u001b[0m eta: 0:58:14  iter: 3039  total_loss: 1.238  loss_cls: 0.4527  loss_box_reg: 0.6043  loss_mask: 0.1049  loss_rpn_cls: 0.0206  loss_rpn_loc: 0.05288    time: 0.4615  last_time: 0.4609  data_time: 0.0214  last_data_time: 0.0151   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:35:35 d2.utils.events]: \u001b[0m eta: 0:58:05  iter: 3059  total_loss: 1.192  loss_cls: 0.4152  loss_box_reg: 0.5708  loss_mask: 0.111  loss_rpn_cls: 0.01815  loss_rpn_loc: 0.05399    time: 0.4615  last_time: 0.4444  data_time: 0.0115  last_data_time: 0.0097   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:35:44 d2.utils.events]: \u001b[0m eta: 0:57:54  iter: 3079  total_loss: 1.167  loss_cls: 0.4516  loss_box_reg: 0.5718  loss_mask: 0.09729  loss_rpn_cls: 0.01464  loss_rpn_loc: 0.04559    time: 0.4615  last_time: 0.5676  data_time: 0.0225  last_data_time: 0.1246   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:35:54 d2.utils.events]: \u001b[0m eta: 0:57:44  iter: 3099  total_loss: 1.285  loss_cls: 0.4698  loss_box_reg: 0.5916  loss_mask: 0.1089  loss_rpn_cls: 0.01903  loss_rpn_loc: 0.05499    time: 0.4616  last_time: 0.4501  data_time: 0.0387  last_data_time: 0.0053   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:36:03 d2.utils.events]: \u001b[0m eta: 0:57:34  iter: 3119  total_loss: 1.222  loss_cls: 0.4439  loss_box_reg: 0.5887  loss_mask: 0.1225  loss_rpn_cls: 0.01685  loss_rpn_loc: 0.05549    time: 0.4616  last_time: 0.4673  data_time: 0.0196  last_data_time: 0.0069   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:36:13 d2.utils.events]: \u001b[0m eta: 0:57:25  iter: 3139  total_loss: 1.142  loss_cls: 0.4324  loss_box_reg: 0.5433  loss_mask: 0.1099  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.05248    time: 0.4617  last_time: 0.4519  data_time: 0.0299  last_data_time: 0.0053   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:36:22 d2.utils.events]: \u001b[0m eta: 0:57:18  iter: 3159  total_loss: 1.172  loss_cls: 0.4548  loss_box_reg: 0.5671  loss_mask: 0.09798  loss_rpn_cls: 0.01656  loss_rpn_loc: 0.04227    time: 0.4617  last_time: 0.4740  data_time: 0.0348  last_data_time: 0.0105   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:36:32 d2.utils.events]: \u001b[0m eta: 0:57:07  iter: 3179  total_loss: 1.16  loss_cls: 0.4455  loss_box_reg: 0.5601  loss_mask: 0.1036  loss_rpn_cls: 0.01925  loss_rpn_loc: 0.04676    time: 0.4618  last_time: 0.4362  data_time: 0.0367  last_data_time: 0.0163   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:36:32 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 11:36:32 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/08 11:36:32 d2.data.datasets.coco]: \u001b[0mLoaded 146 images in COCO format from /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Seg/cocoOut/val.json\n",
      "\u001b[32m[07/08 11:36:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/08 11:36:32 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/08 11:36:32 d2.data.common]: \u001b[0mSerializing 146 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/08 11:36:32 d2.data.common]: \u001b[0mSerialized dataset takes 5.22 MiB\n",
      "\u001b[32m[07/08 11:36:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 146 batches\n",
      "\u001b[32m[07/08 11:36:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/146. Dataloading: 0.0025 s/iter. Inference: 0.0683 s/iter. Eval: 1.4877 s/iter. Total: 1.5585 s/iter. ETA=0:03:30\n",
      "\u001b[32m[07/08 11:36:57 d2.evaluation.evaluator]: \u001b[0mInference done 15/146. Dataloading: 0.0018 s/iter. Inference: 0.0679 s/iter. Eval: 1.4780 s/iter. Total: 1.5482 s/iter. ETA=0:03:22\n",
      "\u001b[32m[07/08 11:37:02 d2.evaluation.evaluator]: \u001b[0mInference done 18/146. Dataloading: 0.0018 s/iter. Inference: 0.0678 s/iter. Eval: 1.5203 s/iter. Total: 1.5905 s/iter. ETA=0:03:23\n",
      "\u001b[32m[07/08 11:37:08 d2.evaluation.evaluator]: \u001b[0mInference done 22/146. Dataloading: 0.0019 s/iter. Inference: 0.0669 s/iter. Eval: 1.4856 s/iter. Total: 1.5549 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/08 11:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 25/146. Dataloading: 0.0019 s/iter. Inference: 0.0676 s/iter. Eval: 1.5644 s/iter. Total: 1.6344 s/iter. ETA=0:03:17\n",
      "\u001b[32m[07/08 11:37:20 d2.evaluation.evaluator]: \u001b[0mInference done 28/146. Dataloading: 0.0020 s/iter. Inference: 0.0680 s/iter. Eval: 1.6079 s/iter. Total: 1.6785 s/iter. ETA=0:03:18\n",
      "\u001b[32m[07/08 11:37:26 d2.evaluation.evaluator]: \u001b[0mInference done 31/146. Dataloading: 0.0020 s/iter. Inference: 0.0685 s/iter. Eval: 1.6287 s/iter. Total: 1.6998 s/iter. ETA=0:03:15\n",
      "\u001b[32m[07/08 11:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 35/146. Dataloading: 0.0020 s/iter. Inference: 0.0684 s/iter. Eval: 1.6049 s/iter. Total: 1.6758 s/iter. ETA=0:03:06\n",
      "\u001b[32m[07/08 11:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 39/146. Dataloading: 0.0020 s/iter. Inference: 0.0683 s/iter. Eval: 1.6102 s/iter. Total: 1.6811 s/iter. ETA=0:02:59\n",
      "\u001b[32m[07/08 11:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 42/146. Dataloading: 0.0020 s/iter. Inference: 0.0686 s/iter. Eval: 1.6397 s/iter. Total: 1.7109 s/iter. ETA=0:02:57\n",
      "\u001b[32m[07/08 11:37:51 d2.evaluation.evaluator]: \u001b[0mInference done 45/146. Dataloading: 0.0020 s/iter. Inference: 0.0687 s/iter. Eval: 1.6579 s/iter. Total: 1.7292 s/iter. ETA=0:02:54\n",
      "\u001b[32m[07/08 11:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 49/146. Dataloading: 0.0020 s/iter. Inference: 0.0690 s/iter. Eval: 1.6533 s/iter. Total: 1.7250 s/iter. ETA=0:02:47\n",
      "\u001b[32m[07/08 11:38:04 d2.evaluation.evaluator]: \u001b[0mInference done 52/146. Dataloading: 0.0021 s/iter. Inference: 0.0693 s/iter. Eval: 1.6801 s/iter. Total: 1.7520 s/iter. ETA=0:02:44\n",
      "\u001b[32m[07/08 11:38:11 d2.evaluation.evaluator]: \u001b[0mInference done 56/146. Dataloading: 0.0021 s/iter. Inference: 0.0694 s/iter. Eval: 1.6882 s/iter. Total: 1.7603 s/iter. ETA=0:02:38\n",
      "\u001b[32m[07/08 11:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 59/146. Dataloading: 0.0021 s/iter. Inference: 0.0698 s/iter. Eval: 1.7109 s/iter. Total: 1.7834 s/iter. ETA=0:02:35\n",
      "\u001b[32m[07/08 11:38:24 d2.evaluation.evaluator]: \u001b[0mInference done 63/146. Dataloading: 0.0021 s/iter. Inference: 0.0696 s/iter. Eval: 1.6986 s/iter. Total: 1.7708 s/iter. ETA=0:02:26\n",
      "\u001b[32m[07/08 11:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 66/146. Dataloading: 0.0021 s/iter. Inference: 0.0698 s/iter. Eval: 1.7121 s/iter. Total: 1.7846 s/iter. ETA=0:02:22\n",
      "\u001b[32m[07/08 11:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 70/146. Dataloading: 0.0020 s/iter. Inference: 0.0696 s/iter. Eval: 1.6871 s/iter. Total: 1.7593 s/iter. ETA=0:02:13\n",
      "\u001b[32m[07/08 11:38:42 d2.evaluation.evaluator]: \u001b[0mInference done 73/146. Dataloading: 0.0020 s/iter. Inference: 0.0699 s/iter. Eval: 1.7069 s/iter. Total: 1.7794 s/iter. ETA=0:02:09\n",
      "\u001b[32m[07/08 11:38:48 d2.evaluation.evaluator]: \u001b[0mInference done 75/146. Dataloading: 0.0020 s/iter. Inference: 0.0703 s/iter. Eval: 1.7321 s/iter. Total: 1.8050 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/08 11:38:54 d2.evaluation.evaluator]: \u001b[0mInference done 78/146. Dataloading: 0.0020 s/iter. Inference: 0.0704 s/iter. Eval: 1.7387 s/iter. Total: 1.8116 s/iter. ETA=0:02:03\n",
      "\u001b[32m[07/08 11:38:59 d2.evaluation.evaluator]: \u001b[0mInference done 82/146. Dataloading: 0.0020 s/iter. Inference: 0.0703 s/iter. Eval: 1.7188 s/iter. Total: 1.7917 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/08 11:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 86/146. Dataloading: 0.0020 s/iter. Inference: 0.0704 s/iter. Eval: 1.7027 s/iter. Total: 1.7756 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/08 11:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 89/146. Dataloading: 0.0020 s/iter. Inference: 0.0705 s/iter. Eval: 1.7037 s/iter. Total: 1.7768 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/08 11:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 92/146. Dataloading: 0.0020 s/iter. Inference: 0.0707 s/iter. Eval: 1.7143 s/iter. Total: 1.7876 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/08 11:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 96/146. Dataloading: 0.0020 s/iter. Inference: 0.0704 s/iter. Eval: 1.6932 s/iter. Total: 1.7662 s/iter. ETA=0:01:28\n",
      "\u001b[32m[07/08 11:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 99/146. Dataloading: 0.0020 s/iter. Inference: 0.0706 s/iter. Eval: 1.6982 s/iter. Total: 1.7714 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/08 11:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 103/146. Dataloading: 0.0019 s/iter. Inference: 0.0704 s/iter. Eval: 1.6824 s/iter. Total: 1.7554 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/08 11:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 106/146. Dataloading: 0.0019 s/iter. Inference: 0.0704 s/iter. Eval: 1.6803 s/iter. Total: 1.7532 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/08 11:39:45 d2.evaluation.evaluator]: \u001b[0mInference done 109/146. Dataloading: 0.0020 s/iter. Inference: 0.0706 s/iter. Eval: 1.6938 s/iter. Total: 1.7670 s/iter. ETA=0:01:05\n",
      "\u001b[32m[07/08 11:39:50 d2.evaluation.evaluator]: \u001b[0mInference done 111/146. Dataloading: 0.0020 s/iter. Inference: 0.0709 s/iter. Eval: 1.7085 s/iter. Total: 1.7819 s/iter. ETA=0:01:02\n",
      "\u001b[32m[07/08 11:39:56 d2.evaluation.evaluator]: \u001b[0mInference done 114/146. Dataloading: 0.0020 s/iter. Inference: 0.0710 s/iter. Eval: 1.7085 s/iter. Total: 1.7821 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/08 11:40:01 d2.evaluation.evaluator]: \u001b[0mInference done 118/146. Dataloading: 0.0020 s/iter. Inference: 0.0709 s/iter. Eval: 1.6961 s/iter. Total: 1.7696 s/iter. ETA=0:00:49\n",
      "\u001b[32m[07/08 11:40:07 d2.evaluation.evaluator]: \u001b[0mInference done 121/146. Dataloading: 0.0020 s/iter. Inference: 0.0710 s/iter. Eval: 1.6990 s/iter. Total: 1.7726 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/08 11:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 125/146. Dataloading: 0.0020 s/iter. Inference: 0.0709 s/iter. Eval: 1.6887 s/iter. Total: 1.7621 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/08 11:40:19 d2.evaluation.evaluator]: \u001b[0mInference done 130/146. Dataloading: 0.0020 s/iter. Inference: 0.0706 s/iter. Eval: 1.6702 s/iter. Total: 1.7434 s/iter. ETA=0:00:27\n",
      "\u001b[32m[07/08 11:40:25 d2.evaluation.evaluator]: \u001b[0mInference done 137/146. Dataloading: 0.0019 s/iter. Inference: 0.0704 s/iter. Eval: 1.6182 s/iter. Total: 1.6912 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/08 11:40:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:47.994640 (1.616983 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 11:40:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.070279 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 11:40:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/08 11:40:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to TomatoMAP/TomatoMAP-Seg/output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/08 11:40:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "evaluate failed: 'info'\n",
      "Epoch 3: evaluate failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45811/3081507412.py\", line 123, in _do_eval\n",
      "    results = inference_on_dataset(self.trainer.model, val_loader, evaluator)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py\", line 215, in inference_on_dataset\n",
      "    results = evaluator.evaluate()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 206, in evaluate\n",
      "    self._eval_predictions(predictions, img_ids=img_ids)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 266, in _eval_predictions\n",
      "    _evaluate_predictions_on_coco(\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 590, in _evaluate_predictions_on_coco\n",
      "    coco_dt = coco_gt.loadRes(coco_results)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/pycocotools/coco.py\", line 314, in loadRes\n",
      "    res.dataset['info'] = copy.deepcopy(self.dataset['info'])\n",
      "KeyError: 'info'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/08 11:40:39 d2.utils.events]: \u001b[0m eta: 0:56:57  iter: 3199  total_loss: 1.143  loss_cls: 0.4375  loss_box_reg: 0.5549  loss_mask: 0.1011  loss_rpn_cls: 0.01593  loss_rpn_loc: 0.03751    time: 0.4619  last_time: 0.4187  data_time: 0.0291  last_data_time: 0.0200   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:40:49 d2.utils.events]: \u001b[0m eta: 0:56:47  iter: 3219  total_loss: 1.233  loss_cls: 0.4635  loss_box_reg: 0.5761  loss_mask: 0.1126  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.04823    time: 0.4620  last_time: 0.7004  data_time: 0.0282  last_data_time: 0.0103   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:40:58 d2.utils.events]: \u001b[0m eta: 0:56:38  iter: 3239  total_loss: 1.146  loss_cls: 0.443  loss_box_reg: 0.5359  loss_mask: 0.09607  loss_rpn_cls: 0.01495  loss_rpn_loc: 0.05141    time: 0.4621  last_time: 0.4710  data_time: 0.0352  last_data_time: 0.0109   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:41:07 d2.utils.events]: \u001b[0m eta: 0:56:26  iter: 3259  total_loss: 1.218  loss_cls: 0.4325  loss_box_reg: 0.57  loss_mask: 0.1058  loss_rpn_cls: 0.01856  loss_rpn_loc: 0.05563    time: 0.4620  last_time: 0.4738  data_time: 0.0112  last_data_time: 0.0095   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:41:17 d2.utils.events]: \u001b[0m eta: 0:56:17  iter: 3279  total_loss: 1.191  loss_cls: 0.4545  loss_box_reg: 0.5766  loss_mask: 0.1179  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.0425    time: 0.4621  last_time: 0.5019  data_time: 0.0125  last_data_time: 0.0162   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:41:26 d2.utils.events]: \u001b[0m eta: 0:56:10  iter: 3299  total_loss: 1.164  loss_cls: 0.429  loss_box_reg: 0.5815  loss_mask: 0.1005  loss_rpn_cls: 0.01635  loss_rpn_loc: 0.05088    time: 0.4621  last_time: 0.4413  data_time: 0.0114  last_data_time: 0.0092   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:41:35 d2.utils.events]: \u001b[0m eta: 0:56:00  iter: 3319  total_loss: 1.126  loss_cls: 0.429  loss_box_reg: 0.532  loss_mask: 0.09901  loss_rpn_cls: 0.01607  loss_rpn_loc: 0.05013    time: 0.4621  last_time: 0.4438  data_time: 0.0185  last_data_time: 0.0085   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:41:44 d2.utils.events]: \u001b[0m eta: 0:55:48  iter: 3339  total_loss: 1.102  loss_cls: 0.4174  loss_box_reg: 0.5366  loss_mask: 0.1031  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.04143    time: 0.4621  last_time: 0.4924  data_time: 0.0164  last_data_time: 0.0088   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:41:53 d2.utils.events]: \u001b[0m eta: 0:55:37  iter: 3359  total_loss: 1.26  loss_cls: 0.4323  loss_box_reg: 0.5887  loss_mask: 0.1203  loss_rpn_cls: 0.01649  loss_rpn_loc: 0.05863    time: 0.4620  last_time: 0.4645  data_time: 0.0232  last_data_time: 0.0137   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:42:03 d2.utils.events]: \u001b[0m eta: 0:55:26  iter: 3379  total_loss: 1.166  loss_cls: 0.4409  loss_box_reg: 0.5701  loss_mask: 0.09969  loss_rpn_cls: 0.01675  loss_rpn_loc: 0.05699    time: 0.4621  last_time: 0.4516  data_time: 0.0215  last_data_time: 0.0045   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:42:13 d2.utils.events]: \u001b[0m eta: 0:55:18  iter: 3399  total_loss: 1.185  loss_cls: 0.4453  loss_box_reg: 0.567  loss_mask: 0.1089  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.04709    time: 0.4622  last_time: 0.4771  data_time: 0.0239  last_data_time: 0.0085   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:42:22 d2.utils.events]: \u001b[0m eta: 0:55:11  iter: 3419  total_loss: 1.153  loss_cls: 0.4172  loss_box_reg: 0.5364  loss_mask: 0.1028  loss_rpn_cls: 0.01846  loss_rpn_loc: 0.04181    time: 0.4622  last_time: 0.4454  data_time: 0.0254  last_data_time: 0.0147   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:42:31 d2.utils.events]: \u001b[0m eta: 0:55:00  iter: 3439  total_loss: 1.162  loss_cls: 0.4559  loss_box_reg: 0.5763  loss_mask: 0.102  loss_rpn_cls: 0.01339  loss_rpn_loc: 0.0427    time: 0.4623  last_time: 0.4110  data_time: 0.0223  last_data_time: 0.0162   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:42:41 d2.utils.events]: \u001b[0m eta: 0:54:52  iter: 3459  total_loss: 1.13  loss_cls: 0.4098  loss_box_reg: 0.5344  loss_mask: 0.1047  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.0409    time: 0.4623  last_time: 0.4973  data_time: 0.0199  last_data_time: 0.0115   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:42:50 d2.utils.events]: \u001b[0m eta: 0:54:44  iter: 3479  total_loss: 1.17  loss_cls: 0.4416  loss_box_reg: 0.5564  loss_mask: 0.09852  loss_rpn_cls: 0.01397  loss_rpn_loc: 0.04424    time: 0.4624  last_time: 0.4581  data_time: 0.0282  last_data_time: 0.0097   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:43:00 d2.utils.events]: \u001b[0m eta: 0:54:36  iter: 3499  total_loss: 1.122  loss_cls: 0.4113  loss_box_reg: 0.5464  loss_mask: 0.1043  loss_rpn_cls: 0.02275  loss_rpn_loc: 0.05323    time: 0.4625  last_time: 0.4609  data_time: 0.0183  last_data_time: 0.0103   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:43:09 d2.utils.events]: \u001b[0m eta: 0:54:28  iter: 3519  total_loss: 1.233  loss_cls: 0.4558  loss_box_reg: 0.5958  loss_mask: 0.1089  loss_rpn_cls: 0.01599  loss_rpn_loc: 0.05552    time: 0.4625  last_time: 0.4611  data_time: 0.0264  last_data_time: 0.0085   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:43:19 d2.utils.events]: \u001b[0m eta: 0:54:20  iter: 3539  total_loss: 1.187  loss_cls: 0.4503  loss_box_reg: 0.5737  loss_mask: 0.1035  loss_rpn_cls: 0.01823  loss_rpn_loc: 0.05047    time: 0.4626  last_time: 0.4397  data_time: 0.0232  last_data_time: 0.0084   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:43:28 d2.utils.events]: \u001b[0m eta: 0:54:14  iter: 3559  total_loss: 1.135  loss_cls: 0.4277  loss_box_reg: 0.5207  loss_mask: 0.1143  loss_rpn_cls: 0.0151  loss_rpn_loc: 0.05282    time: 0.4627  last_time: 0.4757  data_time: 0.0288  last_data_time: 0.0096   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:43:38 d2.utils.events]: \u001b[0m eta: 0:54:07  iter: 3579  total_loss: 1.22  loss_cls: 0.4449  loss_box_reg: 0.5849  loss_mask: 0.1003  loss_rpn_cls: 0.01788  loss_rpn_loc: 0.05187    time: 0.4628  last_time: 0.4239  data_time: 0.0280  last_data_time: 0.0021   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:43:47 d2.utils.events]: \u001b[0m eta: 0:53:55  iter: 3599  total_loss: 1.198  loss_cls: 0.4291  loss_box_reg: 0.5583  loss_mask: 0.1094  loss_rpn_cls: 0.02017  loss_rpn_loc: 0.052    time: 0.4629  last_time: 0.5749  data_time: 0.0307  last_data_time: 0.1069   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:43:57 d2.utils.events]: \u001b[0m eta: 0:53:43  iter: 3619  total_loss: 1.101  loss_cls: 0.4013  loss_box_reg: 0.4984  loss_mask: 0.08852  loss_rpn_cls: 0.01541  loss_rpn_loc: 0.04422    time: 0.4629  last_time: 0.4559  data_time: 0.0248  last_data_time: 0.0089   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:44:06 d2.utils.events]: \u001b[0m eta: 0:53:34  iter: 3639  total_loss: 1.079  loss_cls: 0.4168  loss_box_reg: 0.5202  loss_mask: 0.101  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.04368    time: 0.4629  last_time: 0.4927  data_time: 0.0206  last_data_time: 0.0103   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:44:16 d2.utils.events]: \u001b[0m eta: 0:53:25  iter: 3659  total_loss: 1.164  loss_cls: 0.4252  loss_box_reg: 0.58  loss_mask: 0.1071  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.05105    time: 0.4630  last_time: 0.4416  data_time: 0.0296  last_data_time: 0.0100   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:44:25 d2.utils.events]: \u001b[0m eta: 0:53:16  iter: 3679  total_loss: 1.081  loss_cls: 0.4275  loss_box_reg: 0.5291  loss_mask: 0.08534  loss_rpn_cls: 0.01311  loss_rpn_loc: 0.04136    time: 0.4630  last_time: 0.4661  data_time: 0.0124  last_data_time: 0.0104   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:44:34 d2.utils.events]: \u001b[0m eta: 0:53:09  iter: 3699  total_loss: 1.179  loss_cls: 0.4231  loss_box_reg: 0.5806  loss_mask: 0.1059  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.05872    time: 0.4630  last_time: 0.4741  data_time: 0.0116  last_data_time: 0.0258   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:44:44 d2.utils.events]: \u001b[0m eta: 0:53:00  iter: 3719  total_loss: 1.16  loss_cls: 0.4224  loss_box_reg: 0.5605  loss_mask: 0.103  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.05338    time: 0.4630  last_time: 0.4257  data_time: 0.0108  last_data_time: 0.0074   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:44:53 d2.utils.events]: \u001b[0m eta: 0:52:51  iter: 3739  total_loss: 1.068  loss_cls: 0.4007  loss_box_reg: 0.5087  loss_mask: 0.1021  loss_rpn_cls: 0.01723  loss_rpn_loc: 0.04595    time: 0.4631  last_time: 0.4882  data_time: 0.0224  last_data_time: 0.0088   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:45:03 d2.utils.events]: \u001b[0m eta: 0:52:43  iter: 3759  total_loss: 1.134  loss_cls: 0.4326  loss_box_reg: 0.5505  loss_mask: 0.0996  loss_rpn_cls: 0.01611  loss_rpn_loc: 0.04392    time: 0.4632  last_time: 0.4530  data_time: 0.0340  last_data_time: 0.0150   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:45:12 d2.utils.events]: \u001b[0m eta: 0:52:34  iter: 3779  total_loss: 1.06  loss_cls: 0.393  loss_box_reg: 0.5066  loss_mask: 0.1045  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.04144    time: 0.4631  last_time: 0.4633  data_time: 0.0124  last_data_time: 0.0135   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:45:21 d2.utils.events]: \u001b[0m eta: 0:52:24  iter: 3799  total_loss: 1.148  loss_cls: 0.413  loss_box_reg: 0.5612  loss_mask: 0.1144  loss_rpn_cls: 0.01542  loss_rpn_loc: 0.05175    time: 0.4631  last_time: 0.4675  data_time: 0.0114  last_data_time: 0.0099   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:45:30 d2.utils.events]: \u001b[0m eta: 0:52:16  iter: 3819  total_loss: 1.03  loss_cls: 0.4175  loss_box_reg: 0.4917  loss_mask: 0.09459  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.03708    time: 0.4632  last_time: 0.4903  data_time: 0.0263  last_data_time: 0.0064   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:45:40 d2.utils.events]: \u001b[0m eta: 0:52:11  iter: 3839  total_loss: 1.161  loss_cls: 0.435  loss_box_reg: 0.5524  loss_mask: 0.106  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.05063    time: 0.4633  last_time: 0.6252  data_time: 0.0343  last_data_time: 0.1359   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:45:50 d2.utils.events]: \u001b[0m eta: 0:52:05  iter: 3859  total_loss: 1.122  loss_cls: 0.4291  loss_box_reg: 0.5573  loss_mask: 0.09278  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.04596    time: 0.4634  last_time: 0.4212  data_time: 0.0147  last_data_time: 0.0146   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:45:59 d2.utils.events]: \u001b[0m eta: 0:51:54  iter: 3879  total_loss: 1.143  loss_cls: 0.4091  loss_box_reg: 0.5283  loss_mask: 0.08868  loss_rpn_cls: 0.01575  loss_rpn_loc: 0.04949    time: 0.4633  last_time: 0.4466  data_time: 0.0125  last_data_time: 0.0162   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:46:08 d2.utils.events]: \u001b[0m eta: 0:51:40  iter: 3899  total_loss: 1.092  loss_cls: 0.4085  loss_box_reg: 0.507  loss_mask: 0.1027  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.04899    time: 0.4633  last_time: 0.4378  data_time: 0.0155  last_data_time: 0.0133   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:46:17 d2.utils.events]: \u001b[0m eta: 0:51:30  iter: 3919  total_loss: 1.188  loss_cls: 0.4327  loss_box_reg: 0.5759  loss_mask: 0.1177  loss_rpn_cls: 0.01982  loss_rpn_loc: 0.05489    time: 0.4633  last_time: 0.4460  data_time: 0.0119  last_data_time: 0.0171   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:46:27 d2.utils.events]: \u001b[0m eta: 0:51:18  iter: 3939  total_loss: 1.19  loss_cls: 0.4506  loss_box_reg: 0.572  loss_mask: 0.09628  loss_rpn_cls: 0.01487  loss_rpn_loc: 0.0618    time: 0.4633  last_time: 0.4603  data_time: 0.0108  last_data_time: 0.0090   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:46:36 d2.utils.events]: \u001b[0m eta: 0:51:10  iter: 3959  total_loss: 1.018  loss_cls: 0.374  loss_box_reg: 0.5073  loss_mask: 0.09451  loss_rpn_cls: 0.01408  loss_rpn_loc: 0.03916    time: 0.4632  last_time: 0.4339  data_time: 0.0107  last_data_time: 0.0088   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:46:45 d2.utils.events]: \u001b[0m eta: 0:51:01  iter: 3979  total_loss: 1.115  loss_cls: 0.3929  loss_box_reg: 0.5463  loss_mask: 0.09866  loss_rpn_cls: 0.01181  loss_rpn_loc: 0.04657    time: 0.4632  last_time: 0.4636  data_time: 0.0122  last_data_time: 0.0113   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:46:54 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 3999  total_loss: 1.119  loss_cls: 0.4101  loss_box_reg: 0.5597  loss_mask: 0.1048  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.04625    time: 0.4632  last_time: 0.4589  data_time: 0.0235  last_data_time: 0.0129   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:47:03 d2.utils.events]: \u001b[0m eta: 0:50:39  iter: 4019  total_loss: 1.129  loss_cls: 0.3966  loss_box_reg: 0.533  loss_mask: 0.0962  loss_rpn_cls: 0.01722  loss_rpn_loc: 0.04816    time: 0.4632  last_time: 0.4821  data_time: 0.0115  last_data_time: 0.0084   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:47:13 d2.utils.events]: \u001b[0m eta: 0:50:29  iter: 4039  total_loss: 1.124  loss_cls: 0.4161  loss_box_reg: 0.532  loss_mask: 0.09748  loss_rpn_cls: 0.01445  loss_rpn_loc: 0.06044    time: 0.4632  last_time: 0.4475  data_time: 0.0158  last_data_time: 0.0106   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:47:22 d2.utils.events]: \u001b[0m eta: 0:50:22  iter: 4059  total_loss: 1.105  loss_cls: 0.398  loss_box_reg: 0.5359  loss_mask: 0.1056  loss_rpn_cls: 0.01349  loss_rpn_loc: 0.0499    time: 0.4633  last_time: 0.4275  data_time: 0.0361  last_data_time: 0.0118   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:47:31 d2.utils.events]: \u001b[0m eta: 0:50:13  iter: 4079  total_loss: 1.043  loss_cls: 0.379  loss_box_reg: 0.484  loss_mask: 0.08808  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.04056    time: 0.4633  last_time: 0.4428  data_time: 0.0149  last_data_time: 0.0110   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:47:41 d2.utils.events]: \u001b[0m eta: 0:50:03  iter: 4099  total_loss: 1.153  loss_cls: 0.4361  loss_box_reg: 0.5358  loss_mask: 0.1034  loss_rpn_cls: 0.01437  loss_rpn_loc: 0.05569    time: 0.4632  last_time: 0.4723  data_time: 0.0159  last_data_time: 0.0075   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:47:50 d2.utils.events]: \u001b[0m eta: 0:49:54  iter: 4119  total_loss: 1.162  loss_cls: 0.4019  loss_box_reg: 0.5603  loss_mask: 0.1063  loss_rpn_cls: 0.01767  loss_rpn_loc: 0.05394    time: 0.4632  last_time: 0.4229  data_time: 0.0152  last_data_time: 0.0092   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:47:59 d2.utils.events]: \u001b[0m eta: 0:49:46  iter: 4139  total_loss: 1.131  loss_cls: 0.4094  loss_box_reg: 0.5321  loss_mask: 0.09403  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.0473    time: 0.4632  last_time: 0.4496  data_time: 0.0130  last_data_time: 0.0179   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:48:09 d2.utils.events]: \u001b[0m eta: 0:49:38  iter: 4159  total_loss: 1.216  loss_cls: 0.4416  loss_box_reg: 0.5909  loss_mask: 0.1029  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.05562    time: 0.4633  last_time: 0.4177  data_time: 0.0290  last_data_time: 0.0076   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:48:18 d2.utils.events]: \u001b[0m eta: 0:49:30  iter: 4179  total_loss: 1.134  loss_cls: 0.4033  loss_box_reg: 0.5317  loss_mask: 0.1001  loss_rpn_cls: 0.01437  loss_rpn_loc: 0.0504    time: 0.4634  last_time: 0.4949  data_time: 0.0156  last_data_time: 0.0090   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:48:28 d2.utils.events]: \u001b[0m eta: 0:49:20  iter: 4199  total_loss: 1.086  loss_cls: 0.3871  loss_box_reg: 0.5449  loss_mask: 0.1072  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.04805    time: 0.4634  last_time: 0.4296  data_time: 0.0203  last_data_time: 0.0105   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:48:37 d2.utils.events]: \u001b[0m eta: 0:49:10  iter: 4219  total_loss: 1.082  loss_cls: 0.4286  loss_box_reg: 0.5236  loss_mask: 0.08132  loss_rpn_cls: 0.01627  loss_rpn_loc: 0.04251    time: 0.4633  last_time: 0.4594  data_time: 0.0123  last_data_time: 0.0105   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:48:46 d2.utils.events]: \u001b[0m eta: 0:49:02  iter: 4239  total_loss: 1.099  loss_cls: 0.4244  loss_box_reg: 0.5242  loss_mask: 0.1034  loss_rpn_cls: 0.01879  loss_rpn_loc: 0.04551    time: 0.4633  last_time: 0.4377  data_time: 0.0145  last_data_time: 0.0140   lr: 0.00024  max_mem: 4709M\n",
      "\u001b[32m[07/08 11:48:46 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 11:48:46 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/08 11:48:47 d2.data.datasets.coco]: \u001b[0mLoaded 146 images in COCO format from /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Seg/cocoOut/val.json\n",
      "\u001b[32m[07/08 11:48:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/08 11:48:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/08 11:48:47 d2.data.common]: \u001b[0mSerializing 146 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/08 11:48:47 d2.data.common]: \u001b[0mSerialized dataset takes 5.22 MiB\n",
      "\u001b[32m[07/08 11:48:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 146 batches\n",
      "\u001b[32m[07/08 11:49:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/146. Dataloading: 0.0027 s/iter. Inference: 0.0753 s/iter. Eval: 1.8968 s/iter. Total: 1.9748 s/iter. ETA=0:04:26\n",
      "\u001b[32m[07/08 11:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 14/146. Dataloading: 0.0021 s/iter. Inference: 0.0756 s/iter. Eval: 1.9452 s/iter. Total: 2.0235 s/iter. ETA=0:04:27\n",
      "\u001b[32m[07/08 11:49:24 d2.evaluation.evaluator]: \u001b[0mInference done 17/146. Dataloading: 0.0021 s/iter. Inference: 0.0772 s/iter. Eval: 2.0387 s/iter. Total: 2.1186 s/iter. ETA=0:04:33\n",
      "\u001b[32m[07/08 11:49:31 d2.evaluation.evaluator]: \u001b[0mInference done 20/146. Dataloading: 0.0021 s/iter. Inference: 0.0768 s/iter. Eval: 2.0448 s/iter. Total: 2.1244 s/iter. ETA=0:04:27\n",
      "\u001b[32m[07/08 11:49:37 d2.evaluation.evaluator]: \u001b[0mInference done 23/146. Dataloading: 0.0021 s/iter. Inference: 0.0763 s/iter. Eval: 2.0084 s/iter. Total: 2.0873 s/iter. ETA=0:04:16\n",
      "\u001b[32m[07/08 11:49:42 d2.evaluation.evaluator]: \u001b[0mInference done 25/146. Dataloading: 0.0021 s/iter. Inference: 0.0774 s/iter. Eval: 2.0959 s/iter. Total: 2.1759 s/iter. ETA=0:04:23\n",
      "\u001b[32m[07/08 11:49:49 d2.evaluation.evaluator]: \u001b[0mInference done 28/146. Dataloading: 0.0021 s/iter. Inference: 0.0771 s/iter. Eval: 2.0976 s/iter. Total: 2.1774 s/iter. ETA=0:04:16\n",
      "\u001b[32m[07/08 11:49:55 d2.evaluation.evaluator]: \u001b[0mInference done 31/146. Dataloading: 0.0021 s/iter. Inference: 0.0767 s/iter. Eval: 2.0777 s/iter. Total: 2.1570 s/iter. ETA=0:04:08\n",
      "\u001b[32m[07/08 11:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 34/146. Dataloading: 0.0021 s/iter. Inference: 0.0765 s/iter. Eval: 2.0601 s/iter. Total: 2.1392 s/iter. ETA=0:03:59\n",
      "\u001b[32m[07/08 11:50:08 d2.evaluation.evaluator]: \u001b[0mInference done 38/146. Dataloading: 0.0021 s/iter. Inference: 0.0757 s/iter. Eval: 2.0113 s/iter. Total: 2.0896 s/iter. ETA=0:03:45\n",
      "\u001b[32m[07/08 11:50:15 d2.evaluation.evaluator]: \u001b[0mInference done 40/146. Dataloading: 0.0021 s/iter. Inference: 0.0768 s/iter. Eval: 2.0862 s/iter. Total: 2.1657 s/iter. ETA=0:03:49\n",
      "\u001b[32m[07/08 11:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 42/146. Dataloading: 0.0021 s/iter. Inference: 0.0773 s/iter. Eval: 2.1321 s/iter. Total: 2.2122 s/iter. ETA=0:03:50\n",
      "\u001b[32m[07/08 11:50:26 d2.evaluation.evaluator]: \u001b[0mInference done 44/146. Dataloading: 0.0021 s/iter. Inference: 0.0776 s/iter. Eval: 2.1479 s/iter. Total: 2.2283 s/iter. ETA=0:03:47\n",
      "\u001b[32m[07/08 11:50:32 d2.evaluation.evaluator]: \u001b[0mInference done 47/146. Dataloading: 0.0022 s/iter. Inference: 0.0779 s/iter. Eval: 2.1443 s/iter. Total: 2.2251 s/iter. ETA=0:03:40\n",
      "\u001b[32m[07/08 11:50:41 d2.evaluation.evaluator]: \u001b[0mInference done 50/146. Dataloading: 0.0022 s/iter. Inference: 0.0784 s/iter. Eval: 2.1881 s/iter. Total: 2.2693 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/08 11:50:48 d2.evaluation.evaluator]: \u001b[0mInference done 53/146. Dataloading: 0.0022 s/iter. Inference: 0.0783 s/iter. Eval: 2.1814 s/iter. Total: 2.2626 s/iter. ETA=0:03:30\n",
      "\u001b[32m[07/08 11:50:55 d2.evaluation.evaluator]: \u001b[0mInference done 56/146. Dataloading: 0.0022 s/iter. Inference: 0.0786 s/iter. Eval: 2.1900 s/iter. Total: 2.2716 s/iter. ETA=0:03:24\n",
      "\u001b[32m[07/08 11:51:01 d2.evaluation.evaluator]: \u001b[0mInference done 58/146. Dataloading: 0.0023 s/iter. Inference: 0.0791 s/iter. Eval: 2.2128 s/iter. Total: 2.2949 s/iter. ETA=0:03:21\n",
      "\u001b[32m[07/08 11:51:06 d2.evaluation.evaluator]: \u001b[0mInference done 61/146. Dataloading: 0.0023 s/iter. Inference: 0.0788 s/iter. Eval: 2.1809 s/iter. Total: 2.2627 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/08 11:51:13 d2.evaluation.evaluator]: \u001b[0mInference done 64/146. Dataloading: 0.0022 s/iter. Inference: 0.0789 s/iter. Eval: 2.1838 s/iter. Total: 2.2656 s/iter. ETA=0:03:05\n",
      "\u001b[32m[07/08 11:51:20 d2.evaluation.evaluator]: \u001b[0mInference done 68/146. Dataloading: 0.0022 s/iter. Inference: 0.0785 s/iter. Eval: 2.1547 s/iter. Total: 2.2361 s/iter. ETA=0:02:54\n",
      "\u001b[32m[07/08 11:51:26 d2.evaluation.evaluator]: \u001b[0mInference done 71/146. Dataloading: 0.0022 s/iter. Inference: 0.0786 s/iter. Eval: 2.1527 s/iter. Total: 2.2341 s/iter. ETA=0:02:47\n",
      "\u001b[32m[07/08 11:51:31 d2.evaluation.evaluator]: \u001b[0mInference done 73/146. Dataloading: 0.0022 s/iter. Inference: 0.0787 s/iter. Eval: 2.1612 s/iter. Total: 2.2428 s/iter. ETA=0:02:43\n",
      "\u001b[32m[07/08 11:51:38 d2.evaluation.evaluator]: \u001b[0mInference done 75/146. Dataloading: 0.0022 s/iter. Inference: 0.0793 s/iter. Eval: 2.1942 s/iter. Total: 2.2764 s/iter. ETA=0:02:41\n",
      "\u001b[32m[07/08 11:51:44 d2.evaluation.evaluator]: \u001b[0mInference done 78/146. Dataloading: 0.0022 s/iter. Inference: 0.0792 s/iter. Eval: 2.1808 s/iter. Total: 2.2628 s/iter. ETA=0:02:33\n",
      "\u001b[32m[07/08 11:51:50 d2.evaluation.evaluator]: \u001b[0mInference done 81/146. Dataloading: 0.0023 s/iter. Inference: 0.0791 s/iter. Eval: 2.1661 s/iter. Total: 2.2481 s/iter. ETA=0:02:26\n",
      "\u001b[32m[07/08 11:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 85/146. Dataloading: 0.0022 s/iter. Inference: 0.0790 s/iter. Eval: 2.1360 s/iter. Total: 2.2180 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/08 11:52:03 d2.evaluation.evaluator]: \u001b[0mInference done 88/146. Dataloading: 0.0022 s/iter. Inference: 0.0791 s/iter. Eval: 2.1344 s/iter. Total: 2.2163 s/iter. ETA=0:02:08\n",
      "\u001b[32m[07/08 11:52:10 d2.evaluation.evaluator]: \u001b[0mInference done 91/146. Dataloading: 0.0022 s/iter. Inference: 0.0791 s/iter. Eval: 2.1365 s/iter. Total: 2.2185 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/08 11:52:15 d2.evaluation.evaluator]: \u001b[0mInference done 94/146. Dataloading: 0.0022 s/iter. Inference: 0.0791 s/iter. Eval: 2.1236 s/iter. Total: 2.2055 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/08 11:52:21 d2.evaluation.evaluator]: \u001b[0mInference done 97/146. Dataloading: 0.0022 s/iter. Inference: 0.0790 s/iter. Eval: 2.1114 s/iter. Total: 2.1932 s/iter. ETA=0:01:47\n",
      "\u001b[32m[07/08 11:52:26 d2.evaluation.evaluator]: \u001b[0mInference done 100/146. Dataloading: 0.0022 s/iter. Inference: 0.0789 s/iter. Eval: 2.0986 s/iter. Total: 2.1803 s/iter. ETA=0:01:40\n",
      "\u001b[32m[07/08 11:52:31 d2.evaluation.evaluator]: \u001b[0mInference done 103/146. Dataloading: 0.0022 s/iter. Inference: 0.0787 s/iter. Eval: 2.0837 s/iter. Total: 2.1652 s/iter. ETA=0:01:33\n",
      "\u001b[32m[07/08 11:52:39 d2.evaluation.evaluator]: \u001b[0mInference done 106/146. Dataloading: 0.0022 s/iter. Inference: 0.0788 s/iter. Eval: 2.0937 s/iter. Total: 2.1754 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/08 11:52:44 d2.evaluation.evaluator]: \u001b[0mInference done 108/146. Dataloading: 0.0022 s/iter. Inference: 0.0789 s/iter. Eval: 2.1045 s/iter. Total: 2.1863 s/iter. ETA=0:01:23\n",
      "\u001b[32m[07/08 11:52:49 d2.evaluation.evaluator]: \u001b[0mInference done 113/146. Dataloading: 0.0021 s/iter. Inference: 0.0790 s/iter. Eval: 2.0528 s/iter. Total: 2.1347 s/iter. ETA=0:01:10\n",
      "\u001b[32m[07/08 11:52:55 d2.evaluation.evaluator]: \u001b[0mInference done 121/146. Dataloading: 0.0021 s/iter. Inference: 0.0789 s/iter. Eval: 1.9517 s/iter. Total: 2.0334 s/iter. ETA=0:00:50\n",
      "\u001b[32m[07/08 11:53:00 d2.evaluation.evaluator]: \u001b[0mInference done 131/146. Dataloading: 0.0021 s/iter. Inference: 0.0784 s/iter. Eval: 1.8346 s/iter. Total: 1.9156 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/08 11:53:05 d2.evaluation.evaluator]: \u001b[0mInference done 140/146. Dataloading: 0.0021 s/iter. Inference: 0.0779 s/iter. Eval: 1.7457 s/iter. Total: 1.8263 s/iter. ETA=0:00:10\n",
      "\u001b[32m[07/08 11:53:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:10.669253 (1.777796 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 11:53:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.077759 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 11:53:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/08 11:53:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to TomatoMAP/TomatoMAP-Seg/output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/08 11:53:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "evaluate failed: 'info'\n",
      "Epoch 4: evaluate failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45811/3081507412.py\", line 123, in _do_eval\n",
      "    results = inference_on_dataset(self.trainer.model, val_loader, evaluator)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py\", line 215, in inference_on_dataset\n",
      "    results = evaluator.evaluate()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 206, in evaluate\n",
      "    self._eval_predictions(predictions, img_ids=img_ids)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 266, in _eval_predictions\n",
      "    _evaluate_predictions_on_coco(\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 590, in _evaluate_predictions_on_coco\n",
      "    coco_dt = coco_gt.loadRes(coco_results)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/pycocotools/coco.py\", line 314, in loadRes\n",
      "    res.dataset['info'] = copy.deepcopy(self.dataset['info'])\n",
      "KeyError: 'info'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/08 11:53:19 d2.utils.events]: \u001b[0m eta: 0:48:56  iter: 4259  total_loss: 1.101  loss_cls: 0.4183  loss_box_reg: 0.5103  loss_mask: 0.1039  loss_rpn_cls: 0.0151  loss_rpn_loc: 0.04931    time: 0.4633  last_time: 0.4641  data_time: 0.0146  last_data_time: 0.0153   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:53:28 d2.utils.events]: \u001b[0m eta: 0:48:45  iter: 4279  total_loss: 1.143  loss_cls: 0.4214  loss_box_reg: 0.5392  loss_mask: 0.1018  loss_rpn_cls: 0.0155  loss_rpn_loc: 0.04971    time: 0.4634  last_time: 0.4848  data_time: 0.0224  last_data_time: 0.0133   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:53:38 d2.utils.events]: \u001b[0m eta: 0:48:38  iter: 4299  total_loss: 1.056  loss_cls: 0.3794  loss_box_reg: 0.5218  loss_mask: 0.1023  loss_rpn_cls: 0.0146  loss_rpn_loc: 0.04551    time: 0.4634  last_time: 0.4631  data_time: 0.0177  last_data_time: 0.0095   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:53:48 d2.utils.events]: \u001b[0m eta: 0:48:30  iter: 4319  total_loss: 1.033  loss_cls: 0.3934  loss_box_reg: 0.4993  loss_mask: 0.0905  loss_rpn_cls: 0.01115  loss_rpn_loc: 0.04832    time: 0.4635  last_time: 0.4376  data_time: 0.0435  last_data_time: 0.0049   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:53:58 d2.utils.events]: \u001b[0m eta: 0:48:22  iter: 4339  total_loss: 1.043  loss_cls: 0.3753  loss_box_reg: 0.5023  loss_mask: 0.1063  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.0479    time: 0.4637  last_time: 0.4580  data_time: 0.0484  last_data_time: 0.0090   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:54:07 d2.utils.events]: \u001b[0m eta: 0:48:16  iter: 4359  total_loss: 1.071  loss_cls: 0.402  loss_box_reg: 0.5181  loss_mask: 0.09048  loss_rpn_cls: 0.009761  loss_rpn_loc: 0.04097    time: 0.4638  last_time: 0.5698  data_time: 0.0494  last_data_time: 0.1042   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:54:17 d2.utils.events]: \u001b[0m eta: 0:48:08  iter: 4379  total_loss: 1.048  loss_cls: 0.3959  loss_box_reg: 0.5176  loss_mask: 0.0979  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.04063    time: 0.4639  last_time: 0.4359  data_time: 0.0275  last_data_time: 0.0080   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:54:26 d2.utils.events]: \u001b[0m eta: 0:48:00  iter: 4399  total_loss: 1.156  loss_cls: 0.4276  loss_box_reg: 0.5625  loss_mask: 0.09143  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.05378    time: 0.4639  last_time: 0.4522  data_time: 0.0183  last_data_time: 0.0154   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:54:36 d2.utils.events]: \u001b[0m eta: 0:47:51  iter: 4419  total_loss: 1.158  loss_cls: 0.4197  loss_box_reg: 0.5534  loss_mask: 0.1163  loss_rpn_cls: 0.01698  loss_rpn_loc: 0.04961    time: 0.4639  last_time: 0.4370  data_time: 0.0157  last_data_time: 0.0081   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:54:45 d2.utils.events]: \u001b[0m eta: 0:47:42  iter: 4439  total_loss: 1.11  loss_cls: 0.3924  loss_box_reg: 0.5486  loss_mask: 0.09955  loss_rpn_cls: 0.0148  loss_rpn_loc: 0.04903    time: 0.4639  last_time: 0.4782  data_time: 0.0123  last_data_time: 0.0122   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:54:54 d2.utils.events]: \u001b[0m eta: 0:47:33  iter: 4459  total_loss: 1.166  loss_cls: 0.4137  loss_box_reg: 0.5756  loss_mask: 0.09729  loss_rpn_cls: 0.01487  loss_rpn_loc: 0.04861    time: 0.4639  last_time: 0.4483  data_time: 0.0191  last_data_time: 0.0156   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:55:04 d2.utils.events]: \u001b[0m eta: 0:47:23  iter: 4479  total_loss: 1.131  loss_cls: 0.3847  loss_box_reg: 0.5423  loss_mask: 0.096  loss_rpn_cls: 0.01393  loss_rpn_loc: 0.05289    time: 0.4639  last_time: 0.4118  data_time: 0.0163  last_data_time: 0.0102   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:55:13 d2.utils.events]: \u001b[0m eta: 0:47:12  iter: 4499  total_loss: 1.141  loss_cls: 0.4285  loss_box_reg: 0.5463  loss_mask: 0.0991  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.0418    time: 0.4639  last_time: 0.4604  data_time: 0.0106  last_data_time: 0.0117   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:55:22 d2.utils.events]: \u001b[0m eta: 0:47:03  iter: 4519  total_loss: 1.09  loss_cls: 0.385  loss_box_reg: 0.4899  loss_mask: 0.1065  loss_rpn_cls: 0.01593  loss_rpn_loc: 0.06425    time: 0.4639  last_time: 0.3993  data_time: 0.0211  last_data_time: 0.0090   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:55:31 d2.utils.events]: \u001b[0m eta: 0:46:48  iter: 4539  total_loss: 1.095  loss_cls: 0.3859  loss_box_reg: 0.5085  loss_mask: 0.09167  loss_rpn_cls: 0.01484  loss_rpn_loc: 0.05431    time: 0.4639  last_time: 0.4627  data_time: 0.0125  last_data_time: 0.0183   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:55:41 d2.utils.events]: \u001b[0m eta: 0:46:38  iter: 4559  total_loss: 1.077  loss_cls: 0.3844  loss_box_reg: 0.4909  loss_mask: 0.08171  loss_rpn_cls: 0.01276  loss_rpn_loc: 0.04904    time: 0.4639  last_time: 0.4795  data_time: 0.0156  last_data_time: 0.0247   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:55:50 d2.utils.events]: \u001b[0m eta: 0:46:25  iter: 4579  total_loss: 1.029  loss_cls: 0.3689  loss_box_reg: 0.4933  loss_mask: 0.1056  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.04707    time: 0.4639  last_time: 0.4550  data_time: 0.0263  last_data_time: 0.0127   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:55:59 d2.utils.events]: \u001b[0m eta: 0:46:19  iter: 4599  total_loss: 0.9867  loss_cls: 0.3832  loss_box_reg: 0.4864  loss_mask: 0.08576  loss_rpn_cls: 0.01046  loss_rpn_loc: 0.03487    time: 0.4639  last_time: 0.4791  data_time: 0.0175  last_data_time: 0.0113   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:56:09 d2.utils.events]: \u001b[0m eta: 0:46:11  iter: 4619  total_loss: 1.094  loss_cls: 0.3888  loss_box_reg: 0.5106  loss_mask: 0.09937  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.04418    time: 0.4640  last_time: 0.4905  data_time: 0.0344  last_data_time: 0.0102   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:56:18 d2.utils.events]: \u001b[0m eta: 0:46:03  iter: 4639  total_loss: 1.049  loss_cls: 0.4088  loss_box_reg: 0.5023  loss_mask: 0.09321  loss_rpn_cls: 0.01604  loss_rpn_loc: 0.03991    time: 0.4640  last_time: 0.4923  data_time: 0.0104  last_data_time: 0.0091   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:56:28 d2.utils.events]: \u001b[0m eta: 0:45:53  iter: 4659  total_loss: 1.138  loss_cls: 0.3923  loss_box_reg: 0.5394  loss_mask: 0.1009  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.05553    time: 0.4641  last_time: 0.5574  data_time: 0.0267  last_data_time: 0.0856   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:56:37 d2.utils.events]: \u001b[0m eta: 0:45:44  iter: 4679  total_loss: 1.147  loss_cls: 0.4058  loss_box_reg: 0.5478  loss_mask: 0.1044  loss_rpn_cls: 0.01543  loss_rpn_loc: 0.05485    time: 0.4641  last_time: 0.4514  data_time: 0.0116  last_data_time: 0.0114   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:56:47 d2.utils.events]: \u001b[0m eta: 0:45:33  iter: 4699  total_loss: 1.058  loss_cls: 0.374  loss_box_reg: 0.5147  loss_mask: 0.0833  loss_rpn_cls: 0.01402  loss_rpn_loc: 0.04521    time: 0.4641  last_time: 0.4602  data_time: 0.0371  last_data_time: 0.0079   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:56:56 d2.utils.events]: \u001b[0m eta: 0:45:25  iter: 4719  total_loss: 1.127  loss_cls: 0.3923  loss_box_reg: 0.5435  loss_mask: 0.1085  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.05832    time: 0.4641  last_time: 0.6040  data_time: 0.0199  last_data_time: 0.1712   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:57:05 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 4739  total_loss: 1.032  loss_cls: 0.3721  loss_box_reg: 0.4942  loss_mask: 0.08127  loss_rpn_cls: 0.01511  loss_rpn_loc: 0.04897    time: 0.4641  last_time: 0.4547  data_time: 0.0235  last_data_time: 0.0137   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:57:15 d2.utils.events]: \u001b[0m eta: 0:45:10  iter: 4759  total_loss: 1.129  loss_cls: 0.4234  loss_box_reg: 0.5457  loss_mask: 0.09561  loss_rpn_cls: 0.01597  loss_rpn_loc: 0.04331    time: 0.4643  last_time: 0.5487  data_time: 0.0453  last_data_time: 0.1290   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:57:25 d2.utils.events]: \u001b[0m eta: 0:45:01  iter: 4779  total_loss: 1.04  loss_cls: 0.4003  loss_box_reg: 0.4964  loss_mask: 0.09194  loss_rpn_cls: 0.009958  loss_rpn_loc: 0.04168    time: 0.4643  last_time: 0.4652  data_time: 0.0378  last_data_time: 0.0189   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:57:34 d2.utils.events]: \u001b[0m eta: 0:44:55  iter: 4799  total_loss: 1.085  loss_cls: 0.3896  loss_box_reg: 0.5223  loss_mask: 0.09809  loss_rpn_cls: 0.01462  loss_rpn_loc: 0.04241    time: 0.4643  last_time: 0.4794  data_time: 0.0122  last_data_time: 0.0121   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:57:44 d2.utils.events]: \u001b[0m eta: 0:44:45  iter: 4819  total_loss: 1.128  loss_cls: 0.4159  loss_box_reg: 0.5126  loss_mask: 0.09979  loss_rpn_cls: 0.01629  loss_rpn_loc: 0.05269    time: 0.4643  last_time: 0.4334  data_time: 0.0228  last_data_time: 0.0176   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:57:53 d2.utils.events]: \u001b[0m eta: 0:44:35  iter: 4839  total_loss: 1.046  loss_cls: 0.3933  loss_box_reg: 0.5056  loss_mask: 0.08358  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.04268    time: 0.4643  last_time: 0.4421  data_time: 0.0119  last_data_time: 0.0216   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:58:02 d2.utils.events]: \u001b[0m eta: 0:44:26  iter: 4859  total_loss: 1.102  loss_cls: 0.3844  loss_box_reg: 0.5382  loss_mask: 0.1053  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.05494    time: 0.4644  last_time: 0.4747  data_time: 0.0110  last_data_time: 0.0081   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:58:12 d2.utils.events]: \u001b[0m eta: 0:44:18  iter: 4879  total_loss: 1.118  loss_cls: 0.3904  loss_box_reg: 0.5469  loss_mask: 0.09461  loss_rpn_cls: 0.01505  loss_rpn_loc: 0.0469    time: 0.4644  last_time: 0.4521  data_time: 0.0282  last_data_time: 0.0022   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:58:22 d2.utils.events]: \u001b[0m eta: 0:44:10  iter: 4899  total_loss: 1.081  loss_cls: 0.3906  loss_box_reg: 0.5378  loss_mask: 0.1031  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.05135    time: 0.4645  last_time: 0.4867  data_time: 0.0335  last_data_time: 0.0084   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:58:31 d2.utils.events]: \u001b[0m eta: 0:44:00  iter: 4919  total_loss: 1.053  loss_cls: 0.3931  loss_box_reg: 0.5138  loss_mask: 0.0947  loss_rpn_cls: 0.01134  loss_rpn_loc: 0.04124    time: 0.4646  last_time: 0.5853  data_time: 0.0366  last_data_time: 0.1037   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:58:41 d2.utils.events]: \u001b[0m eta: 0:43:53  iter: 4939  total_loss: 1.128  loss_cls: 0.4092  loss_box_reg: 0.5625  loss_mask: 0.1014  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.05574    time: 0.4646  last_time: 0.6148  data_time: 0.0259  last_data_time: 0.1271   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:58:50 d2.utils.events]: \u001b[0m eta: 0:43:44  iter: 4959  total_loss: 1.069  loss_cls: 0.4136  loss_box_reg: 0.5154  loss_mask: 0.09282  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.04717    time: 0.4646  last_time: 0.4510  data_time: 0.0135  last_data_time: 0.0116   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:58:59 d2.utils.events]: \u001b[0m eta: 0:43:36  iter: 4979  total_loss: 1.11  loss_cls: 0.4084  loss_box_reg: 0.5332  loss_mask: 0.09847  loss_rpn_cls: 0.01624  loss_rpn_loc: 0.05063    time: 0.4646  last_time: 0.5035  data_time: 0.0182  last_data_time: 0.0226   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:59:09 d2.utils.events]: \u001b[0m eta: 0:43:28  iter: 4999  total_loss: 1.062  loss_cls: 0.3872  loss_box_reg: 0.5382  loss_mask: 0.09049  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.04649    time: 0.4647  last_time: 0.5112  data_time: 0.0228  last_data_time: 0.0212   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:59:19 d2.utils.events]: \u001b[0m eta: 0:43:19  iter: 5019  total_loss: 1.029  loss_cls: 0.3663  loss_box_reg: 0.5051  loss_mask: 0.1036  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.04182    time: 0.4648  last_time: 0.4851  data_time: 0.0290  last_data_time: 0.0149   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:59:28 d2.utils.events]: \u001b[0m eta: 0:43:10  iter: 5039  total_loss: 1.077  loss_cls: 0.4104  loss_box_reg: 0.5226  loss_mask: 0.09941  loss_rpn_cls: 0.01544  loss_rpn_loc: 0.04391    time: 0.4648  last_time: 0.4713  data_time: 0.0139  last_data_time: 0.0178   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:59:37 d2.utils.events]: \u001b[0m eta: 0:43:01  iter: 5059  total_loss: 1.027  loss_cls: 0.3808  loss_box_reg: 0.4865  loss_mask: 0.09397  loss_rpn_cls: 0.009347  loss_rpn_loc: 0.04129    time: 0.4648  last_time: 0.4937  data_time: 0.0196  last_data_time: 0.0834   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:59:47 d2.utils.events]: \u001b[0m eta: 0:42:53  iter: 5079  total_loss: 1.129  loss_cls: 0.3937  loss_box_reg: 0.5397  loss_mask: 0.08261  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.04687    time: 0.4648  last_time: 0.4893  data_time: 0.0184  last_data_time: 0.0138   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 11:59:56 d2.utils.events]: \u001b[0m eta: 0:42:43  iter: 5099  total_loss: 1.044  loss_cls: 0.3722  loss_box_reg: 0.514  loss_mask: 0.1012  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.03996    time: 0.4648  last_time: 0.4371  data_time: 0.0133  last_data_time: 0.0102   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:00:05 d2.utils.events]: \u001b[0m eta: 0:42:34  iter: 5119  total_loss: 1.019  loss_cls: 0.3956  loss_box_reg: 0.4864  loss_mask: 0.09571  loss_rpn_cls: 0.01865  loss_rpn_loc: 0.05216    time: 0.4648  last_time: 0.5507  data_time: 0.0189  last_data_time: 0.1155   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:00:14 d2.utils.events]: \u001b[0m eta: 0:42:24  iter: 5139  total_loss: 0.9551  loss_cls: 0.3403  loss_box_reg: 0.4731  loss_mask: 0.1152  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.04088    time: 0.4648  last_time: 0.4643  data_time: 0.0139  last_data_time: 0.0082   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:00:24 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 5159  total_loss: 1.117  loss_cls: 0.4149  loss_box_reg: 0.523  loss_mask: 0.08384  loss_rpn_cls: 0.01702  loss_rpn_loc: 0.05342    time: 0.4647  last_time: 0.4457  data_time: 0.0152  last_data_time: 0.0089   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:00:33 d2.utils.events]: \u001b[0m eta: 0:42:04  iter: 5179  total_loss: 1.079  loss_cls: 0.3823  loss_box_reg: 0.5287  loss_mask: 0.1062  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.05016    time: 0.4647  last_time: 0.4615  data_time: 0.0127  last_data_time: 0.0083   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:00:42 d2.utils.events]: \u001b[0m eta: 0:41:55  iter: 5199  total_loss: 1.041  loss_cls: 0.3826  loss_box_reg: 0.4983  loss_mask: 0.09148  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.03901    time: 0.4647  last_time: 0.4712  data_time: 0.0185  last_data_time: 0.0198   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:00:52 d2.utils.events]: \u001b[0m eta: 0:41:47  iter: 5219  total_loss: 1.037  loss_cls: 0.3725  loss_box_reg: 0.4945  loss_mask: 0.1012  loss_rpn_cls: 0.009586  loss_rpn_loc: 0.049    time: 0.4647  last_time: 0.4290  data_time: 0.0281  last_data_time: 0.0115   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:01:01 d2.utils.events]: \u001b[0m eta: 0:41:36  iter: 5239  total_loss: 1.021  loss_cls: 0.3777  loss_box_reg: 0.4783  loss_mask: 0.09139  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.0441    time: 0.4647  last_time: 0.4452  data_time: 0.0101  last_data_time: 0.0105   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:01:10 d2.utils.events]: \u001b[0m eta: 0:41:27  iter: 5259  total_loss: 0.9699  loss_cls: 0.3644  loss_box_reg: 0.4656  loss_mask: 0.08849  loss_rpn_cls: 0.009586  loss_rpn_loc: 0.04072    time: 0.4647  last_time: 0.4791  data_time: 0.0135  last_data_time: 0.0144   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:01:19 d2.utils.events]: \u001b[0m eta: 0:41:18  iter: 5279  total_loss: 1.081  loss_cls: 0.3918  loss_box_reg: 0.5197  loss_mask: 0.0839  loss_rpn_cls: 0.01082  loss_rpn_loc: 0.05303    time: 0.4647  last_time: 0.4312  data_time: 0.0148  last_data_time: 0.0184   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:01:29 d2.utils.events]: \u001b[0m eta: 0:41:08  iter: 5299  total_loss: 1.099  loss_cls: 0.3915  loss_box_reg: 0.5264  loss_mask: 0.09807  loss_rpn_cls: 0.01578  loss_rpn_loc: 0.04893    time: 0.4647  last_time: 0.4638  data_time: 0.0141  last_data_time: 0.0169   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:01:29 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 12:01:29 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/08 12:01:29 d2.data.datasets.coco]: \u001b[0mLoaded 146 images in COCO format from /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Seg/cocoOut/val.json\n",
      "\u001b[32m[07/08 12:01:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/08 12:01:29 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/08 12:01:29 d2.data.common]: \u001b[0mSerializing 146 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/08 12:01:29 d2.data.common]: \u001b[0mSerialized dataset takes 5.22 MiB\n",
      "\u001b[32m[07/08 12:01:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 146 batches\n",
      "\u001b[32m[07/08 12:01:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/146. Dataloading: 0.0019 s/iter. Inference: 0.0728 s/iter. Eval: 1.5692 s/iter. Total: 1.6439 s/iter. ETA=0:03:41\n",
      "\u001b[32m[07/08 12:01:56 d2.evaluation.evaluator]: \u001b[0mInference done 14/146. Dataloading: 0.0019 s/iter. Inference: 0.0731 s/iter. Eval: 1.6313 s/iter. Total: 1.7069 s/iter. ETA=0:03:45\n",
      "\u001b[32m[07/08 12:02:02 d2.evaluation.evaluator]: \u001b[0mInference done 17/146. Dataloading: 0.0017 s/iter. Inference: 0.0728 s/iter. Eval: 1.6623 s/iter. Total: 1.7374 s/iter. ETA=0:03:44\n",
      "\u001b[32m[07/08 12:02:09 d2.evaluation.evaluator]: \u001b[0mInference done 21/146. Dataloading: 0.0020 s/iter. Inference: 0.0723 s/iter. Eval: 1.6737 s/iter. Total: 1.7485 s/iter. ETA=0:03:38\n",
      "\u001b[32m[07/08 12:02:15 d2.evaluation.evaluator]: \u001b[0mInference done 24/146. Dataloading: 0.0020 s/iter. Inference: 0.0722 s/iter. Eval: 1.7060 s/iter. Total: 1.7809 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/08 12:02:20 d2.evaluation.evaluator]: \u001b[0mInference done 27/146. Dataloading: 0.0021 s/iter. Inference: 0.0721 s/iter. Eval: 1.7175 s/iter. Total: 1.7923 s/iter. ETA=0:03:33\n",
      "\u001b[32m[07/08 12:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 31/146. Dataloading: 0.0021 s/iter. Inference: 0.0722 s/iter. Eval: 1.7214 s/iter. Total: 1.7962 s/iter. ETA=0:03:26\n",
      "\u001b[32m[07/08 12:02:34 d2.evaluation.evaluator]: \u001b[0mInference done 35/146. Dataloading: 0.0021 s/iter. Inference: 0.0716 s/iter. Eval: 1.6997 s/iter. Total: 1.7740 s/iter. ETA=0:03:16\n",
      "\u001b[32m[07/08 12:02:42 d2.evaluation.evaluator]: \u001b[0mInference done 39/146. Dataloading: 0.0021 s/iter. Inference: 0.0718 s/iter. Eval: 1.7339 s/iter. Total: 1.8084 s/iter. ETA=0:03:13\n",
      "\u001b[32m[07/08 12:02:49 d2.evaluation.evaluator]: \u001b[0mInference done 42/146. Dataloading: 0.0021 s/iter. Inference: 0.0720 s/iter. Eval: 1.7634 s/iter. Total: 1.8381 s/iter. ETA=0:03:11\n",
      "\u001b[32m[07/08 12:02:54 d2.evaluation.evaluator]: \u001b[0mInference done 44/146. Dataloading: 0.0021 s/iter. Inference: 0.0725 s/iter. Eval: 1.8034 s/iter. Total: 1.8786 s/iter. ETA=0:03:11\n",
      "\u001b[32m[07/08 12:03:00 d2.evaluation.evaluator]: \u001b[0mInference done 48/146. Dataloading: 0.0021 s/iter. Inference: 0.0720 s/iter. Eval: 1.7664 s/iter. Total: 1.8411 s/iter. ETA=0:03:00\n",
      "\u001b[32m[07/08 12:03:06 d2.evaluation.evaluator]: \u001b[0mInference done 50/146. Dataloading: 0.0022 s/iter. Inference: 0.0728 s/iter. Eval: 1.8130 s/iter. Total: 1.8887 s/iter. ETA=0:03:01\n",
      "\u001b[32m[07/08 12:03:11 d2.evaluation.evaluator]: \u001b[0mInference done 53/146. Dataloading: 0.0023 s/iter. Inference: 0.0730 s/iter. Eval: 1.8126 s/iter. Total: 1.8885 s/iter. ETA=0:02:55\n",
      "\u001b[32m[07/08 12:03:17 d2.evaluation.evaluator]: \u001b[0mInference done 56/146. Dataloading: 0.0023 s/iter. Inference: 0.0730 s/iter. Eval: 1.8040 s/iter. Total: 1.8800 s/iter. ETA=0:02:49\n",
      "\u001b[32m[07/08 12:03:22 d2.evaluation.evaluator]: \u001b[0mInference done 58/146. Dataloading: 0.0023 s/iter. Inference: 0.0735 s/iter. Eval: 1.8398 s/iter. Total: 1.9163 s/iter. ETA=0:02:48\n",
      "\u001b[32m[07/08 12:03:29 d2.evaluation.evaluator]: \u001b[0mInference done 62/146. Dataloading: 0.0023 s/iter. Inference: 0.0733 s/iter. Eval: 1.8210 s/iter. Total: 1.8972 s/iter. ETA=0:02:39\n",
      "\u001b[32m[07/08 12:03:35 d2.evaluation.evaluator]: \u001b[0mInference done 65/146. Dataloading: 0.0023 s/iter. Inference: 0.0732 s/iter. Eval: 1.8207 s/iter. Total: 1.8967 s/iter. ETA=0:02:33\n",
      "\u001b[32m[07/08 12:03:40 d2.evaluation.evaluator]: \u001b[0mInference done 69/146. Dataloading: 0.0023 s/iter. Inference: 0.0728 s/iter. Eval: 1.7902 s/iter. Total: 1.8660 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/08 12:03:46 d2.evaluation.evaluator]: \u001b[0mInference done 72/146. Dataloading: 0.0023 s/iter. Inference: 0.0728 s/iter. Eval: 1.7891 s/iter. Total: 1.8648 s/iter. ETA=0:02:17\n",
      "\u001b[32m[07/08 12:03:51 d2.evaluation.evaluator]: \u001b[0mInference done 74/146. Dataloading: 0.0023 s/iter. Inference: 0.0730 s/iter. Eval: 1.8155 s/iter. Total: 1.8915 s/iter. ETA=0:02:16\n",
      "\u001b[32m[07/08 12:03:57 d2.evaluation.evaluator]: \u001b[0mInference done 77/146. Dataloading: 0.0022 s/iter. Inference: 0.0730 s/iter. Eval: 1.8153 s/iter. Total: 1.8912 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/08 12:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 81/146. Dataloading: 0.0022 s/iter. Inference: 0.0728 s/iter. Eval: 1.7988 s/iter. Total: 1.8745 s/iter. ETA=0:02:01\n",
      "\u001b[32m[07/08 12:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 85/146. Dataloading: 0.0022 s/iter. Inference: 0.0727 s/iter. Eval: 1.7800 s/iter. Total: 1.8555 s/iter. ETA=0:01:53\n",
      "\u001b[32m[07/08 12:04:16 d2.evaluation.evaluator]: \u001b[0mInference done 88/146. Dataloading: 0.0022 s/iter. Inference: 0.0729 s/iter. Eval: 1.7906 s/iter. Total: 1.8664 s/iter. ETA=0:01:48\n",
      "\u001b[32m[07/08 12:04:21 d2.evaluation.evaluator]: \u001b[0mInference done 91/146. Dataloading: 0.0022 s/iter. Inference: 0.0729 s/iter. Eval: 1.7930 s/iter. Total: 1.8688 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/08 12:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 95/146. Dataloading: 0.0022 s/iter. Inference: 0.0726 s/iter. Eval: 1.7722 s/iter. Total: 1.8475 s/iter. ETA=0:01:34\n",
      "\u001b[32m[07/08 12:04:32 d2.evaluation.evaluator]: \u001b[0mInference done 98/146. Dataloading: 0.0021 s/iter. Inference: 0.0725 s/iter. Eval: 1.7703 s/iter. Total: 1.8456 s/iter. ETA=0:01:28\n",
      "\u001b[32m[07/08 12:04:38 d2.evaluation.evaluator]: \u001b[0mInference done 101/146. Dataloading: 0.0021 s/iter. Inference: 0.0723 s/iter. Eval: 1.7671 s/iter. Total: 1.8422 s/iter. ETA=0:01:22\n",
      "\u001b[32m[07/08 12:04:43 d2.evaluation.evaluator]: \u001b[0mInference done 105/146. Dataloading: 0.0021 s/iter. Inference: 0.0720 s/iter. Eval: 1.7471 s/iter. Total: 1.8219 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/08 12:04:49 d2.evaluation.evaluator]: \u001b[0mInference done 107/146. Dataloading: 0.0021 s/iter. Inference: 0.0723 s/iter. Eval: 1.7704 s/iter. Total: 1.8454 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/08 12:04:56 d2.evaluation.evaluator]: \u001b[0mInference done 110/146. Dataloading: 0.0021 s/iter. Inference: 0.0724 s/iter. Eval: 1.7836 s/iter. Total: 1.8588 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/08 12:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 114/146. Dataloading: 0.0021 s/iter. Inference: 0.0723 s/iter. Eval: 1.7726 s/iter. Total: 1.8476 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/08 12:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 118/146. Dataloading: 0.0021 s/iter. Inference: 0.0721 s/iter. Eval: 1.7607 s/iter. Total: 1.8355 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/08 12:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 121/146. Dataloading: 0.0021 s/iter. Inference: 0.0721 s/iter. Eval: 1.7599 s/iter. Total: 1.8347 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/08 12:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 131/146. Dataloading: 0.0020 s/iter. Inference: 0.0717 s/iter. Eval: 1.6566 s/iter. Total: 1.7309 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/08 12:05:24 d2.evaluation.evaluator]: \u001b[0mInference done 141/146. Dataloading: 0.0020 s/iter. Inference: 0.0714 s/iter. Eval: 1.5694 s/iter. Total: 1.6434 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/08 12:05:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:46.853769 (1.608892 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 12:05:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.071415 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 12:05:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/08 12:05:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to TomatoMAP/TomatoMAP-Seg/output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/08 12:05:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "evaluate failed: 'info'\n",
      "Epoch 5: evaluate failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45811/3081507412.py\", line 123, in _do_eval\n",
      "    results = inference_on_dataset(self.trainer.model, val_loader, evaluator)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py\", line 215, in inference_on_dataset\n",
      "    results = evaluator.evaluate()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 206, in evaluate\n",
      "    self._eval_predictions(predictions, img_ids=img_ids)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 266, in _eval_predictions\n",
      "    _evaluate_predictions_on_coco(\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 590, in _evaluate_predictions_on_coco\n",
      "    coco_dt = coco_gt.loadRes(coco_results)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/pycocotools/coco.py\", line 314, in loadRes\n",
      "    res.dataset['info'] = copy.deepcopy(self.dataset['info'])\n",
      "KeyError: 'info'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/08 12:05:37 d2.utils.events]: \u001b[0m eta: 0:40:59  iter: 5319  total_loss: 1.141  loss_cls: 0.4225  loss_box_reg: 0.5474  loss_mask: 0.09667  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.05079    time: 0.4647  last_time: 0.4909  data_time: 0.0137  last_data_time: 0.0119   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:05:47 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 5339  total_loss: 1.054  loss_cls: 0.3939  loss_box_reg: 0.4928  loss_mask: 0.096  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.04271    time: 0.4647  last_time: 0.4764  data_time: 0.0235  last_data_time: 0.0108   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:05:56 d2.utils.events]: \u001b[0m eta: 0:40:37  iter: 5359  total_loss: 1.11  loss_cls: 0.3733  loss_box_reg: 0.5331  loss_mask: 0.108  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.04762    time: 0.4647  last_time: 0.4397  data_time: 0.0105  last_data_time: 0.0107   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:06:05 d2.utils.events]: \u001b[0m eta: 0:40:27  iter: 5379  total_loss: 1.069  loss_cls: 0.3974  loss_box_reg: 0.5379  loss_mask: 0.1073  loss_rpn_cls: 0.01672  loss_rpn_loc: 0.05056    time: 0.4647  last_time: 0.4555  data_time: 0.0167  last_data_time: 0.0086   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:06:14 d2.utils.events]: \u001b[0m eta: 0:40:18  iter: 5399  total_loss: 0.9419  loss_cls: 0.3451  loss_box_reg: 0.4746  loss_mask: 0.08634  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.0422    time: 0.4647  last_time: 0.4251  data_time: 0.0193  last_data_time: 0.0201   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:06:23 d2.utils.events]: \u001b[0m eta: 0:40:08  iter: 5419  total_loss: 0.9758  loss_cls: 0.3672  loss_box_reg: 0.4629  loss_mask: 0.08694  loss_rpn_cls: 0.01083  loss_rpn_loc: 0.04375    time: 0.4646  last_time: 0.4280  data_time: 0.0172  last_data_time: 0.0079   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:06:32 d2.utils.events]: \u001b[0m eta: 0:39:58  iter: 5439  total_loss: 1.003  loss_cls: 0.3469  loss_box_reg: 0.5061  loss_mask: 0.08464  loss_rpn_cls: 0.01265  loss_rpn_loc: 0.0466    time: 0.4646  last_time: 0.4869  data_time: 0.0126  last_data_time: 0.0147   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:06:42 d2.utils.events]: \u001b[0m eta: 0:39:47  iter: 5459  total_loss: 1.087  loss_cls: 0.39  loss_box_reg: 0.536  loss_mask: 0.08975  loss_rpn_cls: 0.01149  loss_rpn_loc: 0.04495    time: 0.4646  last_time: 0.4598  data_time: 0.0125  last_data_time: 0.0110   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:06:51 d2.utils.events]: \u001b[0m eta: 0:39:39  iter: 5479  total_loss: 1.04  loss_cls: 0.3372  loss_box_reg: 0.4993  loss_mask: 0.09553  loss_rpn_cls: 0.009096  loss_rpn_loc: 0.04384    time: 0.4646  last_time: 0.4928  data_time: 0.0233  last_data_time: 0.0121   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:07:00 d2.utils.events]: \u001b[0m eta: 0:39:31  iter: 5499  total_loss: 1.045  loss_cls: 0.3951  loss_box_reg: 0.4781  loss_mask: 0.08501  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.04198    time: 0.4646  last_time: 0.4681  data_time: 0.0124  last_data_time: 0.0182   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:07:10 d2.utils.events]: \u001b[0m eta: 0:39:21  iter: 5519  total_loss: 1.115  loss_cls: 0.4207  loss_box_reg: 0.5482  loss_mask: 0.1089  loss_rpn_cls: 0.01206  loss_rpn_loc: 0.05127    time: 0.4646  last_time: 0.4870  data_time: 0.0124  last_data_time: 0.0098   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:07:19 d2.utils.events]: \u001b[0m eta: 0:39:10  iter: 5539  total_loss: 1.035  loss_cls: 0.3587  loss_box_reg: 0.4949  loss_mask: 0.08334  loss_rpn_cls: 0.01519  loss_rpn_loc: 0.0469    time: 0.4646  last_time: 0.4632  data_time: 0.0111  last_data_time: 0.0105   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:07:28 d2.utils.events]: \u001b[0m eta: 0:39:01  iter: 5559  total_loss: 1.006  loss_cls: 0.3486  loss_box_reg: 0.4922  loss_mask: 0.1003  loss_rpn_cls: 0.0138  loss_rpn_loc: 0.04786    time: 0.4646  last_time: 0.4753  data_time: 0.0185  last_data_time: 0.0078   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:07:38 d2.utils.events]: \u001b[0m eta: 0:38:53  iter: 5579  total_loss: 0.9989  loss_cls: 0.3678  loss_box_reg: 0.4947  loss_mask: 0.08028  loss_rpn_cls: 0.01408  loss_rpn_loc: 0.04647    time: 0.4646  last_time: 0.4819  data_time: 0.0294  last_data_time: 0.0085   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:07:47 d2.utils.events]: \u001b[0m eta: 0:38:43  iter: 5599  total_loss: 0.991  loss_cls: 0.3591  loss_box_reg: 0.4889  loss_mask: 0.08156  loss_rpn_cls: 0.01341  loss_rpn_loc: 0.04123    time: 0.4646  last_time: 0.4591  data_time: 0.0157  last_data_time: 0.0093   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:07:57 d2.utils.events]: \u001b[0m eta: 0:38:35  iter: 5619  total_loss: 1.065  loss_cls: 0.3805  loss_box_reg: 0.5162  loss_mask: 0.09945  loss_rpn_cls: 0.01042  loss_rpn_loc: 0.04779    time: 0.4647  last_time: 0.4613  data_time: 0.0221  last_data_time: 0.0099   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:08:06 d2.utils.events]: \u001b[0m eta: 0:38:27  iter: 5639  total_loss: 0.9915  loss_cls: 0.3816  loss_box_reg: 0.4831  loss_mask: 0.07806  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.03648    time: 0.4648  last_time: 0.4802  data_time: 0.0252  last_data_time: 0.0128   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:08:16 d2.utils.events]: \u001b[0m eta: 0:38:18  iter: 5659  total_loss: 1.016  loss_cls: 0.382  loss_box_reg: 0.4914  loss_mask: 0.08623  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.04222    time: 0.4648  last_time: 0.4501  data_time: 0.0119  last_data_time: 0.0137   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:08:25 d2.utils.events]: \u001b[0m eta: 0:38:08  iter: 5679  total_loss: 1.108  loss_cls: 0.4075  loss_box_reg: 0.5343  loss_mask: 0.1016  loss_rpn_cls: 0.01518  loss_rpn_loc: 0.04307    time: 0.4648  last_time: 0.3658  data_time: 0.0162  last_data_time: 0.0091   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:08:34 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 5699  total_loss: 1.083  loss_cls: 0.3795  loss_box_reg: 0.5213  loss_mask: 0.1043  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.06265    time: 0.4648  last_time: 0.4859  data_time: 0.0172  last_data_time: 0.0119   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:08:44 d2.utils.events]: \u001b[0m eta: 0:37:50  iter: 5719  total_loss: 0.9754  loss_cls: 0.3628  loss_box_reg: 0.4653  loss_mask: 0.07849  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.04189    time: 0.4648  last_time: 0.4705  data_time: 0.0276  last_data_time: 0.0085   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:08:53 d2.utils.events]: \u001b[0m eta: 0:37:41  iter: 5739  total_loss: 1.031  loss_cls: 0.3774  loss_box_reg: 0.5041  loss_mask: 0.08568  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.04537    time: 0.4648  last_time: 0.4741  data_time: 0.0114  last_data_time: 0.0077   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:09:02 d2.utils.events]: \u001b[0m eta: 0:37:30  iter: 5759  total_loss: 0.9887  loss_cls: 0.3575  loss_box_reg: 0.4853  loss_mask: 0.1013  loss_rpn_cls: 0.01327  loss_rpn_loc: 0.0446    time: 0.4648  last_time: 0.4144  data_time: 0.0099  last_data_time: 0.0082   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:09:11 d2.utils.events]: \u001b[0m eta: 0:37:21  iter: 5779  total_loss: 1.027  loss_cls: 0.3683  loss_box_reg: 0.5144  loss_mask: 0.09674  loss_rpn_cls: 0.01187  loss_rpn_loc: 0.04043    time: 0.4648  last_time: 0.4396  data_time: 0.0109  last_data_time: 0.0094   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:09:21 d2.utils.events]: \u001b[0m eta: 0:37:10  iter: 5799  total_loss: 0.9685  loss_cls: 0.3589  loss_box_reg: 0.4867  loss_mask: 0.08052  loss_rpn_cls: 0.01227  loss_rpn_loc: 0.04446    time: 0.4647  last_time: 0.4494  data_time: 0.0125  last_data_time: 0.0156   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:09:30 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 5819  total_loss: 1.11  loss_cls: 0.3927  loss_box_reg: 0.5338  loss_mask: 0.08914  loss_rpn_cls: 0.01356  loss_rpn_loc: 0.05181    time: 0.4648  last_time: 0.4865  data_time: 0.0152  last_data_time: 0.0112   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:09:39 d2.utils.events]: \u001b[0m eta: 0:36:50  iter: 5839  total_loss: 0.9409  loss_cls: 0.3285  loss_box_reg: 0.4403  loss_mask: 0.08424  loss_rpn_cls: 0.0095  loss_rpn_loc: 0.04099    time: 0.4647  last_time: 0.4865  data_time: 0.0195  last_data_time: 0.0120   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:09:48 d2.utils.events]: \u001b[0m eta: 0:36:40  iter: 5859  total_loss: 1.127  loss_cls: 0.3992  loss_box_reg: 0.5458  loss_mask: 0.1031  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.05137    time: 0.4647  last_time: 0.4902  data_time: 0.0123  last_data_time: 0.0155   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:09:58 d2.utils.events]: \u001b[0m eta: 0:36:31  iter: 5879  total_loss: 1.043  loss_cls: 0.3782  loss_box_reg: 0.5195  loss_mask: 0.09554  loss_rpn_cls: 0.01022  loss_rpn_loc: 0.04083    time: 0.4647  last_time: 0.4248  data_time: 0.0105  last_data_time: 0.0076   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:10:07 d2.utils.events]: \u001b[0m eta: 0:36:22  iter: 5899  total_loss: 0.9734  loss_cls: 0.3466  loss_box_reg: 0.4907  loss_mask: 0.09767  loss_rpn_cls: 0.01372  loss_rpn_loc: 0.04578    time: 0.4648  last_time: 0.5239  data_time: 0.0267  last_data_time: 0.0900   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:10:17 d2.utils.events]: \u001b[0m eta: 0:36:14  iter: 5919  total_loss: 0.9929  loss_cls: 0.3747  loss_box_reg: 0.4855  loss_mask: 0.07754  loss_rpn_cls: 0.01469  loss_rpn_loc: 0.04712    time: 0.4648  last_time: 0.4630  data_time: 0.0158  last_data_time: 0.0103   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:10:26 d2.utils.events]: \u001b[0m eta: 0:36:06  iter: 5939  total_loss: 1.109  loss_cls: 0.3841  loss_box_reg: 0.5352  loss_mask: 0.1078  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.06317    time: 0.4648  last_time: 0.4811  data_time: 0.0170  last_data_time: 0.0121   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:10:35 d2.utils.events]: \u001b[0m eta: 0:35:55  iter: 5959  total_loss: 0.9669  loss_cls: 0.3316  loss_box_reg: 0.4917  loss_mask: 0.08577  loss_rpn_cls: 0.009887  loss_rpn_loc: 0.04316    time: 0.4648  last_time: 0.4591  data_time: 0.0124  last_data_time: 0.0156   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:10:45 d2.utils.events]: \u001b[0m eta: 0:35:45  iter: 5979  total_loss: 0.9119  loss_cls: 0.3534  loss_box_reg: 0.4356  loss_mask: 0.09094  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.04223    time: 0.4648  last_time: 0.4607  data_time: 0.0120  last_data_time: 0.0100   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:10:54 d2.utils.events]: \u001b[0m eta: 0:35:35  iter: 5999  total_loss: 0.9689  loss_cls: 0.3553  loss_box_reg: 0.4736  loss_mask: 0.08212  loss_rpn_cls: 0.008984  loss_rpn_loc: 0.04285    time: 0.4648  last_time: 0.4091  data_time: 0.0132  last_data_time: 0.0081   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:11:03 d2.utils.events]: \u001b[0m eta: 0:35:25  iter: 6019  total_loss: 1.076  loss_cls: 0.374  loss_box_reg: 0.5176  loss_mask: 0.09377  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.05366    time: 0.4647  last_time: 0.4694  data_time: 0.0112  last_data_time: 0.0082   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:11:12 d2.utils.events]: \u001b[0m eta: 0:35:15  iter: 6039  total_loss: 1.125  loss_cls: 0.3943  loss_box_reg: 0.5475  loss_mask: 0.09044  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.05209    time: 0.4647  last_time: 0.4027  data_time: 0.0114  last_data_time: 0.0111   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:11:21 d2.utils.events]: \u001b[0m eta: 0:35:04  iter: 6059  total_loss: 1.065  loss_cls: 0.3819  loss_box_reg: 0.5049  loss_mask: 0.0894  loss_rpn_cls: 0.01462  loss_rpn_loc: 0.0551    time: 0.4647  last_time: 0.4206  data_time: 0.0180  last_data_time: 0.0089   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:11:31 d2.utils.events]: \u001b[0m eta: 0:34:54  iter: 6079  total_loss: 1.01  loss_cls: 0.3467  loss_box_reg: 0.4925  loss_mask: 0.09992  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.04855    time: 0.4647  last_time: 0.4480  data_time: 0.0216  last_data_time: 0.0087   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:11:40 d2.utils.events]: \u001b[0m eta: 0:34:44  iter: 6099  total_loss: 1.008  loss_cls: 0.3663  loss_box_reg: 0.4978  loss_mask: 0.08611  loss_rpn_cls: 0.01133  loss_rpn_loc: 0.04467    time: 0.4647  last_time: 0.4470  data_time: 0.0129  last_data_time: 0.0095   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:11:50 d2.utils.events]: \u001b[0m eta: 0:34:34  iter: 6119  total_loss: 0.991  loss_cls: 0.3768  loss_box_reg: 0.4886  loss_mask: 0.07717  loss_rpn_cls: 0.00931  loss_rpn_loc: 0.05057    time: 0.4648  last_time: 0.4444  data_time: 0.0314  last_data_time: 0.0025   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:11:59 d2.utils.events]: \u001b[0m eta: 0:34:27  iter: 6139  total_loss: 1.026  loss_cls: 0.3455  loss_box_reg: 0.5064  loss_mask: 0.0907  loss_rpn_cls: 0.009016  loss_rpn_loc: 0.04308    time: 0.4648  last_time: 0.4791  data_time: 0.0119  last_data_time: 0.0089   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:12:08 d2.utils.events]: \u001b[0m eta: 0:34:20  iter: 6159  total_loss: 1.113  loss_cls: 0.3833  loss_box_reg: 0.5519  loss_mask: 0.09849  loss_rpn_cls: 0.008169  loss_rpn_loc: 0.05103    time: 0.4648  last_time: 0.4906  data_time: 0.0132  last_data_time: 0.0088   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:12:18 d2.utils.events]: \u001b[0m eta: 0:34:10  iter: 6179  total_loss: 0.9553  loss_cls: 0.3351  loss_box_reg: 0.4645  loss_mask: 0.09328  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.04374    time: 0.4648  last_time: 0.4715  data_time: 0.0274  last_data_time: 0.0023   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:12:27 d2.utils.events]: \u001b[0m eta: 0:34:00  iter: 6199  total_loss: 0.9907  loss_cls: 0.3737  loss_box_reg: 0.5031  loss_mask: 0.07889  loss_rpn_cls: 0.01133  loss_rpn_loc: 0.04779    time: 0.4648  last_time: 0.4515  data_time: 0.0110  last_data_time: 0.0098   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:12:36 d2.utils.events]: \u001b[0m eta: 0:33:48  iter: 6219  total_loss: 0.9804  loss_cls: 0.3611  loss_box_reg: 0.4814  loss_mask: 0.09437  loss_rpn_cls: 0.008895  loss_rpn_loc: 0.04231    time: 0.4648  last_time: 0.4454  data_time: 0.0115  last_data_time: 0.0087   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:12:46 d2.utils.events]: \u001b[0m eta: 0:33:42  iter: 6239  total_loss: 1.095  loss_cls: 0.3793  loss_box_reg: 0.5334  loss_mask: 0.09229  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.05232    time: 0.4648  last_time: 0.4562  data_time: 0.0148  last_data_time: 0.0247   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:12:55 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 6259  total_loss: 0.9897  loss_cls: 0.3468  loss_box_reg: 0.504  loss_mask: 0.08348  loss_rpn_cls: 0.01545  loss_rpn_loc: 0.03958    time: 0.4648  last_time: 0.4289  data_time: 0.0107  last_data_time: 0.0117   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:13:04 d2.utils.events]: \u001b[0m eta: 0:33:22  iter: 6279  total_loss: 0.9936  loss_cls: 0.3628  loss_box_reg: 0.4796  loss_mask: 0.08406  loss_rpn_cls: 0.009711  loss_rpn_loc: 0.05075    time: 0.4648  last_time: 0.4872  data_time: 0.0187  last_data_time: 0.0177   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:13:14 d2.utils.events]: \u001b[0m eta: 0:33:13  iter: 6299  total_loss: 0.9783  loss_cls: 0.3445  loss_box_reg: 0.5013  loss_mask: 0.08337  loss_rpn_cls: 0.01096  loss_rpn_loc: 0.04572    time: 0.4648  last_time: 0.4600  data_time: 0.0264  last_data_time: 0.0044   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:13:23 d2.utils.events]: \u001b[0m eta: 0:33:03  iter: 6319  total_loss: 1.011  loss_cls: 0.3536  loss_box_reg: 0.4924  loss_mask: 0.1073  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.05045    time: 0.4649  last_time: 0.4590  data_time: 0.0210  last_data_time: 0.0080   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:13:33 d2.utils.events]: \u001b[0m eta: 0:32:55  iter: 6339  total_loss: 1.032  loss_cls: 0.375  loss_box_reg: 0.4948  loss_mask: 0.08155  loss_rpn_cls: 0.00947  loss_rpn_loc: 0.05308    time: 0.4649  last_time: 0.4823  data_time: 0.0148  last_data_time: 0.0055   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:13:42 d2.utils.events]: \u001b[0m eta: 0:32:47  iter: 6359  total_loss: 0.9943  loss_cls: 0.362  loss_box_reg: 0.4846  loss_mask: 0.09379  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.0457    time: 0.4649  last_time: 0.4401  data_time: 0.0164  last_data_time: 0.0089   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:13:42 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 12:13:42 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/08 12:13:43 d2.data.datasets.coco]: \u001b[0mLoaded 146 images in COCO format from /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Seg/cocoOut/val.json\n",
      "\u001b[32m[07/08 12:13:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/08 12:13:43 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/08 12:13:43 d2.data.common]: \u001b[0mSerializing 146 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/08 12:13:43 d2.data.common]: \u001b[0mSerialized dataset takes 5.22 MiB\n",
      "\u001b[32m[07/08 12:13:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 146 batches\n",
      "\u001b[32m[07/08 12:14:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/146. Dataloading: 0.0025 s/iter. Inference: 0.0693 s/iter. Eval: 1.5588 s/iter. Total: 1.6307 s/iter. ETA=0:03:40\n",
      "\u001b[32m[07/08 12:14:08 d2.evaluation.evaluator]: \u001b[0mInference done 14/146. Dataloading: 0.0021 s/iter. Inference: 0.0702 s/iter. Eval: 1.6667 s/iter. Total: 1.7396 s/iter. ETA=0:03:49\n",
      "\u001b[32m[07/08 12:14:15 d2.evaluation.evaluator]: \u001b[0mInference done 17/146. Dataloading: 0.0022 s/iter. Inference: 0.0714 s/iter. Eval: 1.7630 s/iter. Total: 1.8373 s/iter. ETA=0:03:57\n",
      "\u001b[32m[07/08 12:14:22 d2.evaluation.evaluator]: \u001b[0mInference done 21/146. Dataloading: 0.0022 s/iter. Inference: 0.0712 s/iter. Eval: 1.7477 s/iter. Total: 1.8217 s/iter. ETA=0:03:47\n",
      "\u001b[32m[07/08 12:14:28 d2.evaluation.evaluator]: \u001b[0mInference done 24/146. Dataloading: 0.0022 s/iter. Inference: 0.0715 s/iter. Eval: 1.7699 s/iter. Total: 1.8443 s/iter. ETA=0:03:45\n",
      "\u001b[32m[07/08 12:14:35 d2.evaluation.evaluator]: \u001b[0mInference done 28/146. Dataloading: 0.0022 s/iter. Inference: 0.0712 s/iter. Eval: 1.7539 s/iter. Total: 1.8279 s/iter. ETA=0:03:35\n",
      "\u001b[32m[07/08 12:14:41 d2.evaluation.evaluator]: \u001b[0mInference done 32/146. Dataloading: 0.0022 s/iter. Inference: 0.0714 s/iter. Eval: 1.7246 s/iter. Total: 1.7988 s/iter. ETA=0:03:25\n",
      "\u001b[32m[07/08 12:14:47 d2.evaluation.evaluator]: \u001b[0mInference done 35/146. Dataloading: 0.0022 s/iter. Inference: 0.0713 s/iter. Eval: 1.7221 s/iter. Total: 1.7962 s/iter. ETA=0:03:19\n",
      "\u001b[32m[07/08 12:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 39/146. Dataloading: 0.0022 s/iter. Inference: 0.0718 s/iter. Eval: 1.7318 s/iter. Total: 1.8064 s/iter. ETA=0:03:13\n",
      "\u001b[32m[07/08 12:15:01 d2.evaluation.evaluator]: \u001b[0mInference done 42/146. Dataloading: 0.0023 s/iter. Inference: 0.0722 s/iter. Eval: 1.7659 s/iter. Total: 1.8410 s/iter. ETA=0:03:11\n",
      "\u001b[32m[07/08 12:15:06 d2.evaluation.evaluator]: \u001b[0mInference done 44/146. Dataloading: 0.0023 s/iter. Inference: 0.0730 s/iter. Eval: 1.8133 s/iter. Total: 1.8892 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/08 12:15:12 d2.evaluation.evaluator]: \u001b[0mInference done 47/146. Dataloading: 0.0024 s/iter. Inference: 0.0730 s/iter. Eval: 1.8139 s/iter. Total: 1.8899 s/iter. ETA=0:03:07\n",
      "\u001b[32m[07/08 12:15:19 d2.evaluation.evaluator]: \u001b[0mInference done 50/146. Dataloading: 0.0025 s/iter. Inference: 0.0734 s/iter. Eval: 1.8308 s/iter. Total: 1.9073 s/iter. ETA=0:03:03\n",
      "\u001b[32m[07/08 12:15:26 d2.evaluation.evaluator]: \u001b[0mInference done 54/146. Dataloading: 0.0024 s/iter. Inference: 0.0735 s/iter. Eval: 1.8181 s/iter. Total: 1.8947 s/iter. ETA=0:02:54\n",
      "\u001b[32m[07/08 12:15:31 d2.evaluation.evaluator]: \u001b[0mInference done 57/146. Dataloading: 0.0024 s/iter. Inference: 0.0739 s/iter. Eval: 1.8225 s/iter. Total: 1.8994 s/iter. ETA=0:02:49\n",
      "\u001b[32m[07/08 12:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 60/146. Dataloading: 0.0023 s/iter. Inference: 0.0738 s/iter. Eval: 1.8189 s/iter. Total: 1.8958 s/iter. ETA=0:02:43\n",
      "\u001b[32m[07/08 12:15:43 d2.evaluation.evaluator]: \u001b[0mInference done 63/146. Dataloading: 0.0023 s/iter. Inference: 0.0740 s/iter. Eval: 1.8277 s/iter. Total: 1.9046 s/iter. ETA=0:02:38\n",
      "\u001b[32m[07/08 12:15:49 d2.evaluation.evaluator]: \u001b[0mInference done 66/146. Dataloading: 0.0023 s/iter. Inference: 0.0738 s/iter. Eval: 1.8237 s/iter. Total: 1.9005 s/iter. ETA=0:02:32\n",
      "\u001b[32m[07/08 12:15:54 d2.evaluation.evaluator]: \u001b[0mInference done 70/146. Dataloading: 0.0023 s/iter. Inference: 0.0734 s/iter. Eval: 1.7877 s/iter. Total: 1.8640 s/iter. ETA=0:02:21\n",
      "\u001b[32m[07/08 12:16:01 d2.evaluation.evaluator]: \u001b[0mInference done 73/146. Dataloading: 0.0022 s/iter. Inference: 0.0736 s/iter. Eval: 1.8113 s/iter. Total: 1.8878 s/iter. ETA=0:02:17\n",
      "\u001b[32m[07/08 12:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 75/146. Dataloading: 0.0022 s/iter. Inference: 0.0741 s/iter. Eval: 1.8488 s/iter. Total: 1.9257 s/iter. ETA=0:02:16\n",
      "\u001b[32m[07/08 12:16:13 d2.evaluation.evaluator]: \u001b[0mInference done 78/146. Dataloading: 0.0022 s/iter. Inference: 0.0740 s/iter. Eval: 1.8429 s/iter. Total: 1.9198 s/iter. ETA=0:02:10\n",
      "\u001b[32m[07/08 12:16:18 d2.evaluation.evaluator]: \u001b[0mInference done 82/146. Dataloading: 0.0022 s/iter. Inference: 0.0737 s/iter. Eval: 1.8101 s/iter. Total: 1.8867 s/iter. ETA=0:02:00\n",
      "\u001b[32m[07/08 12:16:24 d2.evaluation.evaluator]: \u001b[0mInference done 86/146. Dataloading: 0.0022 s/iter. Inference: 0.0737 s/iter. Eval: 1.7916 s/iter. Total: 1.8682 s/iter. ETA=0:01:52\n",
      "\u001b[32m[07/08 12:16:30 d2.evaluation.evaluator]: \u001b[0mInference done 89/146. Dataloading: 0.0022 s/iter. Inference: 0.0737 s/iter. Eval: 1.7949 s/iter. Total: 1.8714 s/iter. ETA=0:01:46\n",
      "\u001b[32m[07/08 12:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 92/146. Dataloading: 0.0021 s/iter. Inference: 0.0739 s/iter. Eval: 1.8114 s/iter. Total: 1.8881 s/iter. ETA=0:01:41\n",
      "\u001b[32m[07/08 12:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 96/146. Dataloading: 0.0021 s/iter. Inference: 0.0737 s/iter. Eval: 1.7884 s/iter. Total: 1.8648 s/iter. ETA=0:01:33\n",
      "\u001b[32m[07/08 12:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 99/146. Dataloading: 0.0021 s/iter. Inference: 0.0736 s/iter. Eval: 1.7847 s/iter. Total: 1.8610 s/iter. ETA=0:01:27\n",
      "\u001b[32m[07/08 12:16:53 d2.evaluation.evaluator]: \u001b[0mInference done 103/146. Dataloading: 0.0021 s/iter. Inference: 0.0733 s/iter. Eval: 1.7629 s/iter. Total: 1.8389 s/iter. ETA=0:01:19\n",
      "\u001b[32m[07/08 12:17:00 d2.evaluation.evaluator]: \u001b[0mInference done 106/146. Dataloading: 0.0021 s/iter. Inference: 0.0735 s/iter. Eval: 1.7782 s/iter. Total: 1.8545 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/08 12:17:09 d2.evaluation.evaluator]: \u001b[0mInference done 110/146. Dataloading: 0.0021 s/iter. Inference: 0.0737 s/iter. Eval: 1.7929 s/iter. Total: 1.8693 s/iter. ETA=0:01:07\n",
      "\u001b[32m[07/08 12:17:15 d2.evaluation.evaluator]: \u001b[0mInference done 114/146. Dataloading: 0.0020 s/iter. Inference: 0.0736 s/iter. Eval: 1.7809 s/iter. Total: 1.8572 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/08 12:17:21 d2.evaluation.evaluator]: \u001b[0mInference done 118/146. Dataloading: 0.0020 s/iter. Inference: 0.0736 s/iter. Eval: 1.7694 s/iter. Total: 1.8457 s/iter. ETA=0:00:51\n",
      "\u001b[32m[07/08 12:17:27 d2.evaluation.evaluator]: \u001b[0mInference done 122/146. Dataloading: 0.0020 s/iter. Inference: 0.0735 s/iter. Eval: 1.7518 s/iter. Total: 1.8279 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/08 12:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 126/146. Dataloading: 0.0020 s/iter. Inference: 0.0734 s/iter. Eval: 1.7341 s/iter. Total: 1.8101 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/08 12:17:37 d2.evaluation.evaluator]: \u001b[0mInference done 139/146. Dataloading: 0.0020 s/iter. Inference: 0.0725 s/iter. Eval: 1.5999 s/iter. Total: 1.6750 s/iter. ETA=0:00:11\n",
      "\u001b[32m[07/08 12:17:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:48.903442 (1.623429 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 12:17:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.072501 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 12:17:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/08 12:17:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to TomatoMAP/TomatoMAP-Seg/output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/08 12:17:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "evaluate failed: 'info'\n",
      "Epoch 6: evaluate failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45811/3081507412.py\", line 123, in _do_eval\n",
      "    results = inference_on_dataset(self.trainer.model, val_loader, evaluator)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py\", line 215, in inference_on_dataset\n",
      "    results = evaluator.evaluate()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 206, in evaluate\n",
      "    self._eval_predictions(predictions, img_ids=img_ids)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 266, in _eval_predictions\n",
      "    _evaluate_predictions_on_coco(\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 590, in _evaluate_predictions_on_coco\n",
      "    coco_dt = coco_gt.loadRes(coco_results)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/pycocotools/coco.py\", line 314, in loadRes\n",
      "    res.dataset['info'] = copy.deepcopy(self.dataset['info'])\n",
      "KeyError: 'info'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/08 12:17:51 d2.utils.events]: \u001b[0m eta: 0:32:38  iter: 6379  total_loss: 0.9284  loss_cls: 0.3402  loss_box_reg: 0.4409  loss_mask: 0.07881  loss_rpn_cls: 0.009381  loss_rpn_loc: 0.03456    time: 0.4649  last_time: 0.4501  data_time: 0.0210  last_data_time: 0.0120   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:18:01 d2.utils.events]: \u001b[0m eta: 0:32:29  iter: 6399  total_loss: 1.03  loss_cls: 0.3825  loss_box_reg: 0.4914  loss_mask: 0.09714  loss_rpn_cls: 0.0129  loss_rpn_loc: 0.04699    time: 0.4649  last_time: 0.4334  data_time: 0.0333  last_data_time: 0.0101   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:18:10 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 6419  total_loss: 1.004  loss_cls: 0.3668  loss_box_reg: 0.509  loss_mask: 0.087  loss_rpn_cls: 0.01131  loss_rpn_loc: 0.05003    time: 0.4649  last_time: 0.4799  data_time: 0.0181  last_data_time: 0.0110   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:18:19 d2.utils.events]: \u001b[0m eta: 0:32:11  iter: 6439  total_loss: 1.002  loss_cls: 0.3662  loss_box_reg: 0.4929  loss_mask: 0.09959  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.04147    time: 0.4649  last_time: 0.5103  data_time: 0.0109  last_data_time: 0.0149   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:18:29 d2.utils.events]: \u001b[0m eta: 0:32:03  iter: 6459  total_loss: 0.9821  loss_cls: 0.3386  loss_box_reg: 0.5  loss_mask: 0.08716  loss_rpn_cls: 0.01322  loss_rpn_loc: 0.04735    time: 0.4649  last_time: 0.4504  data_time: 0.0128  last_data_time: 0.0159   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:18:38 d2.utils.events]: \u001b[0m eta: 0:31:53  iter: 6479  total_loss: 1.027  loss_cls: 0.3569  loss_box_reg: 0.491  loss_mask: 0.1042  loss_rpn_cls: 0.01105  loss_rpn_loc: 0.03964    time: 0.4649  last_time: 0.4402  data_time: 0.0125  last_data_time: 0.0093   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:18:47 d2.utils.events]: \u001b[0m eta: 0:31:43  iter: 6499  total_loss: 0.9629  loss_cls: 0.3414  loss_box_reg: 0.472  loss_mask: 0.07207  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.04361    time: 0.4649  last_time: 0.4401  data_time: 0.0103  last_data_time: 0.0104   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:18:56 d2.utils.events]: \u001b[0m eta: 0:31:33  iter: 6519  total_loss: 0.9612  loss_cls: 0.3431  loss_box_reg: 0.4688  loss_mask: 0.08247  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.03601    time: 0.4649  last_time: 0.4359  data_time: 0.0150  last_data_time: 0.0097   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:19:06 d2.utils.events]: \u001b[0m eta: 0:31:25  iter: 6539  total_loss: 1.046  loss_cls: 0.3707  loss_box_reg: 0.5104  loss_mask: 0.09252  loss_rpn_cls: 0.01464  loss_rpn_loc: 0.05088    time: 0.4649  last_time: 0.6075  data_time: 0.0269  last_data_time: 0.1567   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:19:15 d2.utils.events]: \u001b[0m eta: 0:31:17  iter: 6559  total_loss: 1.045  loss_cls: 0.369  loss_box_reg: 0.508  loss_mask: 0.08888  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.04911    time: 0.4649  last_time: 0.4218  data_time: 0.0140  last_data_time: 0.0080   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:19:24 d2.utils.events]: \u001b[0m eta: 0:31:06  iter: 6579  total_loss: 0.988  loss_cls: 0.3499  loss_box_reg: 0.4788  loss_mask: 0.08749  loss_rpn_cls: 0.01274  loss_rpn_loc: 0.04853    time: 0.4649  last_time: 0.4688  data_time: 0.0134  last_data_time: 0.0083   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:19:34 d2.utils.events]: \u001b[0m eta: 0:30:57  iter: 6599  total_loss: 0.9818  loss_cls: 0.356  loss_box_reg: 0.4812  loss_mask: 0.08561  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.0468    time: 0.4649  last_time: 0.4345  data_time: 0.0174  last_data_time: 0.0152   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:19:43 d2.utils.events]: \u001b[0m eta: 0:30:46  iter: 6619  total_loss: 1.011  loss_cls: 0.3376  loss_box_reg: 0.4954  loss_mask: 0.08911  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.04872    time: 0.4649  last_time: 0.4515  data_time: 0.0194  last_data_time: 0.0235   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:19:52 d2.utils.events]: \u001b[0m eta: 0:30:34  iter: 6639  total_loss: 0.973  loss_cls: 0.3143  loss_box_reg: 0.4883  loss_mask: 0.08836  loss_rpn_cls: 0.009717  loss_rpn_loc: 0.04513    time: 0.4649  last_time: 0.4587  data_time: 0.0102  last_data_time: 0.0110   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:20:01 d2.utils.events]: \u001b[0m eta: 0:30:24  iter: 6659  total_loss: 0.9149  loss_cls: 0.333  loss_box_reg: 0.4568  loss_mask: 0.08615  loss_rpn_cls: 0.01081  loss_rpn_loc: 0.04105    time: 0.4649  last_time: 0.4722  data_time: 0.0128  last_data_time: 0.0089   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:20:10 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 6679  total_loss: 1.002  loss_cls: 0.3627  loss_box_reg: 0.4985  loss_mask: 0.07489  loss_rpn_cls: 0.01349  loss_rpn_loc: 0.05817    time: 0.4648  last_time: 0.4897  data_time: 0.0105  last_data_time: 0.0113   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:20:20 d2.utils.events]: \u001b[0m eta: 0:30:03  iter: 6699  total_loss: 0.9928  loss_cls: 0.3541  loss_box_reg: 0.485  loss_mask: 0.09204  loss_rpn_cls: 0.01095  loss_rpn_loc: 0.04455    time: 0.4648  last_time: 0.4808  data_time: 0.0095  last_data_time: 0.0084   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:20:29 d2.utils.events]: \u001b[0m eta: 0:29:54  iter: 6719  total_loss: 0.9448  loss_cls: 0.3302  loss_box_reg: 0.4674  loss_mask: 0.09245  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.04399    time: 0.4648  last_time: 0.5076  data_time: 0.0118  last_data_time: 0.0107   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:20:38 d2.utils.events]: \u001b[0m eta: 0:29:45  iter: 6739  total_loss: 1.006  loss_cls: 0.3672  loss_box_reg: 0.4785  loss_mask: 0.07717  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.04936    time: 0.4648  last_time: 0.4415  data_time: 0.0139  last_data_time: 0.0093   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:20:47 d2.utils.events]: \u001b[0m eta: 0:29:35  iter: 6759  total_loss: 1.005  loss_cls: 0.3623  loss_box_reg: 0.4889  loss_mask: 0.09502  loss_rpn_cls: 0.009395  loss_rpn_loc: 0.04661    time: 0.4648  last_time: 0.4531  data_time: 0.0207  last_data_time: 0.0158   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:20:57 d2.utils.events]: \u001b[0m eta: 0:29:27  iter: 6779  total_loss: 0.9831  loss_cls: 0.3524  loss_box_reg: 0.4898  loss_mask: 0.09372  loss_rpn_cls: 0.00873  loss_rpn_loc: 0.04791    time: 0.4648  last_time: 0.4914  data_time: 0.0114  last_data_time: 0.0092   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:21:06 d2.utils.events]: \u001b[0m eta: 0:29:18  iter: 6799  total_loss: 1.057  loss_cls: 0.3709  loss_box_reg: 0.5194  loss_mask: 0.09304  loss_rpn_cls: 0.01245  loss_rpn_loc: 0.05046    time: 0.4648  last_time: 0.4668  data_time: 0.0198  last_data_time: 0.0091   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:21:15 d2.utils.events]: \u001b[0m eta: 0:29:08  iter: 6819  total_loss: 0.9667  loss_cls: 0.3486  loss_box_reg: 0.4788  loss_mask: 0.07721  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.05179    time: 0.4648  last_time: 0.4816  data_time: 0.0111  last_data_time: 0.0074   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:21:25 d2.utils.events]: \u001b[0m eta: 0:28:58  iter: 6839  total_loss: 0.9411  loss_cls: 0.3449  loss_box_reg: 0.4606  loss_mask: 0.08205  loss_rpn_cls: 0.007963  loss_rpn_loc: 0.04035    time: 0.4648  last_time: 0.4577  data_time: 0.0195  last_data_time: 0.0163   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:21:34 d2.utils.events]: \u001b[0m eta: 0:28:48  iter: 6859  total_loss: 0.9352  loss_cls: 0.3205  loss_box_reg: 0.4609  loss_mask: 0.07834  loss_rpn_cls: 0.009408  loss_rpn_loc: 0.03926    time: 0.4648  last_time: 0.4315  data_time: 0.0160  last_data_time: 0.0046   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:21:44 d2.utils.events]: \u001b[0m eta: 0:28:39  iter: 6879  total_loss: 0.9363  loss_cls: 0.3285  loss_box_reg: 0.4862  loss_mask: 0.09365  loss_rpn_cls: 0.008856  loss_rpn_loc: 0.04704    time: 0.4648  last_time: 0.5894  data_time: 0.0186  last_data_time: 0.1270   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:21:53 d2.utils.events]: \u001b[0m eta: 0:28:29  iter: 6899  total_loss: 1.023  loss_cls: 0.3608  loss_box_reg: 0.5096  loss_mask: 0.1094  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.04704    time: 0.4648  last_time: 0.4855  data_time: 0.0138  last_data_time: 0.0095   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:22:02 d2.utils.events]: \u001b[0m eta: 0:28:19  iter: 6919  total_loss: 1  loss_cls: 0.3722  loss_box_reg: 0.4748  loss_mask: 0.07985  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.05365    time: 0.4649  last_time: 0.4549  data_time: 0.0107  last_data_time: 0.0119   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:22:12 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 6939  total_loss: 1.01  loss_cls: 0.3447  loss_box_reg: 0.4966  loss_mask: 0.1105  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.04726    time: 0.4649  last_time: 0.4838  data_time: 0.0128  last_data_time: 0.0075   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:22:21 d2.utils.events]: \u001b[0m eta: 0:28:01  iter: 6959  total_loss: 0.9597  loss_cls: 0.3511  loss_box_reg: 0.4691  loss_mask: 0.08023  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.04698    time: 0.4649  last_time: 0.4377  data_time: 0.0249  last_data_time: 0.0123   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:22:30 d2.utils.events]: \u001b[0m eta: 0:27:51  iter: 6979  total_loss: 0.9647  loss_cls: 0.3413  loss_box_reg: 0.48  loss_mask: 0.08618  loss_rpn_cls: 0.01073  loss_rpn_loc: 0.04324    time: 0.4649  last_time: 0.4898  data_time: 0.0125  last_data_time: 0.0208   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:22:40 d2.utils.events]: \u001b[0m eta: 0:27:45  iter: 6999  total_loss: 1.017  loss_cls: 0.3568  loss_box_reg: 0.5001  loss_mask: 0.09409  loss_rpn_cls: 0.01313  loss_rpn_loc: 0.05386    time: 0.4649  last_time: 0.4899  data_time: 0.0151  last_data_time: 0.0161   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:22:49 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 7019  total_loss: 0.9549  loss_cls: 0.3384  loss_box_reg: 0.4678  loss_mask: 0.07739  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.0478    time: 0.4650  last_time: 0.4849  data_time: 0.0201  last_data_time: 0.0066   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:22:59 d2.utils.events]: \u001b[0m eta: 0:27:30  iter: 7039  total_loss: 0.9967  loss_cls: 0.3404  loss_box_reg: 0.5126  loss_mask: 0.09113  loss_rpn_cls: 0.0107  loss_rpn_loc: 0.0505    time: 0.4650  last_time: 0.4824  data_time: 0.0287  last_data_time: 0.0178   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:23:09 d2.utils.events]: \u001b[0m eta: 0:27:23  iter: 7059  total_loss: 0.9729  loss_cls: 0.336  loss_box_reg: 0.4501  loss_mask: 0.0837  loss_rpn_cls: 0.009925  loss_rpn_loc: 0.04473    time: 0.4651  last_time: 0.4688  data_time: 0.0221  last_data_time: 0.0091   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:23:18 d2.utils.events]: \u001b[0m eta: 0:27:13  iter: 7079  total_loss: 0.9388  loss_cls: 0.3397  loss_box_reg: 0.4825  loss_mask: 0.0927  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.04096    time: 0.4651  last_time: 0.4685  data_time: 0.0176  last_data_time: 0.0102   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:23:28 d2.utils.events]: \u001b[0m eta: 0:27:04  iter: 7099  total_loss: 0.9933  loss_cls: 0.3382  loss_box_reg: 0.501  loss_mask: 0.08253  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.0533    time: 0.4651  last_time: 0.4614  data_time: 0.0258  last_data_time: 0.0135   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:23:37 d2.utils.events]: \u001b[0m eta: 0:26:55  iter: 7119  total_loss: 0.8768  loss_cls: 0.3317  loss_box_reg: 0.4248  loss_mask: 0.0816  loss_rpn_cls: 0.009619  loss_rpn_loc: 0.03762    time: 0.4651  last_time: 0.4129  data_time: 0.0272  last_data_time: 0.0089   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:23:47 d2.utils.events]: \u001b[0m eta: 0:26:45  iter: 7139  total_loss: 0.9647  loss_cls: 0.3323  loss_box_reg: 0.4749  loss_mask: 0.08323  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.05079    time: 0.4652  last_time: 0.4521  data_time: 0.0392  last_data_time: 0.0140   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:23:56 d2.utils.events]: \u001b[0m eta: 0:26:35  iter: 7159  total_loss: 0.9892  loss_cls: 0.3486  loss_box_reg: 0.4749  loss_mask: 0.08069  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.05243    time: 0.4652  last_time: 0.4254  data_time: 0.0197  last_data_time: 0.0224   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:24:06 d2.utils.events]: \u001b[0m eta: 0:26:27  iter: 7179  total_loss: 1.025  loss_cls: 0.3509  loss_box_reg: 0.507  loss_mask: 0.0885  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.04865    time: 0.4652  last_time: 0.4741  data_time: 0.0148  last_data_time: 0.0087   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:24:15 d2.utils.events]: \u001b[0m eta: 0:26:17  iter: 7199  total_loss: 0.9313  loss_cls: 0.3168  loss_box_reg: 0.4604  loss_mask: 0.09347  loss_rpn_cls: 0.008657  loss_rpn_loc: 0.04574    time: 0.4651  last_time: 0.4665  data_time: 0.0113  last_data_time: 0.0085   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:24:24 d2.utils.events]: \u001b[0m eta: 0:26:07  iter: 7219  total_loss: 0.9385  loss_cls: 0.334  loss_box_reg: 0.4636  loss_mask: 0.08814  loss_rpn_cls: 0.008912  loss_rpn_loc: 0.04752    time: 0.4651  last_time: 0.4760  data_time: 0.0128  last_data_time: 0.0111   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:24:33 d2.utils.events]: \u001b[0m eta: 0:25:55  iter: 7239  total_loss: 0.9544  loss_cls: 0.341  loss_box_reg: 0.4698  loss_mask: 0.08853  loss_rpn_cls: 0.009121  loss_rpn_loc: 0.04204    time: 0.4651  last_time: 0.4372  data_time: 0.0113  last_data_time: 0.0077   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:24:42 d2.utils.events]: \u001b[0m eta: 0:25:48  iter: 7259  total_loss: 0.9275  loss_cls: 0.336  loss_box_reg: 0.4586  loss_mask: 0.08716  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.03963    time: 0.4651  last_time: 0.4729  data_time: 0.0122  last_data_time: 0.0146   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:24:51 d2.utils.events]: \u001b[0m eta: 0:25:38  iter: 7279  total_loss: 0.9868  loss_cls: 0.3278  loss_box_reg: 0.4853  loss_mask: 0.09542  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.04692    time: 0.4651  last_time: 0.6522  data_time: 0.0275  last_data_time: 0.1943   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:25:00 d2.utils.events]: \u001b[0m eta: 0:25:29  iter: 7299  total_loss: 0.9333  loss_cls: 0.3236  loss_box_reg: 0.4623  loss_mask: 0.09168  loss_rpn_cls: 0.01075  loss_rpn_loc: 0.04478    time: 0.4650  last_time: 0.4693  data_time: 0.0119  last_data_time: 0.0089   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:25:10 d2.utils.events]: \u001b[0m eta: 0:25:20  iter: 7319  total_loss: 1.027  loss_cls: 0.364  loss_box_reg: 0.5078  loss_mask: 0.07928  loss_rpn_cls: 0.008295  loss_rpn_loc: 0.04772    time: 0.4651  last_time: 0.4675  data_time: 0.0193  last_data_time: 0.0133   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:25:19 d2.utils.events]: \u001b[0m eta: 0:25:11  iter: 7339  total_loss: 0.9316  loss_cls: 0.3438  loss_box_reg: 0.462  loss_mask: 0.08339  loss_rpn_cls: 0.009148  loss_rpn_loc: 0.03918    time: 0.4651  last_time: 0.4673  data_time: 0.0192  last_data_time: 0.0165   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:25:29 d2.utils.events]: \u001b[0m eta: 0:25:01  iter: 7359  total_loss: 1.002  loss_cls: 0.3345  loss_box_reg: 0.4881  loss_mask: 0.08863  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.04983    time: 0.4651  last_time: 0.4999  data_time: 0.0199  last_data_time: 0.0230   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:25:38 d2.utils.events]: \u001b[0m eta: 0:24:52  iter: 7379  total_loss: 0.9814  loss_cls: 0.3306  loss_box_reg: 0.5025  loss_mask: 0.08871  loss_rpn_cls: 0.01206  loss_rpn_loc: 0.04846    time: 0.4651  last_time: 0.4820  data_time: 0.0113  last_data_time: 0.0087   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:25:47 d2.utils.events]: \u001b[0m eta: 0:24:40  iter: 7399  total_loss: 0.9373  loss_cls: 0.3254  loss_box_reg: 0.4686  loss_mask: 0.08602  loss_rpn_cls: 0.007959  loss_rpn_loc: 0.03947    time: 0.4651  last_time: 0.4785  data_time: 0.0177  last_data_time: 0.0121   lr: 0.00024  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:25:57 d2.utils.events]: \u001b[0m eta: 0:24:30  iter: 7419  total_loss: 0.9181  loss_cls: 0.3281  loss_box_reg: 0.4513  loss_mask: 0.07597  loss_rpn_cls: 0.01037  loss_rpn_loc: 0.04371    time: 0.4651  last_time: 0.4824  data_time: 0.0126  last_data_time: 0.0103   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:25:57 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 12:25:57 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/08 12:25:57 d2.data.datasets.coco]: \u001b[0mLoaded 146 images in COCO format from /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Seg/cocoOut/val.json\n",
      "\u001b[32m[07/08 12:25:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/08 12:25:57 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/08 12:25:57 d2.data.common]: \u001b[0mSerializing 146 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/08 12:25:57 d2.data.common]: \u001b[0mSerialized dataset takes 5.22 MiB\n",
      "\u001b[32m[07/08 12:25:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 146 batches\n",
      "\u001b[32m[07/08 12:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/146. Dataloading: 0.0023 s/iter. Inference: 0.0684 s/iter. Eval: 1.6340 s/iter. Total: 1.7046 s/iter. ETA=0:03:50\n",
      "\u001b[32m[07/08 12:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 14/146. Dataloading: 0.0024 s/iter. Inference: 0.0709 s/iter. Eval: 1.8038 s/iter. Total: 1.8777 s/iter. ETA=0:04:07\n",
      "\u001b[32m[07/08 12:26:31 d2.evaluation.evaluator]: \u001b[0mInference done 17/146. Dataloading: 0.0022 s/iter. Inference: 0.0706 s/iter. Eval: 1.7884 s/iter. Total: 1.8618 s/iter. ETA=0:04:00\n",
      "\u001b[32m[07/08 12:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 21/146. Dataloading: 0.0024 s/iter. Inference: 0.0702 s/iter. Eval: 1.7658 s/iter. Total: 1.8389 s/iter. ETA=0:03:49\n",
      "\u001b[32m[07/08 12:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 24/146. Dataloading: 0.0023 s/iter. Inference: 0.0701 s/iter. Eval: 1.7673 s/iter. Total: 1.8402 s/iter. ETA=0:03:44\n",
      "\u001b[32m[07/08 12:26:49 d2.evaluation.evaluator]: \u001b[0mInference done 28/146. Dataloading: 0.0023 s/iter. Inference: 0.0694 s/iter. Eval: 1.7098 s/iter. Total: 1.7821 s/iter. ETA=0:03:30\n",
      "\u001b[32m[07/08 12:26:55 d2.evaluation.evaluator]: \u001b[0mInference done 31/146. Dataloading: 0.0023 s/iter. Inference: 0.0694 s/iter. Eval: 1.7116 s/iter. Total: 1.7838 s/iter. ETA=0:03:25\n",
      "\u001b[32m[07/08 12:27:00 d2.evaluation.evaluator]: \u001b[0mInference done 34/146. Dataloading: 0.0022 s/iter. Inference: 0.0695 s/iter. Eval: 1.7082 s/iter. Total: 1.7805 s/iter. ETA=0:03:19\n",
      "\u001b[32m[07/08 12:27:05 d2.evaluation.evaluator]: \u001b[0mInference done 37/146. Dataloading: 0.0022 s/iter. Inference: 0.0693 s/iter. Eval: 1.6978 s/iter. Total: 1.7699 s/iter. ETA=0:03:12\n",
      "\u001b[32m[07/08 12:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 39/146. Dataloading: 0.0022 s/iter. Inference: 0.0702 s/iter. Eval: 1.7766 s/iter. Total: 1.8496 s/iter. ETA=0:03:17\n",
      "\u001b[32m[07/08 12:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 42/146. Dataloading: 0.0022 s/iter. Inference: 0.0703 s/iter. Eval: 1.7880 s/iter. Total: 1.8611 s/iter. ETA=0:03:13\n",
      "\u001b[32m[07/08 12:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 44/146. Dataloading: 0.0022 s/iter. Inference: 0.0708 s/iter. Eval: 1.8324 s/iter. Total: 1.9060 s/iter. ETA=0:03:14\n",
      "\u001b[32m[07/08 12:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 47/146. Dataloading: 0.0023 s/iter. Inference: 0.0709 s/iter. Eval: 1.8248 s/iter. Total: 1.8987 s/iter. ETA=0:03:07\n",
      "\u001b[32m[07/08 12:27:34 d2.evaluation.evaluator]: \u001b[0mInference done 50/146. Dataloading: 0.0024 s/iter. Inference: 0.0711 s/iter. Eval: 1.8252 s/iter. Total: 1.8992 s/iter. ETA=0:03:02\n",
      "\u001b[32m[07/08 12:27:40 d2.evaluation.evaluator]: \u001b[0mInference done 54/146. Dataloading: 0.0023 s/iter. Inference: 0.0710 s/iter. Eval: 1.8026 s/iter. Total: 1.8766 s/iter. ETA=0:02:52\n",
      "\u001b[32m[07/08 12:27:47 d2.evaluation.evaluator]: \u001b[0mInference done 57/146. Dataloading: 0.0023 s/iter. Inference: 0.0714 s/iter. Eval: 1.8176 s/iter. Total: 1.8920 s/iter. ETA=0:02:48\n",
      "\u001b[32m[07/08 12:27:52 d2.evaluation.evaluator]: \u001b[0mInference done 60/146. Dataloading: 0.0023 s/iter. Inference: 0.0714 s/iter. Eval: 1.8117 s/iter. Total: 1.8860 s/iter. ETA=0:02:42\n",
      "\u001b[32m[07/08 12:27:57 d2.evaluation.evaluator]: \u001b[0mInference done 62/146. Dataloading: 0.0023 s/iter. Inference: 0.0718 s/iter. Eval: 1.8390 s/iter. Total: 1.9137 s/iter. ETA=0:02:40\n",
      "\u001b[32m[07/08 12:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 66/146. Dataloading: 0.0022 s/iter. Inference: 0.0716 s/iter. Eval: 1.8063 s/iter. Total: 1.8808 s/iter. ETA=0:02:30\n",
      "\u001b[32m[07/08 12:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 75/146. Dataloading: 0.0021 s/iter. Inference: 0.0723 s/iter. Eval: 1.6446 s/iter. Total: 1.7197 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/08 12:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 86/146. Dataloading: 0.0021 s/iter. Inference: 0.0722 s/iter. Eval: 1.4738 s/iter. Total: 1.5486 s/iter. ETA=0:01:32\n",
      "\u001b[32m[07/08 12:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 96/146. Dataloading: 0.0020 s/iter. Inference: 0.0723 s/iter. Eval: 1.3608 s/iter. Total: 1.4356 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/08 12:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 107/146. Dataloading: 0.0019 s/iter. Inference: 0.0723 s/iter. Eval: 1.2607 s/iter. Total: 1.3354 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/08 12:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 117/146. Dataloading: 0.0019 s/iter. Inference: 0.0721 s/iter. Eval: 1.1884 s/iter. Total: 1.2628 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/08 12:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 129/146. Dataloading: 0.0019 s/iter. Inference: 0.0715 s/iter. Eval: 1.1104 s/iter. Total: 1.1843 s/iter. ETA=0:00:20\n",
      "\u001b[32m[07/08 12:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 140/146. Dataloading: 0.0019 s/iter. Inference: 0.0712 s/iter. Eval: 1.0529 s/iter. Total: 1.1264 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/08 12:28:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:35.692945 (1.104205 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 12:28:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.071253 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 12:28:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/08 12:28:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to TomatoMAP/TomatoMAP-Seg/output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/08 12:28:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "evaluate failed: 'info'\n",
      "Epoch 7: evaluate failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45811/3081507412.py\", line 123, in _do_eval\n",
      "    results = inference_on_dataset(self.trainer.model, val_loader, evaluator)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py\", line 215, in inference_on_dataset\n",
      "    results = evaluator.evaluate()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 206, in evaluate\n",
      "    self._eval_predictions(predictions, img_ids=img_ids)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 266, in _eval_predictions\n",
      "    _evaluate_predictions_on_coco(\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 590, in _evaluate_predictions_on_coco\n",
      "    coco_dt = coco_gt.loadRes(coco_results)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/pycocotools/coco.py\", line 314, in loadRes\n",
      "    res.dataset['info'] = copy.deepcopy(self.dataset['info'])\n",
      "KeyError: 'info'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/08 12:28:53 d2.utils.events]: \u001b[0m eta: 0:24:20  iter: 7439  total_loss: 1.028  loss_cls: 0.3602  loss_box_reg: 0.4934  loss_mask: 0.08517  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.0581    time: 0.4651  last_time: 0.5596  data_time: 0.0241  last_data_time: 0.0825   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:29:03 d2.utils.events]: \u001b[0m eta: 0:24:09  iter: 7459  total_loss: 0.8943  loss_cls: 0.3203  loss_box_reg: 0.4381  loss_mask: 0.07501  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.03684    time: 0.4650  last_time: 0.4566  data_time: 0.0125  last_data_time: 0.0110   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:29:12 d2.utils.events]: \u001b[0m eta: 0:24:00  iter: 7479  total_loss: 0.894  loss_cls: 0.3261  loss_box_reg: 0.443  loss_mask: 0.07412  loss_rpn_cls: 0.009382  loss_rpn_loc: 0.04032    time: 0.4651  last_time: 0.4694  data_time: 0.0176  last_data_time: 0.0075   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:29:22 d2.utils.events]: \u001b[0m eta: 0:23:51  iter: 7499  total_loss: 0.9338  loss_cls: 0.3174  loss_box_reg: 0.4675  loss_mask: 0.09023  loss_rpn_cls: 0.01024  loss_rpn_loc: 0.04524    time: 0.4651  last_time: 0.5657  data_time: 0.0302  last_data_time: 0.1337   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:29:31 d2.utils.events]: \u001b[0m eta: 0:23:43  iter: 7519  total_loss: 0.9417  loss_cls: 0.3121  loss_box_reg: 0.4632  loss_mask: 0.09261  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.04619    time: 0.4650  last_time: 0.4688  data_time: 0.0120  last_data_time: 0.0078   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:29:40 d2.utils.events]: \u001b[0m eta: 0:23:33  iter: 7539  total_loss: 0.9108  loss_cls: 0.3011  loss_box_reg: 0.4386  loss_mask: 0.08022  loss_rpn_cls: 0.008367  loss_rpn_loc: 0.04191    time: 0.4650  last_time: 0.4474  data_time: 0.0107  last_data_time: 0.0086   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:29:49 d2.utils.events]: \u001b[0m eta: 0:23:22  iter: 7559  total_loss: 0.958  loss_cls: 0.3207  loss_box_reg: 0.471  loss_mask: 0.09459  loss_rpn_cls: 0.009891  loss_rpn_loc: 0.04972    time: 0.4650  last_time: 0.4541  data_time: 0.0227  last_data_time: 0.0133   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:29:58 d2.utils.events]: \u001b[0m eta: 0:23:12  iter: 7579  total_loss: 0.8649  loss_cls: 0.2947  loss_box_reg: 0.4311  loss_mask: 0.07478  loss_rpn_cls: 0.01086  loss_rpn_loc: 0.03232    time: 0.4650  last_time: 0.4447  data_time: 0.0175  last_data_time: 0.0099   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:30:08 d2.utils.events]: \u001b[0m eta: 0:23:03  iter: 7599  total_loss: 0.9361  loss_cls: 0.3249  loss_box_reg: 0.4693  loss_mask: 0.06602  loss_rpn_cls: 0.008859  loss_rpn_loc: 0.04323    time: 0.4651  last_time: 0.4668  data_time: 0.0242  last_data_time: 0.0096   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:30:17 d2.utils.events]: \u001b[0m eta: 0:22:55  iter: 7619  total_loss: 0.9247  loss_cls: 0.3149  loss_box_reg: 0.4493  loss_mask: 0.08755  loss_rpn_cls: 0.006783  loss_rpn_loc: 0.04567    time: 0.4651  last_time: 0.4420  data_time: 0.0132  last_data_time: 0.0195   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:30:27 d2.utils.events]: \u001b[0m eta: 0:22:47  iter: 7639  total_loss: 0.9742  loss_cls: 0.3044  loss_box_reg: 0.5007  loss_mask: 0.09449  loss_rpn_cls: 0.006835  loss_rpn_loc: 0.04588    time: 0.4651  last_time: 0.4448  data_time: 0.0147  last_data_time: 0.0167   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:30:36 d2.utils.events]: \u001b[0m eta: 0:22:39  iter: 7659  total_loss: 0.9636  loss_cls: 0.3177  loss_box_reg: 0.4726  loss_mask: 0.08022  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.05091    time: 0.4651  last_time: 0.4906  data_time: 0.0225  last_data_time: 0.0058   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:30:46 d2.utils.events]: \u001b[0m eta: 0:22:30  iter: 7679  total_loss: 0.9773  loss_cls: 0.3416  loss_box_reg: 0.4984  loss_mask: 0.09399  loss_rpn_cls: 0.008461  loss_rpn_loc: 0.04858    time: 0.4651  last_time: 0.4482  data_time: 0.0269  last_data_time: 0.0042   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:30:55 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 7699  total_loss: 0.8823  loss_cls: 0.2845  loss_box_reg: 0.436  loss_mask: 0.08076  loss_rpn_cls: 0.008258  loss_rpn_loc: 0.04346    time: 0.4651  last_time: 0.4764  data_time: 0.0180  last_data_time: 0.0142   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:31:04 d2.utils.events]: \u001b[0m eta: 0:22:11  iter: 7719  total_loss: 0.88  loss_cls: 0.3039  loss_box_reg: 0.4491  loss_mask: 0.0862  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.04256    time: 0.4651  last_time: 0.4110  data_time: 0.0162  last_data_time: 0.0093   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:31:14 d2.utils.events]: \u001b[0m eta: 0:22:02  iter: 7739  total_loss: 0.9055  loss_cls: 0.3099  loss_box_reg: 0.4419  loss_mask: 0.08824  loss_rpn_cls: 0.008384  loss_rpn_loc: 0.04849    time: 0.4651  last_time: 0.4621  data_time: 0.0270  last_data_time: 0.0101   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:31:23 d2.utils.events]: \u001b[0m eta: 0:21:53  iter: 7759  total_loss: 0.9907  loss_cls: 0.3348  loss_box_reg: 0.4793  loss_mask: 0.0787  loss_rpn_cls: 0.01021  loss_rpn_loc: 0.047    time: 0.4652  last_time: 0.4608  data_time: 0.0208  last_data_time: 0.0094   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:31:33 d2.utils.events]: \u001b[0m eta: 0:21:43  iter: 7779  total_loss: 0.9937  loss_cls: 0.3218  loss_box_reg: 0.4993  loss_mask: 0.08787  loss_rpn_cls: 0.01723  loss_rpn_loc: 0.04926    time: 0.4652  last_time: 0.4764  data_time: 0.0151  last_data_time: 0.0087   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:31:42 d2.utils.events]: \u001b[0m eta: 0:21:35  iter: 7799  total_loss: 0.929  loss_cls: 0.3159  loss_box_reg: 0.4707  loss_mask: 0.09067  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.03986    time: 0.4652  last_time: 0.4212  data_time: 0.0231  last_data_time: 0.0089   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:31:52 d2.utils.events]: \u001b[0m eta: 0:21:27  iter: 7819  total_loss: 0.863  loss_cls: 0.2943  loss_box_reg: 0.4317  loss_mask: 0.08418  loss_rpn_cls: 0.008144  loss_rpn_loc: 0.03735    time: 0.4652  last_time: 0.5977  data_time: 0.0259  last_data_time: 0.1357   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:32:01 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 7839  total_loss: 0.954  loss_cls: 0.3338  loss_box_reg: 0.4669  loss_mask: 0.08589  loss_rpn_cls: 0.01067  loss_rpn_loc: 0.0533    time: 0.4653  last_time: 0.4443  data_time: 0.0113  last_data_time: 0.0092   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:32:11 d2.utils.events]: \u001b[0m eta: 0:21:11  iter: 7859  total_loss: 0.8898  loss_cls: 0.3357  loss_box_reg: 0.4319  loss_mask: 0.08541  loss_rpn_cls: 0.00823  loss_rpn_loc: 0.04401    time: 0.4653  last_time: 0.4658  data_time: 0.0123  last_data_time: 0.0097   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:32:20 d2.utils.events]: \u001b[0m eta: 0:21:00  iter: 7879  total_loss: 0.8845  loss_cls: 0.2896  loss_box_reg: 0.4505  loss_mask: 0.08554  loss_rpn_cls: 0.007228  loss_rpn_loc: 0.04249    time: 0.4652  last_time: 0.4406  data_time: 0.0147  last_data_time: 0.0108   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:32:29 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 7899  total_loss: 0.9927  loss_cls: 0.3386  loss_box_reg: 0.4798  loss_mask: 0.0885  loss_rpn_cls: 0.0126  loss_rpn_loc: 0.05112    time: 0.4653  last_time: 0.4782  data_time: 0.0107  last_data_time: 0.0080   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:32:38 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 7919  total_loss: 0.8908  loss_cls: 0.3148  loss_box_reg: 0.4388  loss_mask: 0.07836  loss_rpn_cls: 0.008415  loss_rpn_loc: 0.04043    time: 0.4653  last_time: 0.4922  data_time: 0.0179  last_data_time: 0.0088   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:32:48 d2.utils.events]: \u001b[0m eta: 0:20:33  iter: 7939  total_loss: 0.8739  loss_cls: 0.3131  loss_box_reg: 0.4292  loss_mask: 0.08713  loss_rpn_cls: 0.01037  loss_rpn_loc: 0.03606    time: 0.4653  last_time: 0.4667  data_time: 0.0263  last_data_time: 0.0095   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:32:58 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 7959  total_loss: 1.017  loss_cls: 0.3186  loss_box_reg: 0.4828  loss_mask: 0.09938  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.05771    time: 0.4653  last_time: 0.4845  data_time: 0.0246  last_data_time: 0.0061   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:33:07 d2.utils.events]: \u001b[0m eta: 0:20:14  iter: 7979  total_loss: 0.9023  loss_cls: 0.3237  loss_box_reg: 0.4564  loss_mask: 0.08169  loss_rpn_cls: 0.009619  loss_rpn_loc: 0.03524    time: 0.4653  last_time: 0.4243  data_time: 0.0241  last_data_time: 0.0186   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:33:17 d2.utils.events]: \u001b[0m eta: 0:20:03  iter: 7999  total_loss: 0.8954  loss_cls: 0.3139  loss_box_reg: 0.4466  loss_mask: 0.0825  loss_rpn_cls: 0.009949  loss_rpn_loc: 0.04484    time: 0.4654  last_time: 0.5325  data_time: 0.0287  last_data_time: 0.1104   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:33:26 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 8019  total_loss: 0.9197  loss_cls: 0.3328  loss_box_reg: 0.4594  loss_mask: 0.08023  loss_rpn_cls: 0.01505  loss_rpn_loc: 0.04699    time: 0.4653  last_time: 0.5006  data_time: 0.0103  last_data_time: 0.0194   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:33:35 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 8039  total_loss: 0.958  loss_cls: 0.3263  loss_box_reg: 0.4653  loss_mask: 0.08473  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.04622    time: 0.4653  last_time: 0.4788  data_time: 0.0121  last_data_time: 0.0126   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:33:44 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 8059  total_loss: 0.8807  loss_cls: 0.3044  loss_box_reg: 0.4466  loss_mask: 0.09405  loss_rpn_cls: 0.008968  loss_rpn_loc: 0.04132    time: 0.4654  last_time: 0.4974  data_time: 0.0238  last_data_time: 0.0240   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:33:54 d2.utils.events]: \u001b[0m eta: 0:19:25  iter: 8079  total_loss: 0.942  loss_cls: 0.2904  loss_box_reg: 0.4882  loss_mask: 0.08664  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.04914    time: 0.4654  last_time: 0.4606  data_time: 0.0152  last_data_time: 0.0099   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:34:04 d2.utils.events]: \u001b[0m eta: 0:19:16  iter: 8099  total_loss: 0.9139  loss_cls: 0.3239  loss_box_reg: 0.4596  loss_mask: 0.08582  loss_rpn_cls: 0.005937  loss_rpn_loc: 0.04483    time: 0.4654  last_time: 0.4783  data_time: 0.0284  last_data_time: 0.0102   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:34:13 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 8119  total_loss: 0.9185  loss_cls: 0.3353  loss_box_reg: 0.451  loss_mask: 0.08243  loss_rpn_cls: 0.009287  loss_rpn_loc: 0.0446    time: 0.4654  last_time: 0.4700  data_time: 0.0118  last_data_time: 0.0073   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:34:22 d2.utils.events]: \u001b[0m eta: 0:18:58  iter: 8139  total_loss: 0.9245  loss_cls: 0.3153  loss_box_reg: 0.4567  loss_mask: 0.08188  loss_rpn_cls: 0.01065  loss_rpn_loc: 0.04509    time: 0.4654  last_time: 0.4661  data_time: 0.0120  last_data_time: 0.0108   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:34:31 d2.utils.events]: \u001b[0m eta: 0:18:49  iter: 8159  total_loss: 0.9081  loss_cls: 0.3121  loss_box_reg: 0.4702  loss_mask: 0.08239  loss_rpn_cls: 0.007815  loss_rpn_loc: 0.04613    time: 0.4654  last_time: 0.4482  data_time: 0.0187  last_data_time: 0.0024   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:34:41 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 8179  total_loss: 0.9271  loss_cls: 0.3136  loss_box_reg: 0.4762  loss_mask: 0.08234  loss_rpn_cls: 0.007764  loss_rpn_loc: 0.03866    time: 0.4654  last_time: 0.4036  data_time: 0.0122  last_data_time: 0.0098   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:34:50 d2.utils.events]: \u001b[0m eta: 0:18:31  iter: 8199  total_loss: 0.9025  loss_cls: 0.3158  loss_box_reg: 0.4302  loss_mask: 0.0799  loss_rpn_cls: 0.01146  loss_rpn_loc: 0.04941    time: 0.4654  last_time: 0.4796  data_time: 0.0186  last_data_time: 0.0023   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:35:00 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 8219  total_loss: 0.8986  loss_cls: 0.3049  loss_box_reg: 0.4484  loss_mask: 0.08591  loss_rpn_cls: 0.01  loss_rpn_loc: 0.04616    time: 0.4655  last_time: 0.4444  data_time: 0.0296  last_data_time: 0.0144   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:35:09 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 8239  total_loss: 0.8846  loss_cls: 0.2926  loss_box_reg: 0.4649  loss_mask: 0.09346  loss_rpn_cls: 0.008262  loss_rpn_loc: 0.04063    time: 0.4654  last_time: 0.4229  data_time: 0.0221  last_data_time: 0.0140   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:35:18 d2.utils.events]: \u001b[0m eta: 0:18:04  iter: 8259  total_loss: 0.9276  loss_cls: 0.3013  loss_box_reg: 0.4602  loss_mask: 0.08497  loss_rpn_cls: 0.01106  loss_rpn_loc: 0.04065    time: 0.4654  last_time: 0.5609  data_time: 0.0159  last_data_time: 0.1180   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:35:27 d2.utils.events]: \u001b[0m eta: 0:17:55  iter: 8279  total_loss: 0.8829  loss_cls: 0.308  loss_box_reg: 0.4339  loss_mask: 0.07827  loss_rpn_cls: 0.007098  loss_rpn_loc: 0.03828    time: 0.4654  last_time: 0.5542  data_time: 0.0160  last_data_time: 0.1135   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:35:37 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 8299  total_loss: 0.9087  loss_cls: 0.3131  loss_box_reg: 0.4544  loss_mask: 0.07951  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.05775    time: 0.4654  last_time: 0.4942  data_time: 0.0160  last_data_time: 0.0088   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:35:46 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 8319  total_loss: 0.9423  loss_cls: 0.3119  loss_box_reg: 0.4776  loss_mask: 0.08961  loss_rpn_cls: 0.009294  loss_rpn_loc: 0.05158    time: 0.4654  last_time: 0.4658  data_time: 0.0197  last_data_time: 0.0058   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:35:55 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 8339  total_loss: 0.9037  loss_cls: 0.3323  loss_box_reg: 0.446  loss_mask: 0.08325  loss_rpn_cls: 0.008352  loss_rpn_loc: 0.04362    time: 0.4654  last_time: 0.4809  data_time: 0.0218  last_data_time: 0.0206   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:36:05 d2.utils.events]: \u001b[0m eta: 0:17:16  iter: 8359  total_loss: 0.8212  loss_cls: 0.2823  loss_box_reg: 0.4073  loss_mask: 0.07914  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.04214    time: 0.4654  last_time: 0.4275  data_time: 0.0213  last_data_time: 0.0083   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:36:14 d2.utils.events]: \u001b[0m eta: 0:17:07  iter: 8379  total_loss: 0.9112  loss_cls: 0.2949  loss_box_reg: 0.4396  loss_mask: 0.07479  loss_rpn_cls: 0.01103  loss_rpn_loc: 0.04181    time: 0.4654  last_time: 0.4663  data_time: 0.0090  last_data_time: 0.0096   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:36:23 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 8399  total_loss: 0.9776  loss_cls: 0.337  loss_box_reg: 0.4784  loss_mask: 0.08079  loss_rpn_cls: 0.009968  loss_rpn_loc: 0.04026    time: 0.4654  last_time: 0.4787  data_time: 0.0108  last_data_time: 0.0081   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:36:32 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 8419  total_loss: 0.906  loss_cls: 0.3019  loss_box_reg: 0.4521  loss_mask: 0.09165  loss_rpn_cls: 0.008273  loss_rpn_loc: 0.03647    time: 0.4654  last_time: 0.4774  data_time: 0.0183  last_data_time: 0.0108   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:36:42 d2.utils.events]: \u001b[0m eta: 0:16:40  iter: 8439  total_loss: 0.922  loss_cls: 0.3114  loss_box_reg: 0.4421  loss_mask: 0.09015  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.03881    time: 0.4654  last_time: 0.4519  data_time: 0.0239  last_data_time: 0.0084   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:36:51 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 8459  total_loss: 0.9661  loss_cls: 0.3258  loss_box_reg: 0.4821  loss_mask: 0.0958  loss_rpn_cls: 0.009983  loss_rpn_loc: 0.04905    time: 0.4654  last_time: 0.4524  data_time: 0.0178  last_data_time: 0.0087   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:37:01 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 8479  total_loss: 0.973  loss_cls: 0.3191  loss_box_reg: 0.4613  loss_mask: 0.1053  loss_rpn_cls: 0.01445  loss_rpn_loc: 0.05648    time: 0.4654  last_time: 0.4645  data_time: 0.0183  last_data_time: 0.0079   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:37:01 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 12:37:01 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/08 12:37:01 d2.data.datasets.coco]: \u001b[0mLoaded 146 images in COCO format from /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Seg/cocoOut/val.json\n",
      "\u001b[32m[07/08 12:37:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/08 12:37:01 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/08 12:37:01 d2.data.common]: \u001b[0mSerializing 146 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/08 12:37:01 d2.data.common]: \u001b[0mSerialized dataset takes 5.22 MiB\n",
      "\u001b[32m[07/08 12:37:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 146 batches\n",
      "\u001b[32m[07/08 12:37:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/146. Dataloading: 0.0017 s/iter. Inference: 0.0714 s/iter. Eval: 1.6439 s/iter. Total: 1.7170 s/iter. ETA=0:03:51\n",
      "\u001b[32m[07/08 12:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 14/146. Dataloading: 0.0013 s/iter. Inference: 0.0726 s/iter. Eval: 1.7690 s/iter. Total: 1.8433 s/iter. ETA=0:04:03\n",
      "\u001b[32m[07/08 12:37:35 d2.evaluation.evaluator]: \u001b[0mInference done 17/146. Dataloading: 0.0014 s/iter. Inference: 0.0736 s/iter. Eval: 1.8428 s/iter. Total: 1.9182 s/iter. ETA=0:04:07\n",
      "\u001b[32m[07/08 12:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 21/146. Dataloading: 0.0015 s/iter. Inference: 0.0729 s/iter. Eval: 1.7957 s/iter. Total: 1.8706 s/iter. ETA=0:03:53\n",
      "\u001b[32m[07/08 12:37:48 d2.evaluation.evaluator]: \u001b[0mInference done 24/146. Dataloading: 0.0016 s/iter. Inference: 0.0731 s/iter. Eval: 1.8152 s/iter. Total: 1.8904 s/iter. ETA=0:03:50\n",
      "\u001b[32m[07/08 12:37:53 d2.evaluation.evaluator]: \u001b[0mInference done 27/146. Dataloading: 0.0018 s/iter. Inference: 0.0729 s/iter. Eval: 1.7940 s/iter. Total: 1.8692 s/iter. ETA=0:03:42\n",
      "\u001b[32m[07/08 12:38:01 d2.evaluation.evaluator]: \u001b[0mInference done 31/146. Dataloading: 0.0018 s/iter. Inference: 0.0724 s/iter. Eval: 1.7830 s/iter. Total: 1.8578 s/iter. ETA=0:03:33\n",
      "\u001b[32m[07/08 12:38:06 d2.evaluation.evaluator]: \u001b[0mInference done 34/146. Dataloading: 0.0019 s/iter. Inference: 0.0722 s/iter. Eval: 1.7742 s/iter. Total: 1.8488 s/iter. ETA=0:03:27\n",
      "\u001b[32m[07/08 12:38:13 d2.evaluation.evaluator]: \u001b[0mInference done 38/146. Dataloading: 0.0019 s/iter. Inference: 0.0719 s/iter. Eval: 1.7556 s/iter. Total: 1.8299 s/iter. ETA=0:03:17\n",
      "\u001b[32m[07/08 12:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 40/146. Dataloading: 0.0019 s/iter. Inference: 0.0724 s/iter. Eval: 1.7987 s/iter. Total: 1.8735 s/iter. ETA=0:03:18\n",
      "\u001b[32m[07/08 12:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 43/146. Dataloading: 0.0019 s/iter. Inference: 0.0728 s/iter. Eval: 1.8324 s/iter. Total: 1.9076 s/iter. ETA=0:03:16\n",
      "\u001b[32m[07/08 12:38:31 d2.evaluation.evaluator]: \u001b[0mInference done 45/146. Dataloading: 0.0019 s/iter. Inference: 0.0735 s/iter. Eval: 1.8869 s/iter. Total: 1.9629 s/iter. ETA=0:03:18\n",
      "\u001b[32m[07/08 12:38:37 d2.evaluation.evaluator]: \u001b[0mInference done 49/146. Dataloading: 0.0020 s/iter. Inference: 0.0733 s/iter. Eval: 1.8456 s/iter. Total: 1.9215 s/iter. ETA=0:03:06\n",
      "\u001b[32m[07/08 12:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 52/146. Dataloading: 0.0021 s/iter. Inference: 0.0739 s/iter. Eval: 1.8666 s/iter. Total: 1.9431 s/iter. ETA=0:03:02\n",
      "\u001b[32m[07/08 12:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 55/146. Dataloading: 0.0021 s/iter. Inference: 0.0742 s/iter. Eval: 1.8691 s/iter. Total: 1.9460 s/iter. ETA=0:02:57\n",
      "\u001b[32m[07/08 12:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 57/146. Dataloading: 0.0022 s/iter. Inference: 0.0748 s/iter. Eval: 1.9102 s/iter. Total: 1.9878 s/iter. ETA=0:02:56\n",
      "\u001b[32m[07/08 12:39:02 d2.evaluation.evaluator]: \u001b[0mInference done 60/146. Dataloading: 0.0021 s/iter. Inference: 0.0751 s/iter. Eval: 1.9148 s/iter. Total: 1.9926 s/iter. ETA=0:02:51\n",
      "\u001b[32m[07/08 12:39:08 d2.evaluation.evaluator]: \u001b[0mInference done 63/146. Dataloading: 0.0021 s/iter. Inference: 0.0751 s/iter. Eval: 1.9138 s/iter. Total: 1.9916 s/iter. ETA=0:02:45\n",
      "\u001b[32m[07/08 12:39:14 d2.evaluation.evaluator]: \u001b[0mInference done 66/146. Dataloading: 0.0021 s/iter. Inference: 0.0751 s/iter. Eval: 1.9107 s/iter. Total: 1.9885 s/iter. ETA=0:02:39\n",
      "\u001b[32m[07/08 12:39:20 d2.evaluation.evaluator]: \u001b[0mInference done 70/146. Dataloading: 0.0020 s/iter. Inference: 0.0749 s/iter. Eval: 1.8855 s/iter. Total: 1.9630 s/iter. ETA=0:02:29\n",
      "\u001b[32m[07/08 12:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 73/146. Dataloading: 0.0020 s/iter. Inference: 0.0750 s/iter. Eval: 1.8963 s/iter. Total: 1.9739 s/iter. ETA=0:02:24\n",
      "\u001b[32m[07/08 12:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 75/146. Dataloading: 0.0020 s/iter. Inference: 0.0754 s/iter. Eval: 1.9312 s/iter. Total: 2.0092 s/iter. ETA=0:02:22\n",
      "\u001b[32m[07/08 12:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 78/146. Dataloading: 0.0021 s/iter. Inference: 0.0754 s/iter. Eval: 1.9195 s/iter. Total: 1.9975 s/iter. ETA=0:02:15\n",
      "\u001b[32m[07/08 12:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 82/146. Dataloading: 0.0021 s/iter. Inference: 0.0753 s/iter. Eval: 1.8922 s/iter. Total: 1.9701 s/iter. ETA=0:02:06\n",
      "\u001b[32m[07/08 12:39:51 d2.evaluation.evaluator]: \u001b[0mInference done 86/146. Dataloading: 0.0021 s/iter. Inference: 0.0752 s/iter. Eval: 1.8761 s/iter. Total: 1.9539 s/iter. ETA=0:01:57\n",
      "\u001b[32m[07/08 12:39:57 d2.evaluation.evaluator]: \u001b[0mInference done 89/146. Dataloading: 0.0021 s/iter. Inference: 0.0752 s/iter. Eval: 1.8835 s/iter. Total: 1.9613 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/08 12:40:03 d2.evaluation.evaluator]: \u001b[0mInference done 92/146. Dataloading: 0.0020 s/iter. Inference: 0.0751 s/iter. Eval: 1.8836 s/iter. Total: 1.9613 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/08 12:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 96/146. Dataloading: 0.0020 s/iter. Inference: 0.0746 s/iter. Eval: 1.8540 s/iter. Total: 1.9312 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/08 12:40:14 d2.evaluation.evaluator]: \u001b[0mInference done 99/146. Dataloading: 0.0020 s/iter. Inference: 0.0746 s/iter. Eval: 1.8548 s/iter. Total: 1.9320 s/iter. ETA=0:01:30\n",
      "\u001b[32m[07/08 12:40:19 d2.evaluation.evaluator]: \u001b[0mInference done 102/146. Dataloading: 0.0020 s/iter. Inference: 0.0744 s/iter. Eval: 1.8494 s/iter. Total: 1.9264 s/iter. ETA=0:01:24\n",
      "\u001b[32m[07/08 12:40:27 d2.evaluation.evaluator]: \u001b[0mInference done 106/146. Dataloading: 0.0020 s/iter. Inference: 0.0744 s/iter. Eval: 1.8469 s/iter. Total: 1.9238 s/iter. ETA=0:01:16\n",
      "\u001b[32m[07/08 12:40:32 d2.evaluation.evaluator]: \u001b[0mInference done 109/146. Dataloading: 0.0020 s/iter. Inference: 0.0743 s/iter. Eval: 1.8442 s/iter. Total: 1.9211 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/08 12:40:38 d2.evaluation.evaluator]: \u001b[0mInference done 111/146. Dataloading: 0.0020 s/iter. Inference: 0.0745 s/iter. Eval: 1.8628 s/iter. Total: 1.9399 s/iter. ETA=0:01:07\n",
      "\u001b[32m[07/08 12:40:43 d2.evaluation.evaluator]: \u001b[0mInference done 114/146. Dataloading: 0.0020 s/iter. Inference: 0.0744 s/iter. Eval: 1.8585 s/iter. Total: 1.9354 s/iter. ETA=0:01:01\n",
      "\u001b[32m[07/08 12:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 118/146. Dataloading: 0.0020 s/iter. Inference: 0.0743 s/iter. Eval: 1.8455 s/iter. Total: 1.9223 s/iter. ETA=0:00:53\n",
      "\u001b[32m[07/08 12:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 121/146. Dataloading: 0.0019 s/iter. Inference: 0.0743 s/iter. Eval: 1.8417 s/iter. Total: 1.9186 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/08 12:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 132/146. Dataloading: 0.0019 s/iter. Inference: 0.0737 s/iter. Eval: 1.7171 s/iter. Total: 1.7933 s/iter. ETA=0:00:25\n",
      "\u001b[32m[07/08 12:41:05 d2.evaluation.evaluator]: \u001b[0mInference done 141/146. Dataloading: 0.0019 s/iter. Inference: 0.0735 s/iter. Eval: 1.6358 s/iter. Total: 1.7118 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/08 12:41:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:56.236403 (1.675435 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 12:41:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.073564 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 12:41:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/08 12:41:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to TomatoMAP/TomatoMAP-Seg/output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/08 12:41:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "evaluate failed: 'info'\n",
      "Epoch 8: evaluate failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45811/3081507412.py\", line 123, in _do_eval\n",
      "    results = inference_on_dataset(self.trainer.model, val_loader, evaluator)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py\", line 215, in inference_on_dataset\n",
      "    results = evaluator.evaluate()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 206, in evaluate\n",
      "    self._eval_predictions(predictions, img_ids=img_ids)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 266, in _eval_predictions\n",
      "    _evaluate_predictions_on_coco(\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 590, in _evaluate_predictions_on_coco\n",
      "    coco_dt = coco_gt.loadRes(coco_results)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/pycocotools/coco.py\", line 314, in loadRes\n",
      "    res.dataset['info'] = copy.deepcopy(self.dataset['info'])\n",
      "KeyError: 'info'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/08 12:41:18 d2.utils.events]: \u001b[0m eta: 0:16:14  iter: 8499  total_loss: 0.9132  loss_cls: 0.3085  loss_box_reg: 0.4616  loss_mask: 0.09261  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.04337    time: 0.4654  last_time: 0.4559  data_time: 0.0236  last_data_time: 0.0099   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:41:28 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 8519  total_loss: 0.8766  loss_cls: 0.3227  loss_box_reg: 0.4351  loss_mask: 0.07112  loss_rpn_cls: 0.00761  loss_rpn_loc: 0.03827    time: 0.4654  last_time: 0.4299  data_time: 0.0226  last_data_time: 0.0026   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:41:37 d2.utils.events]: \u001b[0m eta: 0:15:56  iter: 8539  total_loss: 0.8979  loss_cls: 0.3206  loss_box_reg: 0.4449  loss_mask: 0.08513  loss_rpn_cls: 0.008552  loss_rpn_loc: 0.03808    time: 0.4654  last_time: 0.4021  data_time: 0.0167  last_data_time: 0.0082   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:41:46 d2.utils.events]: \u001b[0m eta: 0:15:47  iter: 8559  total_loss: 0.9399  loss_cls: 0.3323  loss_box_reg: 0.4715  loss_mask: 0.09881  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.05116    time: 0.4654  last_time: 0.4132  data_time: 0.0150  last_data_time: 0.0091   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:41:55 d2.utils.events]: \u001b[0m eta: 0:15:38  iter: 8579  total_loss: 0.9585  loss_cls: 0.3305  loss_box_reg: 0.4688  loss_mask: 0.07585  loss_rpn_cls: 0.008749  loss_rpn_loc: 0.04041    time: 0.4653  last_time: 0.4836  data_time: 0.0107  last_data_time: 0.0123   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:42:04 d2.utils.events]: \u001b[0m eta: 0:15:29  iter: 8599  total_loss: 0.9505  loss_cls: 0.3269  loss_box_reg: 0.4812  loss_mask: 0.09746  loss_rpn_cls: 0.008805  loss_rpn_loc: 0.04562    time: 0.4653  last_time: 0.4934  data_time: 0.0139  last_data_time: 0.0139   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:42:14 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 8619  total_loss: 0.8932  loss_cls: 0.2976  loss_box_reg: 0.4522  loss_mask: 0.07845  loss_rpn_cls: 0.009601  loss_rpn_loc: 0.04372    time: 0.4653  last_time: 0.4476  data_time: 0.0123  last_data_time: 0.0121   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:42:23 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 8639  total_loss: 0.9091  loss_cls: 0.3363  loss_box_reg: 0.4592  loss_mask: 0.07424  loss_rpn_cls: 0.01025  loss_rpn_loc: 0.04893    time: 0.4653  last_time: 0.4663  data_time: 0.0199  last_data_time: 0.0151   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:42:32 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 8659  total_loss: 0.8785  loss_cls: 0.3211  loss_box_reg: 0.4538  loss_mask: 0.06618  loss_rpn_cls: 0.007098  loss_rpn_loc: 0.03491    time: 0.4653  last_time: 0.4703  data_time: 0.0131  last_data_time: 0.0114   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:42:41 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 8679  total_loss: 0.8943  loss_cls: 0.3168  loss_box_reg: 0.4415  loss_mask: 0.09803  loss_rpn_cls: 0.009157  loss_rpn_loc: 0.04757    time: 0.4653  last_time: 0.4472  data_time: 0.0113  last_data_time: 0.0113   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:42:51 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 8699  total_loss: 0.8191  loss_cls: 0.2673  loss_box_reg: 0.42  loss_mask: 0.07398  loss_rpn_cls: 0.007107  loss_rpn_loc: 0.03547    time: 0.4653  last_time: 0.4685  data_time: 0.0184  last_data_time: 0.0090   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:43:00 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 8719  total_loss: 0.9324  loss_cls: 0.3093  loss_box_reg: 0.478  loss_mask: 0.09558  loss_rpn_cls: 0.01196  loss_rpn_loc: 0.04716    time: 0.4653  last_time: 0.4235  data_time: 0.0238  last_data_time: 0.0083   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:43:10 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 8739  total_loss: 0.9408  loss_cls: 0.3293  loss_box_reg: 0.4657  loss_mask: 0.09503  loss_rpn_cls: 0.009845  loss_rpn_loc: 0.04605    time: 0.4653  last_time: 0.4442  data_time: 0.0177  last_data_time: 0.0089   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:43:19 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 8759  total_loss: 0.831  loss_cls: 0.2809  loss_box_reg: 0.4271  loss_mask: 0.08222  loss_rpn_cls: 0.008795  loss_rpn_loc: 0.03739    time: 0.4653  last_time: 0.4528  data_time: 0.0114  last_data_time: 0.0095   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:43:28 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 8779  total_loss: 0.9365  loss_cls: 0.3122  loss_box_reg: 0.4743  loss_mask: 0.08415  loss_rpn_cls: 0.01098  loss_rpn_loc: 0.04696    time: 0.4653  last_time: 0.4870  data_time: 0.0114  last_data_time: 0.0096   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:43:37 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 8799  total_loss: 0.8728  loss_cls: 0.3004  loss_box_reg: 0.4435  loss_mask: 0.07481  loss_rpn_cls: 0.009098  loss_rpn_loc: 0.04042    time: 0.4653  last_time: 0.4394  data_time: 0.0115  last_data_time: 0.0168   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:43:47 d2.utils.events]: \u001b[0m eta: 0:13:43  iter: 8819  total_loss: 0.9555  loss_cls: 0.333  loss_box_reg: 0.4975  loss_mask: 0.0843  loss_rpn_cls: 0.008881  loss_rpn_loc: 0.0498    time: 0.4653  last_time: 0.4518  data_time: 0.0281  last_data_time: 0.0049   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:43:57 d2.utils.events]: \u001b[0m eta: 0:13:34  iter: 8839  total_loss: 0.9431  loss_cls: 0.3123  loss_box_reg: 0.4745  loss_mask: 0.07861  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.04945    time: 0.4654  last_time: 0.4592  data_time: 0.0296  last_data_time: 0.0171   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:44:06 d2.utils.events]: \u001b[0m eta: 0:13:25  iter: 8859  total_loss: 0.9409  loss_cls: 0.3256  loss_box_reg: 0.48  loss_mask: 0.08951  loss_rpn_cls: 0.008345  loss_rpn_loc: 0.05067    time: 0.4654  last_time: 0.4748  data_time: 0.0368  last_data_time: 0.0100   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:44:16 d2.utils.events]: \u001b[0m eta: 0:13:16  iter: 8879  total_loss: 0.9098  loss_cls: 0.311  loss_box_reg: 0.4488  loss_mask: 0.09188  loss_rpn_cls: 0.008301  loss_rpn_loc: 0.03582    time: 0.4654  last_time: 0.4573  data_time: 0.0217  last_data_time: 0.0084   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:44:25 d2.utils.events]: \u001b[0m eta: 0:13:07  iter: 8899  total_loss: 0.9289  loss_cls: 0.3092  loss_box_reg: 0.4669  loss_mask: 0.1031  loss_rpn_cls: 0.008879  loss_rpn_loc: 0.0479    time: 0.4655  last_time: 0.4952  data_time: 0.0240  last_data_time: 0.0210   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:44:35 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 8919  total_loss: 0.9434  loss_cls: 0.3183  loss_box_reg: 0.4538  loss_mask: 0.08634  loss_rpn_cls: 0.01078  loss_rpn_loc: 0.03874    time: 0.4655  last_time: 0.5166  data_time: 0.0221  last_data_time: 0.0576   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:44:44 d2.utils.events]: \u001b[0m eta: 0:12:49  iter: 8939  total_loss: 0.9319  loss_cls: 0.3168  loss_box_reg: 0.4668  loss_mask: 0.07468  loss_rpn_cls: 0.009332  loss_rpn_loc: 0.04845    time: 0.4655  last_time: 0.4652  data_time: 0.0228  last_data_time: 0.0024   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:44:54 d2.utils.events]: \u001b[0m eta: 0:12:40  iter: 8959  total_loss: 0.9229  loss_cls: 0.305  loss_box_reg: 0.4764  loss_mask: 0.08248  loss_rpn_cls: 0.00896  loss_rpn_loc: 0.04403    time: 0.4655  last_time: 0.4607  data_time: 0.0314  last_data_time: 0.0024   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:45:03 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 8979  total_loss: 0.8867  loss_cls: 0.3076  loss_box_reg: 0.4345  loss_mask: 0.08148  loss_rpn_cls: 0.009586  loss_rpn_loc: 0.04016    time: 0.4656  last_time: 0.4531  data_time: 0.0354  last_data_time: 0.0083   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:45:13 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 8999  total_loss: 0.9439  loss_cls: 0.3386  loss_box_reg: 0.4653  loss_mask: 0.08867  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.04759    time: 0.4656  last_time: 0.4439  data_time: 0.0357  last_data_time: 0.0088   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:45:23 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 9019  total_loss: 0.9013  loss_cls: 0.3277  loss_box_reg: 0.4352  loss_mask: 0.07332  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.04254    time: 0.4656  last_time: 0.4814  data_time: 0.0459  last_data_time: 0.0222   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:45:32 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 9039  total_loss: 0.8637  loss_cls: 0.2966  loss_box_reg: 0.4414  loss_mask: 0.07878  loss_rpn_cls: 0.01011  loss_rpn_loc: 0.0461    time: 0.4657  last_time: 0.4509  data_time: 0.0344  last_data_time: 0.0067   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:45:42 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 9059  total_loss: 0.9021  loss_cls: 0.2882  loss_box_reg: 0.4439  loss_mask: 0.0919  loss_rpn_cls: 0.008255  loss_rpn_loc: 0.05564    time: 0.4657  last_time: 0.6195  data_time: 0.0325  last_data_time: 0.1430   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:45:52 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 9079  total_loss: 0.8737  loss_cls: 0.305  loss_box_reg: 0.4387  loss_mask: 0.08429  loss_rpn_cls: 0.007606  loss_rpn_loc: 0.03901    time: 0.4658  last_time: 0.4797  data_time: 0.0177  last_data_time: 0.0093   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:46:01 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 9099  total_loss: 0.9537  loss_cls: 0.3065  loss_box_reg: 0.4882  loss_mask: 0.093  loss_rpn_cls: 0.008245  loss_rpn_loc: 0.05027    time: 0.4658  last_time: 0.4409  data_time: 0.0286  last_data_time: 0.0102   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:46:11 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 9119  total_loss: 0.9001  loss_cls: 0.3215  loss_box_reg: 0.4292  loss_mask: 0.07434  loss_rpn_cls: 0.008019  loss_rpn_loc: 0.0532    time: 0.4658  last_time: 0.4866  data_time: 0.0128  last_data_time: 0.0152   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:46:20 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 9139  total_loss: 0.8854  loss_cls: 0.2934  loss_box_reg: 0.4351  loss_mask: 0.08524  loss_rpn_cls: 0.009659  loss_rpn_loc: 0.04499    time: 0.4658  last_time: 0.4590  data_time: 0.0356  last_data_time: 0.0052   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:46:29 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 9159  total_loss: 0.9821  loss_cls: 0.3333  loss_box_reg: 0.4874  loss_mask: 0.09439  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.05255    time: 0.4658  last_time: 0.4745  data_time: 0.0098  last_data_time: 0.0089   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:46:39 d2.utils.events]: \u001b[0m eta: 0:10:58  iter: 9179  total_loss: 0.8666  loss_cls: 0.3087  loss_box_reg: 0.4285  loss_mask: 0.07536  loss_rpn_cls: 0.00653  loss_rpn_loc: 0.04156    time: 0.4658  last_time: 0.4389  data_time: 0.0225  last_data_time: 0.0090   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:46:49 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 9199  total_loss: 0.9227  loss_cls: 0.3211  loss_box_reg: 0.4488  loss_mask: 0.09059  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.05052    time: 0.4659  last_time: 0.4542  data_time: 0.0321  last_data_time: 0.0177   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:46:58 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 9219  total_loss: 0.8964  loss_cls: 0.3238  loss_box_reg: 0.4551  loss_mask: 0.07945  loss_rpn_cls: 0.01064  loss_rpn_loc: 0.04473    time: 0.4659  last_time: 0.4524  data_time: 0.0089  last_data_time: 0.0076   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:47:07 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 9239  total_loss: 0.8777  loss_cls: 0.3133  loss_box_reg: 0.4422  loss_mask: 0.07865  loss_rpn_cls: 0.00822  loss_rpn_loc: 0.03773    time: 0.4659  last_time: 0.4636  data_time: 0.0166  last_data_time: 0.0102   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:47:17 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 9259  total_loss: 0.9252  loss_cls: 0.3202  loss_box_reg: 0.4479  loss_mask: 0.07181  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.05416    time: 0.4659  last_time: 0.4646  data_time: 0.0112  last_data_time: 0.0148   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:47:26 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 9279  total_loss: 0.9285  loss_cls: 0.3129  loss_box_reg: 0.4827  loss_mask: 0.09226  loss_rpn_cls: 0.008579  loss_rpn_loc: 0.04253    time: 0.4659  last_time: 0.4777  data_time: 0.0240  last_data_time: 0.0086   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:47:36 d2.utils.events]: \u001b[0m eta: 0:10:04  iter: 9299  total_loss: 0.9473  loss_cls: 0.3086  loss_box_reg: 0.4456  loss_mask: 0.08451  loss_rpn_cls: 0.01023  loss_rpn_loc: 0.05078    time: 0.4659  last_time: 0.4373  data_time: 0.0258  last_data_time: 0.0082   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:47:45 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 9319  total_loss: 0.8427  loss_cls: 0.292  loss_box_reg: 0.4053  loss_mask: 0.07992  loss_rpn_cls: 0.005889  loss_rpn_loc: 0.03613    time: 0.4659  last_time: 0.4413  data_time: 0.0108  last_data_time: 0.0088   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:47:55 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 9339  total_loss: 0.9549  loss_cls: 0.3131  loss_box_reg: 0.4779  loss_mask: 0.08921  loss_rpn_cls: 0.008923  loss_rpn_loc: 0.04353    time: 0.4659  last_time: 0.4264  data_time: 0.0148  last_data_time: 0.0076   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:48:04 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 9359  total_loss: 0.8897  loss_cls: 0.301  loss_box_reg: 0.4591  loss_mask: 0.07864  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.04049    time: 0.4659  last_time: 0.4265  data_time: 0.0159  last_data_time: 0.0103   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:48:13 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 9379  total_loss: 0.9801  loss_cls: 0.3254  loss_box_reg: 0.4906  loss_mask: 0.07801  loss_rpn_cls: 0.01105  loss_rpn_loc: 0.05721    time: 0.4659  last_time: 0.4674  data_time: 0.0120  last_data_time: 0.0070   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:48:22 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 9399  total_loss: 0.8797  loss_cls: 0.2997  loss_box_reg: 0.4422  loss_mask: 0.08171  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.04328    time: 0.4659  last_time: 0.4810  data_time: 0.0157  last_data_time: 0.0076   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:48:32 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 9419  total_loss: 0.8751  loss_cls: 0.3124  loss_box_reg: 0.4436  loss_mask: 0.07714  loss_rpn_cls: 0.009896  loss_rpn_loc: 0.0445    time: 0.4659  last_time: 0.5830  data_time: 0.0169  last_data_time: 0.1366   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:48:41 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 9439  total_loss: 0.9282  loss_cls: 0.3098  loss_box_reg: 0.4622  loss_mask: 0.08266  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.04215    time: 0.4659  last_time: 0.4459  data_time: 0.0237  last_data_time: 0.0102   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:48:50 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 9459  total_loss: 0.8866  loss_cls: 0.2889  loss_box_reg: 0.4306  loss_mask: 0.07984  loss_rpn_cls: 0.01066  loss_rpn_loc: 0.04147    time: 0.4659  last_time: 0.4830  data_time: 0.0221  last_data_time: 0.0081   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:49:00 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 9479  total_loss: 0.9328  loss_cls: 0.2958  loss_box_reg: 0.4461  loss_mask: 0.09053  loss_rpn_cls: 0.009418  loss_rpn_loc: 0.04959    time: 0.4659  last_time: 0.6202  data_time: 0.0298  last_data_time: 0.1475   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:49:09 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 9499  total_loss: 0.9286  loss_cls: 0.3147  loss_box_reg: 0.4491  loss_mask: 0.09412  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.04217    time: 0.4659  last_time: 0.4829  data_time: 0.0336  last_data_time: 0.0098   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:49:19 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 9519  total_loss: 0.8587  loss_cls: 0.3144  loss_box_reg: 0.4448  loss_mask: 0.09201  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.04584    time: 0.4660  last_time: 0.4464  data_time: 0.0383  last_data_time: 0.0049   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:49:29 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 9539  total_loss: 0.8902  loss_cls: 0.3024  loss_box_reg: 0.4351  loss_mask: 0.08997  loss_rpn_cls: 0.008288  loss_rpn_loc: 0.04663    time: 0.4660  last_time: 0.6160  data_time: 0.0304  last_data_time: 0.1590   lr: 2.4e-05  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:49:29 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 12:49:29 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/08 12:49:29 d2.data.datasets.coco]: \u001b[0mLoaded 146 images in COCO format from /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Seg/cocoOut/val.json\n",
      "\u001b[32m[07/08 12:49:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/08 12:49:29 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/08 12:49:29 d2.data.common]: \u001b[0mSerializing 146 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/08 12:49:29 d2.data.common]: \u001b[0mSerialized dataset takes 5.22 MiB\n",
      "\u001b[32m[07/08 12:49:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 146 batches\n",
      "\u001b[32m[07/08 12:49:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/146. Dataloading: 0.0022 s/iter. Inference: 0.0713 s/iter. Eval: 1.8303 s/iter. Total: 1.9039 s/iter. ETA=0:04:17\n",
      "\u001b[32m[07/08 12:49:59 d2.evaluation.evaluator]: \u001b[0mInference done 14/146. Dataloading: 0.0018 s/iter. Inference: 0.0724 s/iter. Eval: 1.8129 s/iter. Total: 1.8877 s/iter. ETA=0:04:09\n",
      "\u001b[32m[07/08 12:50:05 d2.evaluation.evaluator]: \u001b[0mInference done 17/146. Dataloading: 0.0017 s/iter. Inference: 0.0739 s/iter. Eval: 1.8768 s/iter. Total: 1.9530 s/iter. ETA=0:04:11\n",
      "\u001b[32m[07/08 12:50:13 d2.evaluation.evaluator]: \u001b[0mInference done 21/146. Dataloading: 0.0018 s/iter. Inference: 0.0735 s/iter. Eval: 1.8465 s/iter. Total: 1.9225 s/iter. ETA=0:04:00\n",
      "\u001b[32m[07/08 12:50:19 d2.evaluation.evaluator]: \u001b[0mInference done 24/146. Dataloading: 0.0019 s/iter. Inference: 0.0747 s/iter. Eval: 1.8701 s/iter. Total: 1.9473 s/iter. ETA=0:03:57\n",
      "\u001b[32m[07/08 12:50:25 d2.evaluation.evaluator]: \u001b[0mInference done 27/146. Dataloading: 0.0020 s/iter. Inference: 0.0748 s/iter. Eval: 1.8781 s/iter. Total: 1.9555 s/iter. ETA=0:03:52\n",
      "\u001b[32m[07/08 12:50:30 d2.evaluation.evaluator]: \u001b[0mInference done 30/146. Dataloading: 0.0020 s/iter. Inference: 0.0743 s/iter. Eval: 1.8528 s/iter. Total: 1.9297 s/iter. ETA=0:03:43\n",
      "\u001b[32m[07/08 12:50:35 d2.evaluation.evaluator]: \u001b[0mInference done 32/146. Dataloading: 0.0020 s/iter. Inference: 0.0752 s/iter. Eval: 1.8957 s/iter. Total: 1.9735 s/iter. ETA=0:03:44\n",
      "\u001b[32m[07/08 12:50:41 d2.evaluation.evaluator]: \u001b[0mInference done 35/146. Dataloading: 0.0021 s/iter. Inference: 0.0748 s/iter. Eval: 1.8789 s/iter. Total: 1.9564 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/08 12:50:46 d2.evaluation.evaluator]: \u001b[0mInference done 38/146. Dataloading: 0.0020 s/iter. Inference: 0.0748 s/iter. Eval: 1.8619 s/iter. Total: 1.9394 s/iter. ETA=0:03:29\n",
      "\u001b[32m[07/08 12:50:52 d2.evaluation.evaluator]: \u001b[0mInference done 40/146. Dataloading: 0.0021 s/iter. Inference: 0.0751 s/iter. Eval: 1.9190 s/iter. Total: 1.9969 s/iter. ETA=0:03:31\n",
      "\u001b[32m[07/08 12:50:57 d2.evaluation.evaluator]: \u001b[0mInference done 42/146. Dataloading: 0.0021 s/iter. Inference: 0.0754 s/iter. Eval: 1.9513 s/iter. Total: 2.0294 s/iter. ETA=0:03:31\n",
      "\u001b[32m[07/08 12:51:02 d2.evaluation.evaluator]: \u001b[0mInference done 44/146. Dataloading: 0.0021 s/iter. Inference: 0.0757 s/iter. Eval: 1.9886 s/iter. Total: 2.0671 s/iter. ETA=0:03:30\n",
      "\u001b[32m[07/08 12:51:08 d2.evaluation.evaluator]: \u001b[0mInference done 47/146. Dataloading: 0.0022 s/iter. Inference: 0.0752 s/iter. Eval: 1.9669 s/iter. Total: 2.0449 s/iter. ETA=0:03:22\n",
      "\u001b[32m[07/08 12:51:14 d2.evaluation.evaluator]: \u001b[0mInference done 50/146. Dataloading: 0.0022 s/iter. Inference: 0.0750 s/iter. Eval: 1.9603 s/iter. Total: 2.0382 s/iter. ETA=0:03:15\n",
      "\u001b[32m[07/08 12:51:20 d2.evaluation.evaluator]: \u001b[0mInference done 53/146. Dataloading: 0.0023 s/iter. Inference: 0.0749 s/iter. Eval: 1.9587 s/iter. Total: 2.0366 s/iter. ETA=0:03:09\n",
      "\u001b[32m[07/08 12:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 56/146. Dataloading: 0.0023 s/iter. Inference: 0.0753 s/iter. Eval: 1.9839 s/iter. Total: 2.0622 s/iter. ETA=0:03:05\n",
      "\u001b[32m[07/08 12:51:34 d2.evaluation.evaluator]: \u001b[0mInference done 58/146. Dataloading: 0.0023 s/iter. Inference: 0.0758 s/iter. Eval: 2.0295 s/iter. Total: 2.1083 s/iter. ETA=0:03:05\n",
      "\u001b[32m[07/08 12:51:42 d2.evaluation.evaluator]: \u001b[0mInference done 62/146. Dataloading: 0.0023 s/iter. Inference: 0.0756 s/iter. Eval: 2.0257 s/iter. Total: 2.1042 s/iter. ETA=0:02:56\n",
      "\u001b[32m[07/08 12:51:48 d2.evaluation.evaluator]: \u001b[0mInference done 65/146. Dataloading: 0.0023 s/iter. Inference: 0.0755 s/iter. Eval: 2.0187 s/iter. Total: 2.0971 s/iter. ETA=0:02:49\n",
      "\u001b[32m[07/08 12:51:54 d2.evaluation.evaluator]: \u001b[0mInference done 69/146. Dataloading: 0.0022 s/iter. Inference: 0.0751 s/iter. Eval: 1.9787 s/iter. Total: 2.0567 s/iter. ETA=0:02:38\n",
      "\u001b[32m[07/08 12:52:00 d2.evaluation.evaluator]: \u001b[0mInference done 72/146. Dataloading: 0.0022 s/iter. Inference: 0.0752 s/iter. Eval: 1.9765 s/iter. Total: 2.0546 s/iter. ETA=0:02:32\n",
      "\u001b[32m[07/08 12:52:05 d2.evaluation.evaluator]: \u001b[0mInference done 74/146. Dataloading: 0.0022 s/iter. Inference: 0.0756 s/iter. Eval: 1.9984 s/iter. Total: 2.0768 s/iter. ETA=0:02:29\n",
      "\u001b[32m[07/08 12:52:12 d2.evaluation.evaluator]: \u001b[0mInference done 77/146. Dataloading: 0.0022 s/iter. Inference: 0.0757 s/iter. Eval: 2.0035 s/iter. Total: 2.0820 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/08 12:52:17 d2.evaluation.evaluator]: \u001b[0mInference done 80/146. Dataloading: 0.0022 s/iter. Inference: 0.0757 s/iter. Eval: 1.9929 s/iter. Total: 2.0714 s/iter. ETA=0:02:16\n",
      "\u001b[32m[07/08 12:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 84/146. Dataloading: 0.0022 s/iter. Inference: 0.0756 s/iter. Eval: 1.9746 s/iter. Total: 2.0531 s/iter. ETA=0:02:07\n",
      "\u001b[32m[07/08 12:52:30 d2.evaluation.evaluator]: \u001b[0mInference done 87/146. Dataloading: 0.0022 s/iter. Inference: 0.0756 s/iter. Eval: 1.9698 s/iter. Total: 2.0482 s/iter. ETA=0:02:00\n",
      "\u001b[32m[07/08 12:52:36 d2.evaluation.evaluator]: \u001b[0mInference done 90/146. Dataloading: 0.0021 s/iter. Inference: 0.0755 s/iter. Eval: 1.9662 s/iter. Total: 2.0446 s/iter. ETA=0:01:54\n",
      "\u001b[32m[07/08 12:52:41 d2.evaluation.evaluator]: \u001b[0mInference done 92/146. Dataloading: 0.0022 s/iter. Inference: 0.0758 s/iter. Eval: 1.9858 s/iter. Total: 2.0644 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/08 12:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 96/146. Dataloading: 0.0022 s/iter. Inference: 0.0757 s/iter. Eval: 1.9639 s/iter. Total: 2.0425 s/iter. ETA=0:01:42\n",
      "\u001b[32m[07/08 12:52:54 d2.evaluation.evaluator]: \u001b[0mInference done 99/146. Dataloading: 0.0021 s/iter. Inference: 0.0758 s/iter. Eval: 1.9657 s/iter. Total: 2.0443 s/iter. ETA=0:01:36\n",
      "\u001b[32m[07/08 12:53:00 d2.evaluation.evaluator]: \u001b[0mInference done 102/146. Dataloading: 0.0021 s/iter. Inference: 0.0757 s/iter. Eval: 1.9597 s/iter. Total: 2.0382 s/iter. ETA=0:01:29\n",
      "\u001b[32m[07/08 12:53:07 d2.evaluation.evaluator]: \u001b[0mInference done 106/146. Dataloading: 0.0021 s/iter. Inference: 0.0756 s/iter. Eval: 1.9569 s/iter. Total: 2.0352 s/iter. ETA=0:01:21\n",
      "\u001b[32m[07/08 12:53:13 d2.evaluation.evaluator]: \u001b[0mInference done 109/146. Dataloading: 0.0021 s/iter. Inference: 0.0755 s/iter. Eval: 1.9558 s/iter. Total: 2.0340 s/iter. ETA=0:01:15\n",
      "\u001b[32m[07/08 12:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 111/146. Dataloading: 0.0021 s/iter. Inference: 0.0757 s/iter. Eval: 1.9660 s/iter. Total: 2.0444 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/08 12:53:24 d2.evaluation.evaluator]: \u001b[0mInference done 117/146. Dataloading: 0.0021 s/iter. Inference: 0.0754 s/iter. Eval: 1.9045 s/iter. Total: 1.9826 s/iter. ETA=0:00:57\n",
      "\u001b[32m[07/08 12:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 127/146. Dataloading: 0.0021 s/iter. Inference: 0.0749 s/iter. Eval: 1.7839 s/iter. Total: 1.8614 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/08 12:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 137/146. Dataloading: 0.0020 s/iter. Inference: 0.0744 s/iter. Eval: 1.6821 s/iter. Total: 1.7592 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/08 12:53:40 d2.evaluation.evaluator]: \u001b[0mInference done 144/146. Dataloading: 0.0020 s/iter. Inference: 0.0745 s/iter. Eval: 1.6338 s/iter. Total: 1.7109 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/08 12:53:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:59.038219 (1.695307 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 12:53:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.074376 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 12:53:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/08 12:53:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to TomatoMAP/TomatoMAP-Seg/output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/08 12:53:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "evaluate failed: 'info'\n",
      "Epoch 9: evaluate failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45811/3081507412.py\", line 123, in _do_eval\n",
      "    results = inference_on_dataset(self.trainer.model, val_loader, evaluator)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py\", line 215, in inference_on_dataset\n",
      "    results = evaluator.evaluate()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 206, in evaluate\n",
      "    self._eval_predictions(predictions, img_ids=img_ids)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 266, in _eval_predictions\n",
      "    _evaluate_predictions_on_coco(\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 590, in _evaluate_predictions_on_coco\n",
      "    coco_dt = coco_gt.loadRes(coco_results)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/pycocotools/coco.py\", line 314, in loadRes\n",
      "    res.dataset['info'] = copy.deepcopy(self.dataset['info'])\n",
      "KeyError: 'info'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/08 12:53:51 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 9559  total_loss: 0.8985  loss_cls: 0.3224  loss_box_reg: 0.463  loss_mask: 0.08128  loss_rpn_cls: 0.008203  loss_rpn_loc: 0.05081    time: 0.4661  last_time: 0.4272  data_time: 0.0254  last_data_time: 0.0087   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:54:00 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 9579  total_loss: 0.8203  loss_cls: 0.2902  loss_box_reg: 0.422  loss_mask: 0.06939  loss_rpn_cls: 0.006889  loss_rpn_loc: 0.03715    time: 0.4660  last_time: 0.4485  data_time: 0.0161  last_data_time: 0.0105   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:54:09 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 9599  total_loss: 0.9584  loss_cls: 0.3304  loss_box_reg: 0.478  loss_mask: 0.08064  loss_rpn_cls: 0.00931  loss_rpn_loc: 0.04727    time: 0.4661  last_time: 0.5408  data_time: 0.0262  last_data_time: 0.1170   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:54:19 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 9619  total_loss: 0.9281  loss_cls: 0.3305  loss_box_reg: 0.4761  loss_mask: 0.07436  loss_rpn_cls: 0.009771  loss_rpn_loc: 0.0483    time: 0.4660  last_time: 0.4671  data_time: 0.0104  last_data_time: 0.0111   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:54:28 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 9639  total_loss: 0.9168  loss_cls: 0.334  loss_box_reg: 0.4404  loss_mask: 0.07841  loss_rpn_cls: 0.00976  loss_rpn_loc: 0.04156    time: 0.4661  last_time: 0.4823  data_time: 0.0220  last_data_time: 0.0094   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:54:37 d2.utils.events]: \u001b[0m eta: 0:07:17  iter: 9659  total_loss: 1.005  loss_cls: 0.3305  loss_box_reg: 0.508  loss_mask: 0.0878  loss_rpn_cls: 0.008508  loss_rpn_loc: 0.05142    time: 0.4661  last_time: 0.4300  data_time: 0.0154  last_data_time: 0.0080   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:54:47 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 9679  total_loss: 0.8073  loss_cls: 0.2775  loss_box_reg: 0.4065  loss_mask: 0.08217  loss_rpn_cls: 0.01025  loss_rpn_loc: 0.04126    time: 0.4661  last_time: 0.4836  data_time: 0.0355  last_data_time: 0.0088   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:54:56 d2.utils.events]: \u001b[0m eta: 0:06:59  iter: 9699  total_loss: 0.9152  loss_cls: 0.3  loss_box_reg: 0.4498  loss_mask: 0.07823  loss_rpn_cls: 0.008733  loss_rpn_loc: 0.04115    time: 0.4661  last_time: 0.4595  data_time: 0.0250  last_data_time: 0.0085   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:55:06 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 9719  total_loss: 0.8744  loss_cls: 0.3028  loss_box_reg: 0.4377  loss_mask: 0.0756  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.04564    time: 0.4661  last_time: 0.4096  data_time: 0.0115  last_data_time: 0.0073   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:55:15 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 9739  total_loss: 0.8922  loss_cls: 0.2979  loss_box_reg: 0.4625  loss_mask: 0.08176  loss_rpn_cls: 0.012  loss_rpn_loc: 0.04817    time: 0.4661  last_time: 0.5024  data_time: 0.0205  last_data_time: 0.0146   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:55:24 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 9759  total_loss: 0.8721  loss_cls: 0.3085  loss_box_reg: 0.4359  loss_mask: 0.07548  loss_rpn_cls: 0.008983  loss_rpn_loc: 0.03471    time: 0.4661  last_time: 0.4897  data_time: 0.0100  last_data_time: 0.0136   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:55:34 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 9779  total_loss: 0.8814  loss_cls: 0.306  loss_box_reg: 0.4572  loss_mask: 0.07002  loss_rpn_cls: 0.009849  loss_rpn_loc: 0.03983    time: 0.4661  last_time: 0.4823  data_time: 0.0108  last_data_time: 0.0120   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:55:43 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 9799  total_loss: 0.928  loss_cls: 0.2916  loss_box_reg: 0.4771  loss_mask: 0.08833  loss_rpn_cls: 0.01137  loss_rpn_loc: 0.05808    time: 0.4661  last_time: 0.4924  data_time: 0.0257  last_data_time: 0.0189   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:55:53 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 9819  total_loss: 0.975  loss_cls: 0.3291  loss_box_reg: 0.4934  loss_mask: 0.1003  loss_rpn_cls: 0.01037  loss_rpn_loc: 0.05812    time: 0.4662  last_time: 0.4481  data_time: 0.0249  last_data_time: 0.0114   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:56:03 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 9839  total_loss: 0.8735  loss_cls: 0.3118  loss_box_reg: 0.4412  loss_mask: 0.0804  loss_rpn_cls: 0.01035  loss_rpn_loc: 0.04434    time: 0.4662  last_time: 0.4254  data_time: 0.0196  last_data_time: 0.0024   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:56:12 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 9859  total_loss: 0.9256  loss_cls: 0.3175  loss_box_reg: 0.4567  loss_mask: 0.08459  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.04096    time: 0.4662  last_time: 0.4763  data_time: 0.0325  last_data_time: 0.0143   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:56:22 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 9879  total_loss: 0.8731  loss_cls: 0.2983  loss_box_reg: 0.4391  loss_mask: 0.0745  loss_rpn_cls: 0.008243  loss_rpn_loc: 0.04096    time: 0.4662  last_time: 0.4455  data_time: 0.0219  last_data_time: 0.0114   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:56:31 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 9899  total_loss: 0.9514  loss_cls: 0.3102  loss_box_reg: 0.4744  loss_mask: 0.08415  loss_rpn_cls: 0.009909  loss_rpn_loc: 0.046    time: 0.4662  last_time: 0.4993  data_time: 0.0235  last_data_time: 0.0176   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:56:41 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 9919  total_loss: 0.8864  loss_cls: 0.3278  loss_box_reg: 0.4542  loss_mask: 0.07409  loss_rpn_cls: 0.008821  loss_rpn_loc: 0.03991    time: 0.4663  last_time: 0.4858  data_time: 0.0385  last_data_time: 0.0179   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:56:50 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 9939  total_loss: 0.9256  loss_cls: 0.3112  loss_box_reg: 0.4643  loss_mask: 0.08879  loss_rpn_cls: 0.008117  loss_rpn_loc: 0.04553    time: 0.4663  last_time: 0.4726  data_time: 0.0168  last_data_time: 0.0141   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:57:00 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 9959  total_loss: 0.9206  loss_cls: 0.2885  loss_box_reg: 0.4587  loss_mask: 0.08465  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.04997    time: 0.4663  last_time: 0.4774  data_time: 0.0254  last_data_time: 0.0080   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:57:09 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 9979  total_loss: 0.8984  loss_cls: 0.3115  loss_box_reg: 0.4511  loss_mask: 0.09043  loss_rpn_cls: 0.007324  loss_rpn_loc: 0.04169    time: 0.4663  last_time: 0.4773  data_time: 0.0231  last_data_time: 0.0095   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:57:19 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 9999  total_loss: 0.9294  loss_cls: 0.3082  loss_box_reg: 0.4605  loss_mask: 0.07944  loss_rpn_cls: 0.01203  loss_rpn_loc: 0.05368    time: 0.4663  last_time: 0.4356  data_time: 0.0181  last_data_time: 0.0044   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:57:28 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 10019  total_loss: 0.9222  loss_cls: 0.317  loss_box_reg: 0.458  loss_mask: 0.06972  loss_rpn_cls: 0.008981  loss_rpn_loc: 0.04401    time: 0.4664  last_time: 0.4758  data_time: 0.0143  last_data_time: 0.0085   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:57:38 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 10039  total_loss: 0.9828  loss_cls: 0.3132  loss_box_reg: 0.4623  loss_mask: 0.08878  loss_rpn_cls: 0.01005  loss_rpn_loc: 0.05179    time: 0.4664  last_time: 0.4735  data_time: 0.0206  last_data_time: 0.0045   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:57:48 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 10059  total_loss: 0.9112  loss_cls: 0.297  loss_box_reg: 0.4715  loss_mask: 0.0835  loss_rpn_cls: 0.007082  loss_rpn_loc: 0.03913    time: 0.4664  last_time: 0.4277  data_time: 0.0167  last_data_time: 0.0142   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:57:57 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 10079  total_loss: 0.9141  loss_cls: 0.302  loss_box_reg: 0.4647  loss_mask: 0.08494  loss_rpn_cls: 0.009691  loss_rpn_loc: 0.03832    time: 0.4664  last_time: 0.4752  data_time: 0.0124  last_data_time: 0.0086   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:58:06 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 10099  total_loss: 0.9347  loss_cls: 0.311  loss_box_reg: 0.4661  loss_mask: 0.09716  loss_rpn_cls: 0.006377  loss_rpn_loc: 0.04579    time: 0.4664  last_time: 0.4665  data_time: 0.0195  last_data_time: 0.0082   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:58:15 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 10119  total_loss: 0.8686  loss_cls: 0.2929  loss_box_reg: 0.4187  loss_mask: 0.07816  loss_rpn_cls: 0.0094  loss_rpn_loc: 0.0408    time: 0.4664  last_time: 0.5078  data_time: 0.0108  last_data_time: 0.0224   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:58:25 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 10139  total_loss: 0.9381  loss_cls: 0.3226  loss_box_reg: 0.454  loss_mask: 0.08766  loss_rpn_cls: 0.01049  loss_rpn_loc: 0.04293    time: 0.4664  last_time: 0.4539  data_time: 0.0226  last_data_time: 0.0153   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:58:34 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 10159  total_loss: 0.9217  loss_cls: 0.326  loss_box_reg: 0.4333  loss_mask: 0.07999  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.04419    time: 0.4664  last_time: 0.4253  data_time: 0.0260  last_data_time: 0.0082   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:58:43 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 10179  total_loss: 0.8702  loss_cls: 0.3031  loss_box_reg: 0.4553  loss_mask: 0.07749  loss_rpn_cls: 0.009297  loss_rpn_loc: 0.04462    time: 0.4664  last_time: 0.4665  data_time: 0.0094  last_data_time: 0.0097   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:58:53 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 10199  total_loss: 0.8143  loss_cls: 0.2862  loss_box_reg: 0.4153  loss_mask: 0.07703  loss_rpn_cls: 0.007578  loss_rpn_loc: 0.04049    time: 0.4664  last_time: 0.4651  data_time: 0.0138  last_data_time: 0.0104   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:59:02 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 10219  total_loss: 1.004  loss_cls: 0.3298  loss_box_reg: 0.5107  loss_mask: 0.08711  loss_rpn_cls: 0.01124  loss_rpn_loc: 0.05731    time: 0.4664  last_time: 0.4730  data_time: 0.0106  last_data_time: 0.0091   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:59:11 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 10239  total_loss: 0.8852  loss_cls: 0.2976  loss_box_reg: 0.435  loss_mask: 0.08213  loss_rpn_cls: 0.00987  loss_rpn_loc: 0.0386    time: 0.4664  last_time: 0.4178  data_time: 0.0123  last_data_time: 0.0090   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:59:21 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 10259  total_loss: 0.8709  loss_cls: 0.2963  loss_box_reg: 0.4395  loss_mask: 0.08047  loss_rpn_cls: 0.007126  loss_rpn_loc: 0.04267    time: 0.4664  last_time: 0.4375  data_time: 0.0106  last_data_time: 0.0090   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:59:30 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 10279  total_loss: 0.9544  loss_cls: 0.3244  loss_box_reg: 0.4806  loss_mask: 0.08364  loss_rpn_cls: 0.009244  loss_rpn_loc: 0.0454    time: 0.4664  last_time: 0.4988  data_time: 0.0200  last_data_time: 0.0171   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:59:39 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 10299  total_loss: 0.9144  loss_cls: 0.3072  loss_box_reg: 0.4493  loss_mask: 0.08143  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.0476    time: 0.4664  last_time: 0.4544  data_time: 0.0182  last_data_time: 0.0199   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:59:49 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 10319  total_loss: 0.839  loss_cls: 0.2977  loss_box_reg: 0.4186  loss_mask: 0.08646  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.04324    time: 0.4664  last_time: 0.5846  data_time: 0.0361  last_data_time: 0.1352   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 12:59:59 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 10339  total_loss: 0.9284  loss_cls: 0.3103  loss_box_reg: 0.4644  loss_mask: 0.0951  loss_rpn_cls: 0.008797  loss_rpn_loc: 0.05141    time: 0.4664  last_time: 0.4678  data_time: 0.0115  last_data_time: 0.0077   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:00:08 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 10359  total_loss: 0.9293  loss_cls: 0.3225  loss_box_reg: 0.4401  loss_mask: 0.08226  loss_rpn_cls: 0.009649  loss_rpn_loc: 0.0422    time: 0.4665  last_time: 0.4531  data_time: 0.0307  last_data_time: 0.0076   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:00:18 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 10379  total_loss: 0.7879  loss_cls: 0.2804  loss_box_reg: 0.4199  loss_mask: 0.06936  loss_rpn_cls: 0.009762  loss_rpn_loc: 0.03212    time: 0.4665  last_time: 0.4726  data_time: 0.0112  last_data_time: 0.0141   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:00:27 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 10399  total_loss: 0.9497  loss_cls: 0.3168  loss_box_reg: 0.4917  loss_mask: 0.08492  loss_rpn_cls: 0.008391  loss_rpn_loc: 0.05198    time: 0.4665  last_time: 0.4812  data_time: 0.0129  last_data_time: 0.0063   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:00:37 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 10419  total_loss: 0.8905  loss_cls: 0.3125  loss_box_reg: 0.4388  loss_mask: 0.08354  loss_rpn_cls: 0.008027  loss_rpn_loc: 0.03764    time: 0.4665  last_time: 0.4329  data_time: 0.0274  last_data_time: 0.0107   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:00:47 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 10439  total_loss: 0.893  loss_cls: 0.3001  loss_box_reg: 0.4466  loss_mask: 0.0904  loss_rpn_cls: 0.008848  loss_rpn_loc: 0.03861    time: 0.4666  last_time: 0.4757  data_time: 0.0304  last_data_time: 0.0095   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:00:56 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 10459  total_loss: 0.9009  loss_cls: 0.3193  loss_box_reg: 0.4608  loss_mask: 0.08298  loss_rpn_cls: 0.008929  loss_rpn_loc: 0.04042    time: 0.4666  last_time: 0.4544  data_time: 0.0278  last_data_time: 0.0020   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:01:06 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 10479  total_loss: 0.9197  loss_cls: 0.3088  loss_box_reg: 0.4547  loss_mask: 0.08776  loss_rpn_cls: 0.01245  loss_rpn_loc: 0.04783    time: 0.4666  last_time: 0.4668  data_time: 0.0275  last_data_time: 0.0023   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:01:15 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 10499  total_loss: 0.8953  loss_cls: 0.2862  loss_box_reg: 0.4384  loss_mask: 0.08373  loss_rpn_cls: 0.009515  loss_rpn_loc: 0.03712    time: 0.4666  last_time: 0.4801  data_time: 0.0308  last_data_time: 0.0091   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:01:25 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 10519  total_loss: 0.9293  loss_cls: 0.3199  loss_box_reg: 0.4505  loss_mask: 0.08619  loss_rpn_cls: 0.00917  loss_rpn_loc: 0.04803    time: 0.4667  last_time: 0.4355  data_time: 0.0355  last_data_time: 0.0086   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:01:35 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 10539  total_loss: 0.8122  loss_cls: 0.2874  loss_box_reg: 0.409  loss_mask: 0.08162  loss_rpn_cls: 0.005993  loss_rpn_loc: 0.03576    time: 0.4667  last_time: 0.5486  data_time: 0.0292  last_data_time: 0.0988   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:01:44 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 10559  total_loss: 0.9448  loss_cls: 0.3137  loss_box_reg: 0.4714  loss_mask: 0.09177  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.04462    time: 0.4667  last_time: 0.4506  data_time: 0.0270  last_data_time: 0.0097   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:01:54 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 10579  total_loss: 0.8845  loss_cls: 0.3071  loss_box_reg: 0.4575  loss_mask: 0.08021  loss_rpn_cls: 0.00732  loss_rpn_loc: 0.04125    time: 0.4667  last_time: 0.5124  data_time: 0.0134  last_data_time: 0.0114   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:02:04 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 10599  total_loss: 0.873  loss_cls: 0.3197  loss_box_reg: 0.4371  loss_mask: 0.06997  loss_rpn_cls: 0.008478  loss_rpn_loc: 0.04375    time: 0.4667  last_time: 0.4363  data_time: 0.0193  last_data_time: 0.0097   lr: 2.4e-06  max_mem: 4809M\n",
      "\u001b[32m[07/08 13:02:04 d2.engine.hooks]: \u001b[0mOverall training speed: 10598 iterations in 1:22:26 (0.4667 s / it)\n",
      "\u001b[32m[07/08 13:02:04 d2.engine.hooks]: \u001b[0mTotal training time: 1:52:24 (0:29:57 on hooks)\n",
      "\u001b[32m[07/08 13:02:04 d2.data.datasets.coco]: \u001b[0mLoaded 146 images in COCO format from /home/ubuntu/project/EoC/code/TomatoMAP/TomatoMAP-Seg/cocoOut/val.json\n",
      "\u001b[32m[07/08 13:02:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/08 13:02:04 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/08 13:02:04 d2.data.common]: \u001b[0mSerializing 146 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/08 13:02:04 d2.data.common]: \u001b[0mSerialized dataset takes 5.22 MiB\n",
      "\u001b[32m[07/08 13:02:04 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[07/08 13:02:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 146 batches\n",
      "\u001b[32m[07/08 13:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/146. Dataloading: 0.0030 s/iter. Inference: 0.0695 s/iter. Eval: 1.6269 s/iter. Total: 1.6995 s/iter. ETA=0:03:49\n",
      "\u001b[32m[07/08 13:02:33 d2.evaluation.evaluator]: \u001b[0mInference done 14/146. Dataloading: 0.0023 s/iter. Inference: 0.0697 s/iter. Eval: 1.6604 s/iter. Total: 1.7330 s/iter. ETA=0:03:48\n",
      "\u001b[32m[07/08 13:02:39 d2.evaluation.evaluator]: \u001b[0mInference done 17/146. Dataloading: 0.0022 s/iter. Inference: 0.0711 s/iter. Eval: 1.7797 s/iter. Total: 1.8536 s/iter. ETA=0:03:59\n",
      "\u001b[32m[07/08 13:02:46 d2.evaluation.evaluator]: \u001b[0mInference done 21/146. Dataloading: 0.0026 s/iter. Inference: 0.0708 s/iter. Eval: 1.7508 s/iter. Total: 1.8249 s/iter. ETA=0:03:48\n",
      "\u001b[32m[07/08 13:02:52 d2.evaluation.evaluator]: \u001b[0mInference done 24/146. Dataloading: 0.0026 s/iter. Inference: 0.0709 s/iter. Eval: 1.7618 s/iter. Total: 1.8360 s/iter. ETA=0:03:43\n",
      "\u001b[32m[07/08 13:02:57 d2.evaluation.evaluator]: \u001b[0mInference done 27/146. Dataloading: 0.0026 s/iter. Inference: 0.0708 s/iter. Eval: 1.7505 s/iter. Total: 1.8245 s/iter. ETA=0:03:37\n",
      "\u001b[32m[07/08 13:03:02 d2.evaluation.evaluator]: \u001b[0mInference done 30/146. Dataloading: 0.0025 s/iter. Inference: 0.0708 s/iter. Eval: 1.7423 s/iter. Total: 1.8163 s/iter. ETA=0:03:30\n",
      "\u001b[32m[07/08 13:03:09 d2.evaluation.evaluator]: \u001b[0mInference done 33/146. Dataloading: 0.0025 s/iter. Inference: 0.0713 s/iter. Eval: 1.7823 s/iter. Total: 1.8567 s/iter. ETA=0:03:29\n",
      "\u001b[32m[07/08 13:03:14 d2.evaluation.evaluator]: \u001b[0mInference done 37/146. Dataloading: 0.0024 s/iter. Inference: 0.0704 s/iter. Eval: 1.7218 s/iter. Total: 1.7953 s/iter. ETA=0:03:15\n",
      "\u001b[32m[07/08 13:03:21 d2.evaluation.evaluator]: \u001b[0mInference done 39/146. Dataloading: 0.0024 s/iter. Inference: 0.0712 s/iter. Eval: 1.7934 s/iter. Total: 1.8677 s/iter. ETA=0:03:19\n",
      "\u001b[32m[07/08 13:03:27 d2.evaluation.evaluator]: \u001b[0mInference done 42/146. Dataloading: 0.0026 s/iter. Inference: 0.0713 s/iter. Eval: 1.8154 s/iter. Total: 1.8900 s/iter. ETA=0:03:16\n",
      "\u001b[32m[07/08 13:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 44/146. Dataloading: 0.0026 s/iter. Inference: 0.0718 s/iter. Eval: 1.8628 s/iter. Total: 1.9378 s/iter. ETA=0:03:17\n",
      "\u001b[32m[07/08 13:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 47/146. Dataloading: 0.0026 s/iter. Inference: 0.0715 s/iter. Eval: 1.8494 s/iter. Total: 1.9243 s/iter. ETA=0:03:10\n",
      "\u001b[32m[07/08 13:03:44 d2.evaluation.evaluator]: \u001b[0mInference done 50/146. Dataloading: 0.0026 s/iter. Inference: 0.0716 s/iter. Eval: 1.8505 s/iter. Total: 1.9255 s/iter. ETA=0:03:04\n",
      "\u001b[32m[07/08 13:03:50 d2.evaluation.evaluator]: \u001b[0mInference done 53/146. Dataloading: 0.0027 s/iter. Inference: 0.0717 s/iter. Eval: 1.8522 s/iter. Total: 1.9273 s/iter. ETA=0:02:59\n",
      "\u001b[32m[07/08 13:03:56 d2.evaluation.evaluator]: \u001b[0mInference done 56/146. Dataloading: 0.0027 s/iter. Inference: 0.0719 s/iter. Eval: 1.8721 s/iter. Total: 1.9474 s/iter. ETA=0:02:55\n",
      "\u001b[32m[07/08 13:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 58/146. Dataloading: 0.0026 s/iter. Inference: 0.0725 s/iter. Eval: 1.9200 s/iter. Total: 1.9958 s/iter. ETA=0:02:55\n",
      "\u001b[32m[07/08 13:04:11 d2.evaluation.evaluator]: \u001b[0mInference done 62/146. Dataloading: 0.0026 s/iter. Inference: 0.0726 s/iter. Eval: 1.9162 s/iter. Total: 1.9922 s/iter. ETA=0:02:47\n",
      "\u001b[32m[07/08 13:04:16 d2.evaluation.evaluator]: \u001b[0mInference done 65/146. Dataloading: 0.0026 s/iter. Inference: 0.0725 s/iter. Eval: 1.9062 s/iter. Total: 1.9821 s/iter. ETA=0:02:40\n",
      "\u001b[32m[07/08 13:04:21 d2.evaluation.evaluator]: \u001b[0mInference done 69/146. Dataloading: 0.0026 s/iter. Inference: 0.0720 s/iter. Eval: 1.8679 s/iter. Total: 1.9433 s/iter. ETA=0:02:29\n",
      "\u001b[32m[07/08 13:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 72/146. Dataloading: 0.0026 s/iter. Inference: 0.0720 s/iter. Eval: 1.8688 s/iter. Total: 1.9441 s/iter. ETA=0:02:23\n",
      "\u001b[32m[07/08 13:04:33 d2.evaluation.evaluator]: \u001b[0mInference done 74/146. Dataloading: 0.0026 s/iter. Inference: 0.0722 s/iter. Eval: 1.8883 s/iter. Total: 1.9638 s/iter. ETA=0:02:21\n",
      "\u001b[32m[07/08 13:04:38 d2.evaluation.evaluator]: \u001b[0mInference done 76/146. Dataloading: 0.0026 s/iter. Inference: 0.0724 s/iter. Eval: 1.9076 s/iter. Total: 1.9834 s/iter. ETA=0:02:18\n",
      "\u001b[32m[07/08 13:04:43 d2.evaluation.evaluator]: \u001b[0mInference done 79/146. Dataloading: 0.0025 s/iter. Inference: 0.0723 s/iter. Eval: 1.8985 s/iter. Total: 1.9741 s/iter. ETA=0:02:12\n",
      "\u001b[32m[07/08 13:04:49 d2.evaluation.evaluator]: \u001b[0mInference done 83/146. Dataloading: 0.0025 s/iter. Inference: 0.0721 s/iter. Eval: 1.8702 s/iter. Total: 1.9455 s/iter. ETA=0:02:02\n",
      "\u001b[32m[07/08 13:04:54 d2.evaluation.evaluator]: \u001b[0mInference done 86/146. Dataloading: 0.0025 s/iter. Inference: 0.0721 s/iter. Eval: 1.8652 s/iter. Total: 1.9405 s/iter. ETA=0:01:56\n",
      "\u001b[32m[07/08 13:05:01 d2.evaluation.evaluator]: \u001b[0mInference done 89/146. Dataloading: 0.0024 s/iter. Inference: 0.0722 s/iter. Eval: 1.8731 s/iter. Total: 1.9484 s/iter. ETA=0:01:51\n",
      "\u001b[32m[07/08 13:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 92/146. Dataloading: 0.0024 s/iter. Inference: 0.0722 s/iter. Eval: 1.8844 s/iter. Total: 1.9597 s/iter. ETA=0:01:45\n",
      "\u001b[32m[07/08 13:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 96/146. Dataloading: 0.0024 s/iter. Inference: 0.0721 s/iter. Eval: 1.8672 s/iter. Total: 1.9424 s/iter. ETA=0:01:37\n",
      "\u001b[32m[07/08 13:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 99/146. Dataloading: 0.0024 s/iter. Inference: 0.0721 s/iter. Eval: 1.8665 s/iter. Total: 1.9416 s/iter. ETA=0:01:31\n",
      "\u001b[32m[07/08 13:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 102/146. Dataloading: 0.0023 s/iter. Inference: 0.0721 s/iter. Eval: 1.8644 s/iter. Total: 1.9395 s/iter. ETA=0:01:25\n",
      "\u001b[32m[07/08 13:05:33 d2.evaluation.evaluator]: \u001b[0mInference done 106/146. Dataloading: 0.0023 s/iter. Inference: 0.0720 s/iter. Eval: 1.8624 s/iter. Total: 1.9374 s/iter. ETA=0:01:17\n",
      "\u001b[32m[07/08 13:05:38 d2.evaluation.evaluator]: \u001b[0mInference done 109/146. Dataloading: 0.0023 s/iter. Inference: 0.0721 s/iter. Eval: 1.8605 s/iter. Total: 1.9356 s/iter. ETA=0:01:11\n",
      "\u001b[32m[07/08 13:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 111/146. Dataloading: 0.0023 s/iter. Inference: 0.0723 s/iter. Eval: 1.8728 s/iter. Total: 1.9481 s/iter. ETA=0:01:08\n",
      "\u001b[32m[07/08 13:05:49 d2.evaluation.evaluator]: \u001b[0mInference done 115/146. Dataloading: 0.0023 s/iter. Inference: 0.0722 s/iter. Eval: 1.8555 s/iter. Total: 1.9307 s/iter. ETA=0:00:59\n",
      "\u001b[32m[07/08 13:05:55 d2.evaluation.evaluator]: \u001b[0mInference done 125/146. Dataloading: 0.0022 s/iter. Inference: 0.0719 s/iter. Eval: 1.7387 s/iter. Total: 1.8135 s/iter. ETA=0:00:38\n",
      "\u001b[32m[07/08 13:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 137/146. Dataloading: 0.0021 s/iter. Inference: 0.0713 s/iter. Eval: 1.6155 s/iter. Total: 1.6895 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/08 13:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 144/146. Dataloading: 0.0021 s/iter. Inference: 0.0716 s/iter. Eval: 1.5688 s/iter. Total: 1.6431 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/08 13:06:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:49.599913 (1.628368 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 13:06:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.071563 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/08 13:06:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/08 13:06:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to TomatoMAP/TomatoMAP-Seg/output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/08 13:06:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "\n",
      " error occurs:\n",
      "   error info: 'info'\n",
      "\n",
      " training failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45811/539403763.py\", line 20, in train_model\n",
      "    trainer.train()\n",
      "  File \"/tmp/ipykernel_45811/3081507412.py\", line 177, in train\n",
      "    super().train()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/engine/defaults.py\", line 520, in train\n",
      "    super().train(self.start_iter, self.max_iter)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/engine/train_loop.py\", line 165, in train\n",
      "    self.after_train()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/engine/train_loop.py\", line 174, in after_train\n",
      "    h.after_train()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/engine/hooks.py\", line 561, in after_train\n",
      "    self._do_eval()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/engine/hooks.py\", line 529, in _do_eval\n",
      "    results = self._func()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/engine/defaults.py\", line 489, in test_and_save_results\n",
      "    self._last_eval_results = self.test(self.cfg, self.model)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/engine/defaults.py\", line 653, in test\n",
      "    results_i = inference_on_dataset(model, data_loader, evaluator)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py\", line 215, in inference_on_dataset\n",
      "    results = evaluator.evaluate()\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 206, in evaluate\n",
      "    self._eval_predictions(predictions, img_ids=img_ids)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 266, in _eval_predictions\n",
      "    _evaluate_predictions_on_coco(\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/detectron2/evaluation/coco_evaluation.py\", line 590, in _evaluate_predictions_on_coco\n",
      "    coco_dt = coco_gt.loadRes(coco_results)\n",
      "  File \"/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/pycocotools/coco.py\", line 314, in loadRes\n",
      "    res.dataset['info'] = copy.deepcopy(self.dataset['info'])\n",
      "KeyError: 'info'\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    print(\"Training TomatoMAP-Seg\")\n",
    "    \n",
    "    trainer = MyTrainer(cfg, patience=TRAINING_CONFIG['patience'])\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    \n",
    "    print(f\"\\n training configuration:\")\n",
    "    print(f\"  model: {TRAINING_CONFIG['model_name']}\")\n",
    "    print(f\"  max epoch: {TRAINING_CONFIG['max_epochs']}\")\n",
    "    print(f\"  patience: {TRAINING_CONFIG['patience']} epochs\")\n",
    "    print(f\"  eval period: per {TRAINING_CONFIG['eval_period']} epochs\")\n",
    "    print(f\"  save check point: per {TRAINING_CONFIG['checkpoint_period']} epochs\")\n",
    "    print(f\"  multi scale training: {TRAINING_CONFIG['input_min_size_train'][0]}-{TRAINING_CONFIG['input_max_size_train']}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"training start\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        trainer.train()\n",
    "        \n",
    "        print(\"\\n training finished\")\n",
    "        \n",
    "        config_path = os.path.join(cfg.OUTPUT_DIR, \"config.yaml\")\n",
    "        with open(config_path, \"w\") as f:\n",
    "            f.write(cfg.dump())\n",
    "        print(f\"config saved: {config_path}\")\n",
    "        \n",
    "        return trainer, cfg\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n training interrupted\")\n",
    "        return None, cfg\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n error occurs:\")\n",
    "        print(f\"   error info: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, cfg\n",
    "\n",
    "if 'class_labels' in locals() and class_labels is not None and conversion_success:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ready to start training\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    trainer, cfg = train_model()\n",
    "    \n",
    "    if trainer is not None:\n",
    "        print(\"\\n training finished\")\n",
    "        \n",
    "        print(f\"\\n output path:\")\n",
    "        output_dir = Path(cfg.OUTPUT_DIR)\n",
    "        if output_dir.exists():\n",
    "            for file in output_dir.iterdir():\n",
    "                if file.is_file():\n",
    "                    print(f\"  📄 {file.name}\")\n",
    "    else:\n",
    "        print(\"\\n training failed\")\n",
    "else:\n",
    "    print(\"can't start training, please check data structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be5227b6-3e5a-4f40-8192-9a9148fe2aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_path=\"model_best.pth\", dataset_name=\"tomato_test\"):\n",
    "    print(f\"evaluating {dataset_name} ...\")\n",
    "    \n",
    "    eval_cfg = build_cfg()\n",
    "    \n",
    "    full_model_path = os.path.join(eval_cfg.OUTPUT_DIR, model_path)\n",
    "    if not os.path.exists(full_model_path):\n",
    "        print(f\"model not exist: {full_model_path}\")\n",
    "\n",
    "        final_model_path = os.path.join(eval_cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "        if os.path.exists(final_model_path):\n",
    "            full_model_path = final_model_path\n",
    "            print(f\"using final model: {final_model_path}\")\n",
    "        else:\n",
    "            print(\"can't find any models\")\n",
    "            return None\n",
    "    \n",
    "    eval_cfg.MODEL.WEIGHTS = full_model_path\n",
    "    print(f\"load model: {full_model_path}\")\n",
    "    \n",
    "    try:\n",
    "        evaluator = COCOEvaluator(dataset_name, eval_cfg, False, output_dir=eval_cfg.OUTPUT_DIR)\n",
    "        test_loader = build_detection_test_loader(eval_cfg, dataset_name)\n",
    "        \n",
    "        model = MyTrainer.build_model(eval_cfg)\n",
    "        \n",
    "        print(\"start evaluating\")\n",
    "        results = inference_on_dataset(model, test_loader, evaluator)\n",
    "        \n",
    "        print(\"\\n evaluation result:\")\n",
    "        \n",
    "        if \"bbox\" in results:\n",
    "            print(\"\\n bbox result:\")\n",
    "            bbox_results = results[\"bbox\"]\n",
    "            for key in [\"AP\", \"AP50\", \"AP75\", \"APs\", \"APm\", \"APl\"]:\n",
    "                value = bbox_results.get(key, -1)\n",
    "                if value != -1:\n",
    "                    print(f\"  {key}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"  {key}: N/A\")\n",
    "        \n",
    "        if \"segm\" in results:\n",
    "            print(\"\\n segm result:\")\n",
    "            segm_results = results[\"segm\"]\n",
    "            for key in [\"AP\", \"AP50\", \"AP75\", \"APs\", \"APm\", \"APl\"]:\n",
    "                value = segm_results.get(key, -1)\n",
    "                if value != -1:\n",
    "                    print(f\"  {key}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"  {key}: N/A (no objects in this size)\")\n",
    "        \n",
    "        results_file = os.path.join(eval_cfg.OUTPUT_DIR, f\"eval_results_{dataset_name}.json\")\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        print(f\"\\n evaluation results saved at: {results_file}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"failed to evaluate: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "if 'trainer' in locals() and trainer is not None:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Model evaluation started\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    test_results = evaluate_model(\"model_best.pth\", \"tomato_test\")\n",
    "    \n",
    "    final_results = evaluate_model(\"model_final.pth\", \"tomato_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "008a2d8d-18f5-4200-bd84-a57d6f251d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved.\n"
     ]
    }
   ],
   "source": [
    "def visualize_predictions(dataset_name=\"tomato_test\", num_samples=5, model_path=\"model_best.pth\"):\n",
    "\n",
    "    print(f\"plotting {dataset_name} inference result\")\n",
    "    \n",
    "    vis_cfg = build_cfg()\n",
    "    full_model_path = os.path.join(vis_cfg.OUTPUT_DIR, model_path)\n",
    "    \n",
    "    if not os.path.exists(full_model_path):\n",
    "        print(f\"model not exist: {full_model_path}\")\n",
    "\n",
    "        final_model_path = os.path.join(vis_cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "        if os.path.exists(final_model_path):\n",
    "            full_model_path = final_model_path\n",
    "            print(f\"using final model: {final_model_path}\")\n",
    "        else:\n",
    "            print(\"no model file exist\")\n",
    "            return\n",
    "    \n",
    "    vis_cfg.MODEL.WEIGHTS = full_model_path\n",
    "    \n",
    "    predictor = DefaultPredictor(vis_cfg)\n",
    "    \n",
    "    try:\n",
    "        metadata = MetadataCatalog.get(dataset_name)\n",
    "    except:\n",
    "        print(f\" can't get {dataset_name} metadata\")\n",
    "        metadata = None\n",
    "    \n",
    "    img_dir = DATASET_CONFIG['img_dir']\n",
    "    if not os.path.exists(img_dir):\n",
    "        print(f\"image folder not eixst: {img_dir}\")\n",
    "        return\n",
    "    \n",
    "    img_list = [f for f in os.listdir(img_dir) \n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "    \n",
    "    if not img_list:\n",
    "        print(f\"can't find images in {img_dir}\")\n",
    "        return\n",
    "    \n",
    "    random.shuffle(img_list)\n",
    "    shown = 0\n",
    "    \n",
    "    print(f\"using {model_path} generating {num_samples} samples...\")\n",
    "    \n",
    "    for file in img_list:\n",
    "        try:\n",
    "            img_path = os.path.join(img_dir, file)\n",
    "            im = cv2.imread(img_path)\n",
    "            \n",
    "            if im is None:\n",
    "                print(f\"failed to load image: {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            outputs = predictor(im)\n",
    "            \n",
    "            v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=1.2)\n",
    "            v._default_font_size = 20\n",
    "            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "            \n",
    "            save_path = os.path.join(vis_cfg.OUTPUT_DIR, f\"prediction_{shown+1}_{file}\")\n",
    "            cv2.imwrite(save_path, out.get_image()[:, :, ::-1])\n",
    "            print(f\"  saved at: {save_path}\")\n",
    "            \n",
    "            shown += 1\n",
    "            if shown >= num_samples:\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"error when processing {file} : {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"Plotting finished!\")\n",
    "\n",
    "def plot_training_history():\n",
    "    history_file = os.path.join(cfg.OUTPUT_DIR, \"training_history.json\")\n",
    "    \n",
    "    if not os.path.exists(history_file):\n",
    "        print(f\"can't find training log: {history_file}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with open(history_file, 'r') as f:\n",
    "            history = json.load(f)\n",
    "        \n",
    "        if not history:\n",
    "            print(\"training log is empty\")\n",
    "            return\n",
    "        \n",
    "        epochs = [h['epoch'] for h in history]\n",
    "        scores = [h['score'] for h in history]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(epochs, scores, 'b-o', linewidth=2, markersize=6)\n",
    "        plt.title(f'training log - {history[0][\"metric\"]}', fontsize=14)\n",
    "        plt.xlabel('Epoch', fontsize=8)\n",
    "        plt.ylabel(f'{history[0][\"metric\"]}', fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        best_idx = scores.index(max(scores))\n",
    "        plt.annotate(f'best: {max(scores):.4f}', \n",
    "                    xy=(epochs[best_idx], scores[best_idx]),\n",
    "                    xytext=(10, 10), textcoords='offset points',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),\n",
    "                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        curve_path = os.path.join(cfg.OUTPUT_DIR, \"training_curve.png\")\n",
    "        plt.savefig(curve_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"training curve saved at: {curve_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"failed to plot training log: {e}\")\n",
    "\n",
    "if 'trainer' in locals() and trainer is not None:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"plotting start\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    visualize_predictions(\"tomato_test\", num_samples=3, model_path=\"model_best.pth\")\n",
    "    \n",
    "    plot_training_history()\n",
    "    \n",
    "    print(\"plotting finished\")\n",
    "\n",
    "print(\"Output saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6461689-1c02-4110-b91b-b731669c5109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
