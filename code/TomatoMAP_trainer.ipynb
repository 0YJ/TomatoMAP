{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727b72fb-b718-4ed3-8340-5376050147ed",
   "metadata": {},
   "source": [
    "# TomatoMAP-Cls Trainer"
   ]
  },
  {
   "cell_type": "code",
   "id": "fad99b1c-b47d-4386-bc62-433dda73b066",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T06:59:05.120408Z",
     "start_time": "2025-07-07T06:58:55.424375Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from PIL import ImageDraw, ImageFont\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# env checker\n",
    "print(\"check env:\")\n",
    "print(f\"  PyTorch version: {torch.__version__}\")\n",
    "print(f\"  CUDA version: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU ram: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "print(\"env check done\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check env:\n",
      "  PyTorch version: 2.3.0\n",
      "  CUDA version: True\n",
      "  GPU device: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "  GPU ram: 8.0 GB\n",
      "env check done\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "35beeeb4-ca9c-47b4-9893-7d2bf01a1894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T07:00:42.814782Z",
     "start_time": "2025-07-07T07:00:42.797777Z"
    }
   },
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"model saved at: {path}\")\n",
    "\n",
    "def load_model(model, path, device='cpu'):\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"model loaded from: {path}\")\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, path)\n",
    "\n",
    "def load_checkpoint(path, model, optimizer, device):\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"from epoch {start_epoch} re-training\")\n",
    "    return start_epoch\n",
    "\n",
    "def get_font(size=30, bold=False):\n",
    "    font_paths = [\n",
    "        \"C:/Windows/Fonts/arialbd.ttf\" if bold else \"C:/Windows/Fonts/arial.ttf\",\n",
    "        \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\" if bold else \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\",\n",
    "        \"/System/Library/Fonts/Supplemental/Arial Bold.ttf\" if bold else \"/System/Library/Fonts/Supplemental/Arial.ttf\",\n",
    "    ]\n",
    "    for path in font_paths:\n",
    "        try:\n",
    "            return ImageFont.truetype(path, size=size)\n",
    "        except:\n",
    "            continue\n",
    "    return ImageFont.load_default()\n",
    "\n",
    "def denormalize(img_tensor, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "    mean = torch.tensor(mean).view(3, 1, 1).to(img_tensor.device)\n",
    "    std = torch.tensor(std).view(3, 1, 1).to(img_tensor.device)\n",
    "    return torch.clamp(img_tensor * std + mean, 0, 1)\n",
    "\n",
    "print(\"functions defination done!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions defination done!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "6358a0a3-9b2d-4062-9d7f-55f2c1948918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T07:01:28.424113Z",
     "start_time": "2025-07-07T07:01:28.413604Z"
    }
   },
   "source": [
    "from torchvision import models\n",
    "from torchvision.models import (\n",
    "    MobileNet_V3_Large_Weights,\n",
    "    MobileNet_V3_Small_Weights,\n",
    "    MobileNet_V2_Weights,\n",
    "    ResNet18_Weights,\n",
    ")\n",
    "\n",
    "def get_model(name, num_classes, pretrained=True):\n",
    "    print(f\"build model: {name}, class number: {num_classes}\")\n",
    "    \n",
    "    if name == 'mobilenet_v3_large':\n",
    "        weights = MobileNet_V3_Large_Weights.DEFAULT if pretrained else None\n",
    "        model = models.mobilenet_v3_large(weights=weights)\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "    elif name == 'mobilenet_v3_small':\n",
    "        weights = MobileNet_V3_Small_Weights.DEFAULT if pretrained else None\n",
    "        model = models.mobilenet_v3_small(weights=weights)\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "    elif name == 'mobilenet_v2':\n",
    "        weights = MobileNet_V2_Weights.DEFAULT if pretrained else None\n",
    "        model = models.mobilenet_v2(weights=weights)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif name == 'resnet18':\n",
    "        weights = ResNet18_Weights.DEFAULT if pretrained else None\n",
    "        model = models.resnet18(weights=weights)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {name} not supported.\")\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"parameter info: Total{total_params:,}, Trainable{trainable_params:,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"model defination done!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model defination done!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "06eec09a-fea7-4cd8-8712-f3d9ed59bcbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T07:03:22.933578Z",
     "start_time": "2025-07-07T07:03:22.904573Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class BBCHDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_dir, split='train', transform=None):\n",
    "        self.data_dir = os.path.join(data_dir, split)\n",
    "        self.transform = transform\n",
    "        \n",
    "        if not os.path.exists(self.data_dir):\n",
    "            raise FileNotFoundError(f\"Directory not found: {self.data_dir}\")\n",
    "        \n",
    "        # get all classes\n",
    "        self.classes = sorted([d for d in os.listdir(self.data_dir)\n",
    "                              if os.path.isdir(os.path.join(self.data_dir, d))])\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        self.samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.samples.append((img_path, class_idx))\n",
    "        \n",
    "        print(f\"loading {split} dataset: {len(self.samples)} images, {len(self.classes)} classes\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"failed to load image: {img_path}, error: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def get_transforms(target_size=(640, 640)):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(target_size),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(target_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "def get_dataloaders(data_dir, batch_size=32, target_size=(640, 640), num_workers=4, include_test=False):\n",
    "    print(f\"building dataloader: {data_dir}\")\n",
    "    \n",
    "    train_transform, val_transform = get_transforms(target_size)\n",
    "    \n",
    "    train_dataset = BBCHDataset(data_dir, 'train', train_transform)\n",
    "    val_dataset = BBCHDataset(data_dir, 'val', val_transform)\n",
    "\n",
    "    import platform\n",
    "    if platform.system() == 'Windows':\n",
    "        num_workers = 0\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    test_loader = None\n",
    "    if include_test:\n",
    "        test_dir = os.path.join(data_dir, 'test')\n",
    "        if os.path.exists(test_dir):\n",
    "            test_dataset = BBCHDataset(data_dir, 'test', val_transform)\n",
    "            test_loader = DataLoader(\n",
    "                test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
    "            )\n",
    "        else:\n",
    "            print(\"test set not found, using val as test\")\n",
    "            test_loader = val_loader\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "print(f\"dataloader setup!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataloader setup!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "7a707cf3-f677-4963-bff3-043bdc24f791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T07:03:52.327730Z",
     "start_time": "2025-07-07T07:03:52.313731Z"
    }
   },
   "source": [
    "CLASSIFICATION_CONFIG = {\n",
    "    'data_dir': 'TomatoMAP-Cls',\n",
    "    'model_name': 'mobilenet_v3_large',  # 'mobilenet_v3_large', 'mobilenet_v3_small', 'mobilenet_v2', 'resnet18'\n",
    "    'num_classes': 50,\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 150,\n",
    "    'learning_rate': 1e-4,\n",
    "    'target_size': (640, 640),\n",
    "    'patience': 15,\n",
    "    'save_interval': 20\n",
    "}\n",
    "\n",
    "print(\"config:\")\n",
    "for key, value in CLASSIFICATION_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:\n",
      "  data_dir: TomatoMAP-Cls\n",
      "  model_name: mobilenet_v3_large\n",
      "  num_classes: 50\n",
      "  batch_size: 32\n",
      "  num_epochs: 150\n",
      "  learning_rate: 0.0001\n",
      "  target_size: (640, 640)\n",
      "  patience: 15\n",
      "  save_interval: 20\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3ce449-a5a7-47c5-a82c-bdcddf30b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PyTorchåˆ†ç±»è®­ç»ƒå‡½æ•°å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "def plot_training_curve(log_path, model_name):\n",
    "    \"\"\"ç»˜åˆ¶è®­ç»ƒæ›²çº¿\"\"\"\n",
    "    if not os.path.exists(log_path):\n",
    "        print(\"ğŸ“­ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæ—¥å¿—\")\n",
    "        return\n",
    "        \n",
    "    df = pd.read_csv(log_path)\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # æŸå¤±æ›²çº¿\n",
    "    ax1.plot(df['epoch'], df['train_loss'], 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)\n",
    "    ax1.plot(df['epoch'], df['val_loss'], 'r-', label='éªŒè¯æŸå¤±', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('è®­ç»ƒ/éªŒè¯æŸå¤±')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # å‡†ç¡®ç‡æ›²çº¿\n",
    "    ax2.plot(df['epoch'], df['train_accuracy'], 'g-', label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)\n",
    "    ax2.plot(df['epoch'], df['val_accuracy'], 'orange', label='éªŒè¯å‡†ç¡®ç‡', linewidth=2)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('è®­ç»ƒ/éªŒè¯å‡†ç¡®ç‡')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # å­¦ä¹ ç‡æ›²çº¿ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰\n",
    "    ax3.plot(df['epoch'], df['train_loss'], 'b-', alpha=0.7)\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Train Loss')\n",
    "    ax3.set_title('è®­ç»ƒæŸå¤±è¯¦ç»†')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # è¿‡æ‹Ÿåˆæ£€æµ‹\n",
    "    overfitting = df['train_accuracy'] - df['val_accuracy']\n",
    "    ax4.plot(df['epoch'], overfitting, 'purple', label='è¿‡æ‹Ÿåˆç¨‹åº¦', linewidth=2)\n",
    "    ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Train Acc - Val Acc')\n",
    "    ax4.set_title('è¿‡æ‹Ÿåˆæ£€æµ‹')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"checkpoints/{model_name}_detailed_curves.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: checkpoints/{model_name}_detailed_curves.png\")\n",
    "\n",
    "def evaluate_classification(model, dataloader, criterion, device):\n",
    "    \"\"\"è¯„ä¼°åˆ†ç±»æ¨¡å‹\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def train_classification(config):\n",
    "    \"\"\"PyTorchåˆ†ç±»è®­ç»ƒä¸»å‡½æ•°\"\"\"\n",
    "    print(\"ğŸš€ å¼€å§‹PyTorchåˆ†ç±»è®­ç»ƒ\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # è®¾å¤‡æ£€æŸ¥\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"ğŸ”¥ ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "    \n",
    "    try:\n",
    "        # æ•°æ®åŠ è½½å™¨\n",
    "        train_loader, val_loader, _ = get_dataloaders(\n",
    "            config['data_dir'], \n",
    "            config['batch_size'], \n",
    "            config['target_size']\n",
    "        )\n",
    "        \n",
    "        # è·å–ç±»åˆ«ä¿¡æ¯\n",
    "        num_classes = len(train_loader.dataset.classes)\n",
    "        class_names = train_loader.dataset.classes\n",
    "        config['num_classes'] = num_classes  # æ›´æ–°é…ç½®\n",
    "        \n",
    "        print(f\"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:\")\n",
    "        print(f\"  è®­ç»ƒæ‰¹æ¬¡: {len(train_loader)}\")\n",
    "        print(f\"  éªŒè¯æ‰¹æ¬¡: {len(val_loader)}\")\n",
    "        print(f\"  å®é™…ç±»åˆ«æ•°: {num_classes}\")\n",
    "        print(f\"  ç±»åˆ«åç§°: {class_names[:5]}...\")\n",
    "        \n",
    "        # åˆ›å»ºæ¨¡å‹\n",
    "        model = get_model(config['model_name'], num_classes).to(device)\n",
    "        \n",
    "        # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['num_epochs'])\n",
    "        \n",
    "        # åˆ›å»ºä¿å­˜ç›®å½•\n",
    "        os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "        log_path = f\"checkpoints/{config['model_name']}_train_log.csv\"\n",
    "        \n",
    "        if not os.path.exists(log_path):\n",
    "            with open(log_path, 'w') as f:\n",
    "                f.write(\"epoch,train_loss,train_accuracy,val_loss,val_accuracy\\\\n\")\n",
    "        \n",
    "        print(f\"ğŸ’¾ ä¿å­˜è®¾ç½®:\")\n",
    "        print(f\"  æ£€æŸ¥ç‚¹ç›®å½•: checkpoints/\")\n",
    "        print(f\"  è®­ç»ƒæ—¥å¿—: {log_path}\")\n",
    "        \n",
    "        # è®­ç»ƒå¾ªç¯\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(config['num_epochs']):\n",
    "            # è®­ç»ƒé˜¶æ®µ\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            print(f\"\\\\nğŸ“… Epoch {epoch+1}/{config['num_epochs']}\")\n",
    "            \n",
    "            progress_bar = tqdm(train_loader, desc=f\"è®­ç»ƒEpoch {epoch+1}\")\n",
    "            for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                # æ›´æ–°è¿›åº¦æ¡\n",
    "                current_acc = correct / total\n",
    "                progress_bar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Acc': f'{current_acc:.4f}'\n",
    "                })\n",
    "                \n",
    "                # å®šæœŸæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯\n",
    "                if (batch_idx + 1) % 50 == 0:\n",
    "                    print(f\"    Batch {batch_idx+1}/{len(train_loader)} - Loss: {loss.item():.4f}, Acc: {current_acc:.4f}\")\n",
    "            \n",
    "            # è®¡ç®—è®­ç»ƒæŒ‡æ ‡\n",
    "            train_loss = running_loss / len(train_loader)\n",
    "            train_acc = correct / total\n",
    "            \n",
    "            # éªŒè¯é˜¶æ®µ\n",
    "            val_loss, val_acc = evaluate_classification(model, val_loader, criterion, device)\n",
    "            \n",
    "            # å­¦ä¹ ç‡è°ƒåº¦\n",
    "            scheduler.step()\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            \n",
    "            print(f\"ğŸ“Š Epoch {epoch+1} ç»“æœ:\")\n",
    "            print(f\"  è®­ç»ƒ: Loss={train_loss:.4f}, Acc={train_acc:.4f}\")\n",
    "            print(f\"  éªŒè¯: Loss={val_loss:.4f}, Acc={val_acc:.4f}\")\n",
    "            print(f\"  å­¦ä¹ ç‡: {current_lr:.6f}\")\n",
    "            \n",
    "            # è®°å½•è®­ç»ƒæ—¥å¿—\n",
    "            with open(log_path, 'a') as f:\n",
    "                f.write(f\"{epoch+1},{train_loss:.4f},{train_acc:.4f},{val_loss:.4f},{val_acc:.4f}\\\\n\")\n",
    "            \n",
    "            # ä¿å­˜æ£€æŸ¥ç‚¹\n",
    "            save_checkpoint(model, optimizer, epoch, \"checkpoints/last_checkpoint.pth\")\n",
    "            \n",
    "            # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                save_model(model, f\"checkpoints/{config['model_name']}_best.pth\")\n",
    "                print(\"ğŸŒŸ ä¿å­˜æœ€ä½³æ¨¡å‹!\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"â° æ—©åœè®¡æ•°: {patience_counter}/{config['patience']}\")\n",
    "            \n",
    "            # å®šæœŸä¿å­˜\n",
    "            if (epoch + 1) % config['save_interval'] == 0:\n",
    "                save_checkpoint(model, optimizer, epoch, \n",
    "                              f\"checkpoints/{config['model_name']}_epoch{epoch+1}.pth\")\n",
    "                print(f\"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: epoch{epoch+1}\")\n",
    "            \n",
    "            # æ£€æŸ¥æ—©åœ\n",
    "            if patience_counter >= config['patience']:\n",
    "                print(\"ğŸ›‘ è§¦å‘æ—©åœ!\")\n",
    "                break\n",
    "        \n",
    "        # ä¿å­˜æœ€ç»ˆæ¨¡å‹\n",
    "        save_model(model, f\"{config['model_name']}_final.pth\")\n",
    "        \n",
    "        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
    "        plot_training_curve(log_path, config['model_name'])\n",
    "        \n",
    "        print(f\"\\\\nğŸ‰ è®­ç»ƒå®Œæˆ!\")\n",
    "        print(f\"ğŸ“ æœ€ä½³æ¨¡å‹: checkpoints/{config['model_name']}_best.pth\")\n",
    "        print(f\"ğŸ“ æœ€ç»ˆæ¨¡å‹: {config['model_name']}_final.pth\")\n",
    "        \n",
    "        return model, train_loader, val_loader\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è®­ç»ƒå¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None\n",
    "\n",
    "print(\"âœ… PyTorchåˆ†ç±»è®­ç»ƒå‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f7cc2e7-1ee6-4c22-9d25-ef8911af5dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¯ TomatoMAP åˆ†ç±»æ¨¡å‹è®­ç»ƒ\n",
      "============================================================\n",
      "âœ… æ•°æ®ç›®å½•å­˜åœ¨: TomatoMAP-Cls\n",
      "âœ… è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•ç›®å½•éƒ½å­˜åœ¨\n",
      "\n",
      "âš™ï¸ è®­ç»ƒé…ç½®:\n",
      "   data_dir: TomatoMAP-Cls\n",
      "   model_name: mobilenet_v3_large\n",
      "   num_classes: 50\n",
      "   batch_size: 32\n",
      "   num_epochs: 150\n",
      "   learning_rate: 0.0001\n",
      "   target_size: (640, 640)\n",
      "   patience: 15\n",
      "   save_interval: 20\n",
      "\n",
      "ğŸš€ å¼€å§‹è®­ç»ƒ...\n",
      "ğŸ”§ ä½¿ç”¨è®¾å¤‡: cpu\n",
      "ğŸ”§ åˆ›å»ºæ•°æ®åŠ è½½å™¨: TomatoMAP-Cls\n",
      "ğŸ“Š åŠ è½½ train æ•°æ®é›†: 45099 å¼ å›¾ç‰‡, 50 ä¸ªç±»åˆ«\n",
      "ğŸ“Š åŠ è½½ val æ•°æ®é›†: 12870 å¼ å›¾ç‰‡, 50 ä¸ªç±»åˆ«\n",
      "ğŸ“Š åŠ è½½ test æ•°æ®é›†: 6495 å¼ å›¾ç‰‡, 50 ä¸ªç±»åˆ«\n",
      "âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ\n",
      "ğŸ¤– åˆ›å»ºæ¨¡å‹: mobilenet_v3_large, ç±»åˆ«æ•°: 50\n",
      "ğŸ“Š å‚æ•°ç»Ÿè®¡: æ€»æ•°4,266,082, å¯è®­ç»ƒ4,266,082\n",
      "ğŸš€ å¼€å§‹è®­ç»ƒ 150 ä¸ªepoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [è®­ç»ƒ]:   0%|â–                                                                                                                            | 2/1410 [00:21<4:10:10, 10.66s/it, Loss=3.9196, Acc=4.69%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­\n"
     ]
    }
   ],
   "source": [
    "# å®Œæ•´çš„è®­ç»ƒå¾ªç¯\n",
    "def train_model(config):\n",
    "    \"\"\"å®Œæ•´çš„åˆ†ç±»æ¨¡å‹è®­ç»ƒå‡½æ•°\"\"\"\n",
    "    \n",
    "    # è®¾ç½®è®¾å¤‡\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "    \n",
    "    # åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "    output_dir = Path(f\"runs/{config['model_name']}_cls\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # è·å–æ•°æ®åŠ è½½å™¨ï¼ˆåŒ…å«testé›†ï¼‰\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(\n",
    "        config['data_dir'], \n",
    "        batch_size=config['batch_size'],\n",
    "        target_size=config['target_size'],\n",
    "        num_workers=4,\n",
    "        include_test=True\n",
    "    )\n",
    "    \n",
    "    # åˆ›å»ºæ¨¡å‹\n",
    "    model = get_model(config['model_name'], config['num_classes'], pretrained=True)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=0.01)\n",
    "    \n",
    "    # å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    \n",
    "    # è®­ç»ƒå†å²è®°å½•\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # æ—©åœå‚æ•°\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(f\"ğŸš€ å¼€å§‹è®­ç»ƒ {config['num_epochs']} ä¸ªepoch...\")\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        # è®­ç»ƒé˜¶æ®µ\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [è®­ç»ƒ]\")\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_pbar):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # å‰å‘ä¼ æ’­\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # åå‘ä¼ æ’­\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # ç»Ÿè®¡\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # æ›´æ–°è¿›åº¦æ¡\n",
    "            current_acc = 100 * train_correct / train_total\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{current_acc:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # éªŒè¯é˜¶æ®µ\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [éªŒè¯]\")\n",
    "            \n",
    "            for images, labels in val_pbar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                current_acc = 100 * val_correct / val_total\n",
    "                val_pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Acc': f'{current_acc:.2f}%'\n",
    "                })\n",
    "        \n",
    "        # è®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        # è®°å½•å†å²\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        # æ›´æ–°å­¦ä¹ ç‡\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # æ‰“å°epochç»“æœ\n",
    "        print(f\"\\nğŸ“Š Epoch {epoch+1}/{config['num_epochs']}:\")\n",
    "        print(f\"  è®­ç»ƒ - Loss: {avg_train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  éªŒè¯ - Loss: {avg_val_loss:.4f}, Acc: {val_acc:.2f}%\")\n",
    "        print(f\"  å­¦ä¹ ç‡: {current_lr:.2e}\")\n",
    "        \n",
    "        # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_path = output_dir / f\"best_{config['model_name']}.pth\"\n",
    "            save_model(model, best_model_path)\n",
    "            patience_counter = 0\n",
    "            print(f\"  â­ æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  â³ éªŒè¯å‡†ç¡®ç‡æœªæå‡ ({patience_counter}/{config['patience']})\")\n",
    "        \n",
    "        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹\n",
    "        if (epoch + 1) % config['save_interval'] == 0:\n",
    "            checkpoint_path = output_dir / f\"checkpoint_epoch_{epoch+1}.pth\"\n",
    "            save_checkpoint(model, optimizer, epoch, checkpoint_path)\n",
    "        \n",
    "        # æ—©åœæ£€æŸ¥\n",
    "        if patience_counter >= config['patience']:\n",
    "            print(f\"\\nğŸ›‘ æ—©åœè§¦å‘! éªŒè¯å‡†ç¡®ç‡è¿ç»­ {config['patience']} ä¸ªepochæœªæå‡\")\n",
    "            break\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # è®­ç»ƒå®Œæˆï¼Œä¿å­˜æœ€ç»ˆæ¨¡å‹\n",
    "    final_model_path = output_dir / f\"final_{config['model_name']}.pth\"\n",
    "    save_model(model, final_model_path)\n",
    "    \n",
    "    print(f\"\\nğŸ‰ è®­ç»ƒå®Œæˆ!\")\n",
    "    print(f\"  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\n",
    "    print(f\"  æ¨¡å‹ä¿å­˜è·¯å¾„: {output_dir}\")\n",
    "    \n",
    "    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # æŸå¤±æ›²çº¿\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_losses, label='è®­ç»ƒæŸå¤±', color='blue')\n",
    "    plt.plot(val_losses, label='éªŒè¯æŸå¤±', color='red')\n",
    "    plt.title('è®­ç»ƒæŸå¤±æ›²çº¿')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # å‡†ç¡®ç‡æ›²çº¿\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(train_accuracies, label='è®­ç»ƒå‡†ç¡®ç‡', color='blue')\n",
    "    plt.plot(val_accuracies, label='éªŒè¯å‡†ç¡®ç‡', color='red')\n",
    "    plt.title('è®­ç»ƒå‡†ç¡®ç‡æ›²çº¿')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # å­¦ä¹ ç‡æ›²çº¿\n",
    "    plt.subplot(1, 3, 3)\n",
    "    lrs = []\n",
    "    for i in range(len(train_losses)):\n",
    "        if i < 30:\n",
    "            lrs.append(config['learning_rate'])\n",
    "        elif i < 60:\n",
    "            lrs.append(config['learning_rate'] * 0.1)\n",
    "        else:\n",
    "            lrs.append(config['learning_rate'] * 0.01)\n",
    "    plt.plot(lrs, label='å­¦ä¹ ç‡', color='green')\n",
    "    plt.title('å­¦ä¹ ç‡å˜åŒ–')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'training_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # ä¿å­˜è®­ç»ƒå†å²\n",
    "    history_df = pd.DataFrame({\n",
    "        'epoch': range(1, len(train_losses) + 1),\n",
    "        'train_loss': train_losses,\n",
    "        'val_loss': val_losses,\n",
    "        'train_acc': train_accuracies,\n",
    "        'val_acc': val_accuracies\n",
    "    })\n",
    "    history_df.to_csv(output_dir / 'training_history.csv', index=False)\n",
    "    print(f\"ğŸ“ˆ è®­ç»ƒå†å²å·²ä¿å­˜: {output_dir / 'training_history.csv'}\")\n",
    "    \n",
    "    return model, best_val_acc, output_dir, test_loader\n",
    "\n",
    "\n",
    "# ğŸš€ å¼€å§‹æ‰§è¡Œè®­ç»ƒ\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¯ TomatoMAP åˆ†ç±»æ¨¡å‹è®­ç»ƒ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# é¦–å…ˆæ£€æŸ¥æ•°æ®ç›®å½•\n",
    "if not os.path.exists(CLASSIFICATION_CONFIG['data_dir']):\n",
    "    print(f\"âŒ é”™è¯¯: æ•°æ®ç›®å½•ä¸å­˜åœ¨\")\n",
    "    print(f\"   è·¯å¾„: {CLASSIFICATION_CONFIG['data_dir']}\")\n",
    "    print(f\"   è¯·ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨å¹¶åŒ…å« train/ å’Œ val/ å­ç›®å½•\")\n",
    "else:\n",
    "    print(f\"âœ… æ•°æ®ç›®å½•å­˜åœ¨: {CLASSIFICATION_CONFIG['data_dir']}\")\n",
    "    \n",
    "    # æ£€æŸ¥trainã€valå’Œtestç›®å½•\n",
    "    train_dir = os.path.join(CLASSIFICATION_CONFIG['data_dir'], 'train')\n",
    "    val_dir = os.path.join(CLASSIFICATION_CONFIG['data_dir'], 'val')\n",
    "    test_dir = os.path.join(CLASSIFICATION_CONFIG['data_dir'], 'test')\n",
    "    \n",
    "    if not os.path.exists(train_dir):\n",
    "        print(f\"âŒ é”™è¯¯: è®­ç»ƒç›®å½•ä¸å­˜åœ¨: {train_dir}\")\n",
    "    elif not os.path.exists(val_dir):\n",
    "        print(f\"âŒ é”™è¯¯: éªŒè¯ç›®å½•ä¸å­˜åœ¨: {val_dir}\")\n",
    "    elif not os.path.exists(test_dir):\n",
    "        print(f\"âš ï¸ è­¦å‘Š: æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {test_dir}\")\n",
    "        print(f\"   å°†ä½¿ç”¨éªŒè¯é›†ä½œä¸ºæµ‹è¯•é›†\")\n",
    "    else:\n",
    "        print(f\"âœ… è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•ç›®å½•éƒ½å­˜åœ¨\")\n",
    "        \n",
    "        # æ˜¾ç¤ºè®­ç»ƒé…ç½®\n",
    "        print(\"\\nâš™ï¸ è®­ç»ƒé…ç½®:\")\n",
    "        for key, value in CLASSIFICATION_CONFIG.items():\n",
    "            print(f\"   {key}: {value}\")\n",
    "        \n",
    "        print(\"\\nğŸš€ å¼€å§‹è®­ç»ƒ...\")\n",
    "        \n",
    "        try:\n",
    "            # æ‰§è¡Œè®­ç»ƒ\n",
    "            model, best_acc, output_dir, test_loader = train_model(CLASSIFICATION_CONFIG)\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆ!\")\n",
    "            print(f\"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.2f}%\")\n",
    "            print(f\"   æ¨¡å‹ä¿å­˜ç›®å½•: {output_dir}\")\n",
    "            \n",
    "            # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°\n",
    "            print(\"\\nğŸ§ª åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹...\")\n",
    "            model.eval()\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "            test_predictions = []\n",
    "            test_labels = []\n",
    "            \n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                test_pbar = tqdm(test_loader, desc=\"æµ‹è¯•é›†è¯„ä¼°\")\n",
    "                for images, labels in test_pbar:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    \n",
    "                    test_total += labels.size(0)\n",
    "                    test_correct += (predicted == labels).sum().item()\n",
    "                    \n",
    "                    # æ”¶é›†é¢„æµ‹ç»“æœç”¨äºæ··æ·†çŸ©é˜µ\n",
    "                    test_predictions.extend(predicted.cpu().numpy())\n",
    "                    test_labels.extend(labels.cpu().numpy())\n",
    "                    \n",
    "                    current_acc = 100 * test_correct / test_total\n",
    "                    test_pbar.set_postfix({'Acc': f'{current_acc:.2f}%'})\n",
    "            \n",
    "            test_accuracy = 100 * test_correct / test_total\n",
    "            print(f\"ğŸ¯ æµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy:.2f}%\")\n",
    "            \n",
    "            # ç»˜åˆ¶æ··æ·†çŸ©é˜µ\n",
    "            print(\"\\nğŸ“Š ç”Ÿæˆæ··æ·†çŸ©é˜µ...\")\n",
    "            \n",
    "            # è·å–ç±»åˆ«åç§°\n",
    "            train_dataset = test_loader.dataset\n",
    "            class_names = train_dataset.classes\n",
    "            \n",
    "            # è®¡ç®—æ··æ·†çŸ©é˜µ\n",
    "            cm = confusion_matrix(test_labels, test_predictions)\n",
    "            \n",
    "            # ç»˜åˆ¶æ··æ·†çŸ©é˜µ\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "            disp.plot(cmap='Blues', values_format='d')\n",
    "            plt.title(f'æ··æ·†çŸ©é˜µ (æµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy:.2f}%)', fontsize=16)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.yticks(rotation=0)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_dir / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # ä¿å­˜æµ‹è¯•ç»“æœ\n",
    "            test_results = {\n",
    "                'test_accuracy': test_accuracy,\n",
    "                'total_samples': test_total,\n",
    "                'correct_predictions': test_correct,\n",
    "                'num_classes': len(class_names),\n",
    "                'class_names': class_names\n",
    "            }\n",
    "            \n",
    "            import json\n",
    "            with open(output_dir / 'test_results.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(test_results, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"ğŸ“ˆ å®Œæ•´è¯„ä¼°ç»“æœ:\")\n",
    "            print(f\"   éªŒè¯é›†æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%\")\n",
    "            print(f\"   æµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy:.2f}%\")\n",
    "            print(f\"   ç±»åˆ«æ•°é‡: {len(class_names)}\")\n",
    "            print(f\"   æµ‹è¯•æ ·æœ¬æ•°: {test_total}\")\n",
    "            print(f\"   ç»“æœä¿å­˜è·¯å¾„: {output_dir}\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nâ¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:\")\n",
    "            print(f\"   é”™è¯¯ä¿¡æ¯: {str(e)}\")\n",
    "            print(\"\\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:\")\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c9228d-dc78-42af-8b78-7a41685f25b5",
   "metadata": {},
   "source": [
    "# TomatoMAP-Seg Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e455442e-145e-431b-9193-0f3a1c62f348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ç¯å¢ƒæ£€æŸ¥:\n",
      "  PyTorchç‰ˆæœ¬: 2.3.0+cu121\n",
      "  CUDAå¯ç”¨: False\n",
      "  Detectron2ç‰ˆæœ¬: 0.6\n",
      "âœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/py310/lib/python3.10/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "# Detectron2ç›¸å…³å¯¼å…¥\n",
    "import detectron2\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data.datasets.coco import load_coco_json\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "# è®¾ç½®æ—¥å¿—\n",
    "setup_logger()\n",
    "\n",
    "print(\"ğŸ”§ ç¯å¢ƒæ£€æŸ¥:\")\n",
    "print(f\"  PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"  CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "print(f\"  Detectron2ç‰ˆæœ¬: {detectron2.__version__}\")\n",
    "print(\"âœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4df010-b134-4435-9017-27871d82dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ è¯­ä¹‰å®ä¾‹åˆ†å‰²é…ç½®:\n",
      "ğŸ“ æ•°æ®é›†é…ç½®:\n",
      "  dataset_root: ./\n",
      "  img_dir: images\n",
      "  coco_ann_dir: labels\n",
      "  isat_yaml_path: isat.yaml\n",
      "  output_dir: ./output\n",
      "  num_classes: 10\n",
      "\n",
      "ğŸ¯ è®­ç»ƒé…ç½®:\n",
      "  model_name: mask_rcnn_R_50_FPN_3x\n",
      "  batch_size: 2\n",
      "  base_lr: 0.00025\n",
      "  max_iter: 1000\n",
      "  num_workers: 0\n",
      "  score_thresh_test: 0.5\n",
      "  input_min_size_test: 800\n",
      "  input_max_size_test: 1333\n"
     ]
    }
   ],
   "source": [
    "# æ•°æ®é›†é…ç½®\n",
    "DATASET_CONFIG = {\n",
    "    'dataset_root': \"./\",\n",
    "    'img_dir': \"images\",  # å›¾åƒç›®å½•\n",
    "    'coco_ann_dir': \"labels\",  # COCOæ ¼å¼æ ‡æ³¨ç›®å½•\n",
    "    'isat_yaml_path': \"isat.yaml\",  # ISATé…ç½®æ–‡ä»¶\n",
    "    'output_dir': \"./output\",  # è¾“å‡ºç›®å½•\n",
    "    'num_classes': 10,  # ç±»åˆ«æ•°é‡ï¼ˆä¸åŒ…æ‹¬èƒŒæ™¯ï¼‰\n",
    "}\n",
    "\n",
    "# è®­ç»ƒé…ç½®\n",
    "TRAINING_CONFIG = {\n",
    "    'model_name': \"mask_rcnn_R_50_FPN_3x\",\n",
    "    'batch_size': 2,\n",
    "    'base_lr': 0.00025,\n",
    "    'max_iter': 1000,\n",
    "    'num_workers': 0,  # Windowsè®¾ä¸º0ï¼ŒLinuxå¯è®¾ä¸º4\n",
    "    'score_thresh_test': 0.5,\n",
    "    'input_min_size_test': 800,\n",
    "    'input_max_size_test': 1333,\n",
    "}\n",
    "\n",
    "print(\"âš™ï¸ è¯­ä¹‰å®ä¾‹åˆ†å‰²é…ç½®:\")\n",
    "print(\"ğŸ“ æ•°æ®é›†é…ç½®:\")\n",
    "for key, value in DATASET_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"\\nğŸ¯ è®­ç»ƒé…ç½®:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a302a659-d993-40b7-ac3f-ef4b4cf42788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” éªŒè¯æ•°æ®é›†å®Œæ•´æ€§...\n",
      "  âŒ images - è·¯å¾„ä¸å­˜åœ¨!\n",
      "  âœ… labels\n",
      "  âŒ isat.yaml - è·¯å¾„ä¸å­˜åœ¨!\n",
      "  âš ï¸ train.json - æ–‡ä»¶ä¸å­˜åœ¨\n",
      "  âš ï¸ val.json - æ–‡ä»¶ä¸å­˜åœ¨\n",
      "  âš ï¸ test.json - æ–‡ä»¶ä¸å­˜åœ¨\n",
      "âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•COCOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: æ•°æ®é›†éªŒè¯å’Œæ³¨å†Œ\n",
    "print(\"ğŸ” éªŒè¯æ•°æ®é›†å®Œæ•´æ€§...\")\n",
    "\n",
    "# æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶å’Œç›®å½•\n",
    "required_paths = [\n",
    "    DATASET_CONFIG['img_dir'],\n",
    "    DATASET_CONFIG['coco_ann_dir'],\n",
    "    DATASET_CONFIG['isat_yaml_path']\n",
    "]\n",
    "\n",
    "for path in required_paths:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"  âœ… {path}\")\n",
    "    else:\n",
    "        print(f\"  âŒ {path} - è·¯å¾„ä¸å­˜åœ¨!\")\n",
    "\n",
    "# æ£€æŸ¥COCOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶\n",
    "coco_files = ['train.json', 'val.json', 'test.json']\n",
    "available_splits = []\n",
    "\n",
    "for coco_file in coco_files:\n",
    "    coco_path = os.path.join(DATASET_CONFIG['coco_ann_dir'], coco_file)\n",
    "    if os.path.exists(coco_path):\n",
    "        print(f\"  âœ… {coco_file}\")\n",
    "        available_splits.append(coco_file.replace('.json', ''))\n",
    "        \n",
    "        # æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶çš„åŸºæœ¬ä¿¡æ¯\n",
    "        with open(coco_path, 'r') as f:\n",
    "            coco_data = json.load(f)\n",
    "        print(f\"    - å›¾åƒæ•°é‡: {len(coco_data['images'])}\")\n",
    "        print(f\"    - æ ‡æ³¨æ•°é‡: {len(coco_data['annotations'])}\")\n",
    "        print(f\"    - ç±»åˆ«æ•°é‡: {len(coco_data['categories'])}\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ {coco_file} - æ–‡ä»¶ä¸å­˜åœ¨\")\n",
    "\n",
    "if not available_splits:\n",
    "    print(\"âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•COCOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶!\")\n",
    "else:\n",
    "    print(f\"\\nğŸ“Š å¯ç”¨æ•°æ®é›†: {available_splits}\")\n",
    "    \n",
    "    # æ³¨å†Œæ•°æ®é›†\n",
    "    class_labels = register_all_datasets()\n",
    "    print(\"âœ… æ•°æ®é›†æ³¨å†Œå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fad585b-4d6a-4c66-a172-16b10c609076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ æ— æ³•å¼€å§‹è®­ç»ƒï¼Œè¯·æ£€æŸ¥æ•°æ®é›†é…ç½®\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    \"\"\"æ‰§è¡Œæ¨¡å‹è®­ç»ƒ\"\"\"\n",
    "    print(\"ğŸš€ å¼€å§‹è®­ç»ƒè¯­ä¹‰å®ä¾‹åˆ†å‰²æ¨¡å‹...\")\n",
    "    \n",
    "    # æ„å»ºé…ç½®\n",
    "    cfg = build_cfg()\n",
    "    \n",
    "    # ä¿å­˜é…ç½®\n",
    "    save_config(cfg, cfg.OUTPUT_DIR)\n",
    "    \n",
    "    # æ‰“å°è®­ç»ƒä¿¡æ¯\n",
    "    print(f\"\\nğŸ“‹ è®­ç»ƒä¿¡æ¯:\")\n",
    "    print(f\"  æ¨¡å‹: {TRAINING_CONFIG['model_name']}\")\n",
    "    print(f\"  ç±»åˆ«æ•°: {DATASET_CONFIG['num_classes']}\")\n",
    "    print(f\"  æ‰¹æ¬¡å¤§å°: {TRAINING_CONFIG['batch_size']}\")\n",
    "    print(f\"  å­¦ä¹ ç‡: {TRAINING_CONFIG['base_lr']}\")\n",
    "    print(f\"  æœ€å¤§è¿­ä»£: {TRAINING_CONFIG['max_iter']}\")\n",
    "    print(f\"  è¾“å‡ºç›®å½•: {cfg.OUTPUT_DIR}\")\n",
    "    print(f\"  è®¾å¤‡: {cfg.MODEL.DEVICE}\")\n",
    "    \n",
    "    # åˆ›å»ºè®­ç»ƒå™¨\n",
    "    trainer = CustomTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    \n",
    "    print(f\"\\nğŸ¯ å¼€å§‹è®­ç»ƒ {TRAINING_CONFIG['max_iter']} æ­¥...\")\n",
    "    \n",
    "    try:\n",
    "        # å¼€å§‹è®­ç»ƒ\n",
    "        trainer.train()\n",
    "        \n",
    "        print(\"\\nğŸ‰ è®­ç»ƒå®Œæˆ!\")\n",
    "        \n",
    "        # ä¿å­˜æœ€ç»ˆæ¨¡å‹è·¯å¾„\n",
    "        final_model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "        if os.path.exists(final_model_path):\n",
    "            print(f\"ğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model_path}\")\n",
    "        \n",
    "        return trainer, cfg\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâ¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­\")\n",
    "        return None, cfg\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:\")\n",
    "        print(f\"   é”™è¯¯ä¿¡æ¯: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, cfg\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦å¯ä»¥å¼€å§‹è®­ç»ƒ\n",
    "if 'class_labels' in locals() and available_splits:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ¯ å‡†å¤‡å¼€å§‹è®­ç»ƒ...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # æ‰§è¡Œè®­ç»ƒ\n",
    "    trainer, cfg = train_model()\n",
    "    \n",
    "    if trainer is not None:\n",
    "        print(\"\\nâœ… è®­ç»ƒæµç¨‹å®Œæˆ!\")\n",
    "        \n",
    "        # æ˜¾ç¤ºè®­ç»ƒç»“æœä½ç½®\n",
    "        print(f\"\\nğŸ“ è¾“å‡ºæ–‡ä»¶:\")\n",
    "        output_dir = Path(cfg.OUTPUT_DIR)\n",
    "        if output_dir.exists():\n",
    "            for file in output_dir.iterdir():\n",
    "                if file.is_file():\n",
    "                    print(f\"  ğŸ“„ {file.name}\")\n",
    "    else:\n",
    "        print(\"\\nâŒ è®­ç»ƒæœªæˆåŠŸå®Œæˆ\")\n",
    "else:\n",
    "    print(\"âŒ æ— æ³•å¼€å§‹è®­ç»ƒï¼Œè¯·æ£€æŸ¥æ•°æ®é›†é…ç½®\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1be6aa-5a4b-4808-9e77-7e366ee333fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataset_name=\"tomato_test\", config_override=None):\n",
    "    \"\"\"è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹\"\"\"\n",
    "    print(f\"ğŸ“Š åœ¨ {dataset_name} ä¸Šè¯„ä¼°æ¨¡å‹...\")\n",
    "    \n",
    "    # æ„å»ºé…ç½®\n",
    "    cfg = build_cfg()\n",
    "    if config_override:\n",
    "        cfg.update(config_override)\n",
    "    \n",
    "    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹\n",
    "    model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}\")\n",
    "        return None\n",
    "    \n",
    "    cfg.MODEL.WEIGHTS = model_path\n",
    "    \n",
    "    # åˆ›å»ºè¯„ä¼°å™¨\n",
    "    evaluator = COCOEvaluator(dataset_name, cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "    val_loader = build_detection_test_loader(cfg, dataset_name)\n",
    "    \n",
    "    # æ„å»ºæ¨¡å‹\n",
    "    model = DefaultTrainer.build_model(cfg)\n",
    "    \n",
    "    print(\"ğŸ” å¼€å§‹è¯„ä¼°...\")\n",
    "    results = inference_on_dataset(model, val_loader, evaluator)\n",
    "    \n",
    "    # æ˜¾ç¤ºç»“æœ\n",
    "    print(\"\\nğŸ“ˆ è¯„ä¼°ç»“æœ:\")\n",
    "    print(json.dumps(results, indent=2))\n",
    "    \n",
    "    # ä¿å­˜ç»“æœ\n",
    "    results_path = os.path.join(cfg.OUTPUT_DIR, f\"eval_results_{dataset_name}.json\")\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"ğŸ’¾ è¯„ä¼°ç»“æœå·²ä¿å­˜: {results_path}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# å¦‚æœè®­ç»ƒå®Œæˆï¼Œè¿›è¡Œè¯„ä¼°\n",
    "if 'trainer' in locals() and trainer is not None:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“Š å¼€å§‹æ¨¡å‹è¯„ä¼°\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°\n",
    "    if 'test' in available_splits:\n",
    "        test_results = evaluate_model(\"tomato_test\")\n",
    "    \n",
    "    # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°\n",
    "    if 'val' in available_splits:\n",
    "        val_results = evaluate_model(\"tomato_val\")\n",
    "    \n",
    "    print(\"âœ… è¯„ä¼°å®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f394e5-4edb-494d-b281-41765beaa3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ Detectron2è¯­ä¹‰å®ä¾‹åˆ†å‰²è®­ç»ƒæµç¨‹å®Œæˆ!\n"
     ]
    }
   ],
   "source": [
    "def visualize_predictions(dataset_name=\"tomato_test\", num_samples=5):\n",
    "    \"\"\"å¯è§†åŒ–é¢„æµ‹ç»“æœ\"\"\"\n",
    "    print(f\"ğŸ¨ å¯è§†åŒ– {dataset_name} é¢„æµ‹ç»“æœ...\")\n",
    "    \n",
    "    # æ„å»ºé…ç½®\n",
    "    cfg = build_cfg()\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "    \n",
    "    # åˆ›å»ºé¢„æµ‹å™¨\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    metadata = MetadataCatalog.get(dataset_name)\n",
    "    \n",
    "    # åŠ è½½æ•°æ®é›†\n",
    "    split_name = dataset_name.split('_')[-1]\n",
    "    dataset_dicts = load_coco_json(\n",
    "        os.path.join(DATASET_CONFIG['coco_ann_dir'], f\"{split_name}.json\"), \n",
    "        DATASET_CONFIG['img_dir']\n",
    "    )\n",
    "    \n",
    "    # éšæœºé€‰æ‹©æ ·æœ¬è¿›è¡Œå¯è§†åŒ–\n",
    "    sample_data = random.sample(dataset_dicts, min(num_samples, len(dataset_dicts)))\n",
    "    \n",
    "    print(f\"ğŸ–¼ï¸ å¤„ç† {len(sample_data)} å¼ å›¾åƒ...\")\n",
    "    \n",
    "    for i, d in enumerate(sample_data):\n",
    "        img_path = d[\"file_name\"]\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"âš ï¸ å›¾åƒä¸å­˜åœ¨: {img_path}\")\n",
    "            continue\n",
    "            \n",
    "        # è¯»å–å›¾åƒ\n",
    "        im = cv2.imread(img_path)\n",
    "        \n",
    "        # é¢„æµ‹\n",
    "        outputs = predictor(im)\n",
    "        \n",
    "        # å¯è§†åŒ–\n",
    "        v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=1.2)\n",
    "        v._default_font_size = 20\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        \n",
    "        # ä¿å­˜ç»“æœ\n",
    "        save_path = os.path.join(cfg.OUTPUT_DIR, f\"prediction_{i+1}_{os.path.basename(img_path)}\")\n",
    "        cv2.imwrite(save_path, out.get_image()[:, :, ::-1])\n",
    "        print(f\"  ğŸ’¾ {save_path}\")\n",
    "    \n",
    "    print(\"âœ… å¯è§†åŒ–å®Œæˆ!\")\n",
    "\n",
    "def generate_confusion_matrix(dataset_name=\"tomato_val\"):\n",
    "    \"\"\"ç”Ÿæˆæ··æ·†çŸ©é˜µ\"\"\"\n",
    "    print(f\"ğŸ“Š ç”Ÿæˆ {dataset_name} æ··æ·†çŸ©é˜µ...\")\n",
    "    \n",
    "    cfg = build_cfg()\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    split_name = dataset_name.split('_')[-1]\n",
    "    dataset_dicts = load_coco_json(\n",
    "        os.path.join(DATASET_CONFIG['coco_ann_dir'], f\"{split_name}.json\"),\n",
    "        DATASET_CONFIG['img_dir'],\n",
    "        dataset_name=dataset_name\n",
    "    )\n",
    "\n",
    "    metadata = MetadataCatalog.get(dataset_name)\n",
    "    class_names = metadata.thing_classes\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    cmatrix_total = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "\n",
    "    print(f\"ğŸ” å¤„ç† {len(dataset_dicts)} å¼ å›¾åƒ...\")\n",
    "    \n",
    "    for data in tqdm(dataset_dicts, desc=\"ç”Ÿæˆæ··æ·†çŸ©é˜µ\"):\n",
    "        height, width = data[\"height\"], data[\"width\"]\n",
    "        image = cv2.imread(data[\"file_name\"])\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        # ç”ŸæˆçœŸå®æ ‡æ³¨mask\n",
    "        gt_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        for ann in data.get(\"annotations\", []):\n",
    "            category_id = ann[\"category_id\"]\n",
    "            segmentation = ann[\"segmentation\"]\n",
    "            if isinstance(segmentation, list):\n",
    "                rle = mask_utils.frPyObjects(segmentation, height, width)\n",
    "                rle = mask_utils.merge(rle)\n",
    "            elif isinstance(segmentation, dict) and \"counts\" in segmentation:\n",
    "                rle = segmentation\n",
    "            else:\n",
    "                continue\n",
    "            m = mask_utils.decode(rle)\n",
    "            gt_mask[m == 1] = category_id\n",
    "\n",
    "        # ç”Ÿæˆé¢„æµ‹mask\n",
    "        outputs = predictor(image)\n",
    "        instances = outputs[\"instances\"].to(\"cpu\")\n",
    "\n",
    "        pred_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        for i in range(len(instances)):\n",
    "            class_id = int(instances.pred_classes[i])\n",
    "            mask = instances.pred_masks[i].numpy()\n",
    "            pred_mask[mask == 1] = class_id\n",
    "\n",
    "        # è®¡ç®—æ··æ·†çŸ©é˜µ\n",
    "        cm_local = confusion_matrix(\n",
    "            gt_mask.flatten(),\n",
    "            pred_mask.flatten(),\n",
    "            labels=list(range(num_classes))\n",
    "        )\n",
    "        cmatrix_total += cm_local\n",
    "\n",
    "    # å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ\n",
    "    cmatrix_norm = np.nan_to_num(cmatrix_total.astype('float') / cmatrix_total.sum(axis=1, keepdims=True))\n",
    "    \n",
    "    # ä¿å­˜ä¸ºExcel\n",
    "    df = pd.DataFrame(cmatrix_norm, index=class_names, columns=class_names)\n",
    "    excel_path = os.path.join(cfg.OUTPUT_DIR, f\"confusion_matrix_{split_name}.xlsx\")\n",
    "    df.to_excel(excel_path)\n",
    "    print(f\"ğŸ’¾ æ··æ·†çŸ©é˜µå·²ä¿å­˜: {excel_path}\")\n",
    "\n",
    "    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    masked = np.ma.masked_where(cmatrix_norm == 0, cmatrix_norm)\n",
    "    im = ax.imshow(masked, cmap=\"Blues\", vmin=0.0, vmax=1.0)\n",
    "    \n",
    "    # æ·»åŠ æ•°å€¼æ ‡æ³¨\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            val = cmatrix_norm[i, j]\n",
    "            if val > 0:\n",
    "                color = 'white' if val > 0.5 else 'black'\n",
    "                ax.text(j, i, f\"{val:.2f}\", ha='center', va='center', color=color, fontsize=8)\n",
    "    \n",
    "    ax.set_xticks(np.arange(num_classes))\n",
    "    ax.set_yticks(np.arange(num_classes))\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(class_names)\n",
    "    ax.set_xlabel(\"é¢„æµ‹ç±»åˆ«\")\n",
    "    ax.set_ylabel(\"çœŸå®ç±»åˆ«\")\n",
    "    ax.set_title(f\"æ··æ·†çŸ©é˜µ - {dataset_name}\")\n",
    "    \n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # ä¿å­˜å›¾åƒ\n",
    "    img_path = os.path.join(cfg.OUTPUT_DIR, f\"confusion_matrix_{split_name}.png\")\n",
    "    plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"ğŸ¨ æ··æ·†çŸ©é˜µå›¾å·²ä¿å­˜: {img_path}\")\n",
    "    print(\"âœ… æ··æ·†çŸ©é˜µç”Ÿæˆå®Œæˆ!\")\n",
    "\n",
    "# å¦‚æœæ¨¡å‹è®­ç»ƒå®Œæˆï¼Œè¿›è¡Œå¯è§†åŒ–\n",
    "if 'trainer' in locals() and trainer is not None:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ¨ å¼€å§‹ç»“æœå¯è§†åŒ–\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # å¯è§†åŒ–é¢„æµ‹ç»“æœ\n",
    "    if 'test' in available_splits:\n",
    "        visualize_predictions(\"tomato_test\", num_samples=3)\n",
    "    \n",
    "    # ç”Ÿæˆæ··æ·†çŸ©é˜µ\n",
    "    if 'val' in available_splits:\n",
    "        generate_confusion_matrix(\"tomato_val\")\n",
    "    \n",
    "    print(\"âœ… å¯è§†åŒ–å®Œæˆ!\")\n",
    "\n",
    "print(\"\\nğŸ‰ Detectron2è¯­ä¹‰å®ä¾‹åˆ†å‰²è®­ç»ƒæµç¨‹å®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad301eb-e358-4630-9490-c6b5089a7a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
